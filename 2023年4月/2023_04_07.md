# 2023_04_07 Arxiv更新论文汇总
今天共有11篇论文


 ## Paper:1




1. Title: Can Large Language Models Play Text Games Well? (中文翻译：大型语言模型能否很好地玩文本游戏？)

2. Authors: Chen Feng Tsai, Xiaochen Zhou, Sierra S. Liu, Jing Li, Mo Yu, Hongyuan Mei

3. Affiliation: 1-University of Chicago (芝加哥大学), 2-Syracuse University (雪城大学), 3-New Jersey Institute of Technology (新泽西理工学院), 4-WeChat AI (微信人工智能), 5-Toyota Technological Institute at Chicago (芝加哥丰田技术研究所)

4. Keywords: Large Language Models, Text Games, Natural Language Processing, AI, Machine Learning

5. Urls: Paper link: https://arxiv.org/abs/2304.02868v1, Github: None

6. Summary:

- (1):本文研究大型语言模型在玩文本游戏方面的能力。
 
- (2):过去的方法主要是使用计算机代理进行游戏，但由于复杂性和互动性等方面的挑战，使用人类游戏者和计算机代理进行游戏已成为评估人工智能系统能力的主要手段。本文通过将 ChatGPT 放入文本游戏（以 Zork I 为例），研究其与人类游戏者的对比及其本身的能力，则是对这一领域的进一步研究探索。作者发现目前 ChatGPT 能完成文本游戏但表现欠缺，存在不能构建世界模型、知识利用及推断等问题。

- (3):本文主要使用 ChatGPT 模型在 Jericho 游戏环境中测试文本游戏 Zork I，作者将 ChatGPT 插入游戏并与人类游戏者进行比较，通过自动推理和自主点阅方案收集 ChatGPT 的决策和性能。最后提出新的研究问题，探索人工智能、机器学习和自然语言处理的重叠领域。

- (4):ChatGPT 在 Jericho 游戏环境中测试文本游戏 Zork I，与人类游戏者进行比较，ChatGPT 能够像人类一样进行文本游戏，但表现欠缺。作者发现 ChatGPT 不能构建世界模型，难以利用已有知识，也




 ## Paper:2




1. Title: Device-Independent Quantum Secure Direct Communication with User Authentication

2. Authors: Nayana Das, Goutam Paul

3. Affiliation: Nayana Das - Qulabs Software (India) Pvt. Ltd, Hyderabad, India.

4. Keywords: Identity authentication, Device-independent, Quantum cryptography, Quantum dialogue

5. Urls: arXiv:2304.03201v1 [quant-ph] 6 Apr 2023

6. Summary:

- (1): This article focuses on the development of a device-independent quantum secure direct communication (QSDC) protocol with user authentication. Traditional quantum communication protocols rely on the security and trustworthiness of the devices employed to implement the protocols, which can be susceptible to attacks. Device-independent (DI) quantum protocols aim to secure quantum communication independent of the devices used by leveraging the fundamental principles of quantum mechanics.

- (2): Past methods of quantum cryptography have relied on solving complex mathematical problems to ensure the security of communication protocols. The security of these protocols was dependent on the security and trustworthiness of the devices employed to implement the protocols. However, this reliance on device security also makes these protocols susceptible to attacks. The approach proposed in this article is well-motivated because it addresses the challenges of secure communication protocols by designing a DI-QSDC protocol that includes user identity authentication to establish the authenticity of both sender and receiver before message exchange.

- (3): The research methodology proposed in this article involves designing the first DI-QSDC protocol which includes user identity authentication. The authors extend this approach to a DI-Quantum Dialogue (QD) protocol where both parties can send secret messages upon mutual authentication.

- (4): The proposed approach achieves secure communication by authenticating user identities prior to message exchange, thus ensuring the unconditional security of the communication protocol. The paper does not mention any specific task or performance, but the approach is motivated by the challenges of secure communication protocols and addresses those challenges.

- (5): The motivation behind this article is to improve the security of quantum communication protocols by developing a device-independent approach that does not rely on the security and trustworthiness of the devices employed to implement the protocol. By designing a DI-QSDC protocol that includes user identity authentication, the authors ensure secure communication and address the challenges of existing communication protocols.




 ## Paper:3




1. Title: Diffusion Models as Masked Autoencoders

2. Authors: Chen Wei, Karttikeya Mangalam, Po-Yao Huang, Yanghao Li, Haoqi Fan, Hu Xu, Huiyu Wang, Cihang Xie, Alan Yuille, Christoph Feichtenhofer

3. Affiliation: 1. FAIR, Meta AI

4. Keywords: deeplearning, generative pre-training, diffusion models, masked autoencoders, visual representations

5. Urls: https://arxiv.org/abs/2304.03283

6. Summary:

- (1): 本文探讨了图像生成模型的生成式预训练如何有效地为下游任务提供强大的初始参数。

- (2): 早期的generative pre-training方法，如Deep Belief Networks和Denoising Autoencoders，无法很好地在视觉表示方面提供适当的帮助。最近的Generative Pre-trained Transformers和GPTs表现良好。但在视觉领域，这种生成式预训练方法仍无法如预期般发挥强大作用。文章提出将传输模型（diffusion models）作为预训练的基础，并将其作为Masked Autoencoder的变体DiffMAE，取得了很好的效果。

- (3): 文章将传输模型用于Masked Autoencoder中，并且基于Masked Autoencoder的预训练方法，有效提高了下游视觉任务的分类精度。 在完成Denosing Diffusion Model中的迭代过程后，达到解噪的效果。同时，文章还实现了高质量的图像修复和视频分类任务，并对设计选择的优缺点进行了全面研究。

- (4): 本文提出的DiffMAE预训练方法，可作为下游任务的强有力的初始参数，并在ImageNet任务中超越了自监督预训练方法Masked Autoencoders (MAE)。在修复图像方面，DiffMAE表现出强大的图像恢复能力。在视频分类任务方面，DiffMAE也展示了比其他模型更好的性能。

- (5): 本文研究视觉领域中的生成式预训练模型，目前的生成模型无法提供适当的帮助，因此文中提出新的方法，将传输模型引入预训练中，并成功应用于多个任务。




 ## Paper:4




1. Title: GPT detectors are biased against non-native English
        (GPT检测器对非母语为英语的作者存在偏见)
        
2. Authors: Weixin Liang, Mert Yuksekgonul, Yining Mao, Eric Wu, James Zou
        
3. Affiliation: 作者1：斯坦福大学计算机科学系，斯坦福，美国；作者2：斯坦福大学电气工程系，斯坦福，美国；作者3：斯坦福大学生物医学数据科学系，斯坦福，美国
        
4. Keywords: GPT detectors, bias, non-native English writers, generative language models
        
5. Urls: Paper: arXiv:2304.02819v1, Github:None
        
6. Summary:
        - (1): 本文研究背景是：生成式语言模型的广泛应用给数字交流带来了巨大进展，同时也引发了人们关于人工智能生成内容潜在滥用的担忧，虽然已经提出了许多检测方法区分人工智能和人类生成的内容，但这些检测器的公平性和鲁棒性仍未得到充分探讨。
        
        - (2): 过去的检测方法存在的问题和动机以及方法的合理性没有得到很好的解决。现在，作者们通过对来自非母语为英语的作者的投稿以及母语为英语的作者投稿进行准确性测试发现，GPT检测器对非母语为英语的投稿误判率相对较高，而对母语为英语的投稿却能准确地进行辨别。这导致了检测器存在偏见。此外，作者们提出的简单提示策略不仅可以减轻这种偏见，还可以有效地绕过GPT检测器，从而表明GPT检测器可能无意中惩罚那些语言表达受限制的作者。 
      
        - (3): 本文提出了一种对来自非母语为英语的作者的投稿误判率相对较高的GPT检测器进行检测的新方法，并使用这种方法对具有误判存在的GPT检测器进行了评估。评估结果表明，使用这个方法可以有效地缓解这种偏见，并实现对所有作者的公平的检测。
      
        - (4): 文章的主要任务是研究GPT检测器的偏见问题。通过与现有检测方法的对比，此篇论文提出了一种更为公平鲁棒的检测方法，并在实验中得到了良好的效果证明。作者发现，提供多样化的提示可以成功地绕过GPT检测器，而且新方法也取得了理想的效果，可以针对不同语言组进行公平鲁棒性检测。
       
        - (5): 本研究的动机是通过对GPT检测器的评估，揭示其检测偏见的问题，提供更加公平的检测手段，希望能够减少可能的误判率，尤其是在教育背景下。结果表明，GPT检测器对非母语为英语的作者存在偏见，提示需要更多地关注公平和鲁棒性问题，以确保更加公平和安全的数字环境。




 ## Paper:5




1. Title: Inst-Inpaint: Instructing to Remove Objects with Diffusion Models (使用扩散模型指导物体进行消除)
                
                2. Authors: Ahmet Burak Yildirim, Vedat Baday, Erkut Erdem, Aykut Erdem, Aysegul Dundar 

                3. Affiliation: Bilkent University (比尔肯特大学)

                4. Keywords: Deep learning, Natural Language Processing, Computer Vision, Image Inpainting
                
                5. Urls: 
                Paper: https://arxiv.org/abs/2304.03246v1 
                Github: None
                
                6. Summary:
                
                - (1):本文的研究背景是图像中的物体消除技术。传统的图像修复方法需要使用二进制掩模高亮显示希望消除的像素，然而，生成这些掩模耗时且易于出错。因此，本文提出一种通过文本输入预测应该消除的物体并实时移除它的图像修复算法。	               
               
                -  (2): 目前的图像消除技术需要使用二进制掩模麻烦且易出错。最近采用深度学习为基础的图像修复方法则将修复任务视为监督学习问题，利用生成先验知识的框架进行修复。这些方法虽然可以在一定程度上完成消除的任务，但是缺乏在自然语言输入条件下直接预测消除对象的先决要求。
                
                - (3): 本文首先构建了一个数据集 GQA-Inpaint 用于在文本输入下预测消除的物体，并提出了一种新型的补全框架 Inst-Inpaint。该框架可以根据文本提示清除图像中的对象。在合成和真实图像数据集上进行了各种 GAN 和扩散模型基准测试。作者比较了不同评估指标的方法，并展示出重要的定量和定性改进。
              
                - (4): 本文的研究目标是提出一种可以根据自然语言输入预测消除对象并自动移除的图像修复算法。作者给出了 GQA-Inpaint 数据集用于训练和测试他们的方法，其可以比较不同评估指标以评估模型的质量和准确性，并展示了显著的性能改进。
                
                - (5): 本文的动机是为了解决传统图像消除需要使用二进制掩模并容易出错的问题。作者提出了使用自然语言输入预测消除对象并自动移除的图像修复算法。他们的方法可以避免使用手动制作的掩模，提高图像消除的准确性和效率。




 ## Paper:6




1. Title: Investigating Chain-of-thought with ChatGPT for Stance Detection on Social Media 

2. Authors: Bowen Zhang, Xianghua Fu, Daijun Ding, Hu Huang, Yangyang Li, Liwen Jing 

3. Affiliation: 深圳技术大学大数据与互联网学院 

4. Keywords: Stance detection, ChatGPT, Chain-of-thought, neural networks, social media 

5. Urls: https://arxiv.org/abs/2304.03087 

   Github: None 

6. Summary: 

- (1):文章研究的背景是情感倾向检测在社交媒体中的应用，以及传统方法在VLPLMs的时代所面临的困境与挑战。 

- (2):过去的方法包括传统机器学习、早期深度神经网络以及预训练微调模型。然而，随着VLPLMs的出现，如ChatGPT，传统方法在部署方面面临挑战。文章介绍了一种不需要反向传播训练的无参数Chain-of-Thought（CoT）方法，并探讨其在情感倾向检测任务中的有效性和相关挑战。

- (3):本文提出了一种结合CoT和ChatGPT的方法，利用CoT获得上下文中的信息，并通过ChatGPT进行文本特征提取。 

- (4):文章在情感倾向检测任务中比较了多种方法的表现，其中CoT+ChatGPT方法取得了最好的性能，证明了该方法的有效性。 

- (5):文章目的是探讨在VLPLMs时代下解决情感倾向检测任务的方法，并提出了一种不需要反向传播训练的无参数方法。




 ## Paper:7




1. Title: MEMEFIER: DUAL-STAGE MODALITY FUSION FOR IMAGE MEME CLASSIFICATION
2. Authors: Christos Koutlis, Manos Schinas, Symeon Papadopoulos
3. Affiliation: CERTH-ITI希腊撒洛尼基
4. Keywords: multimodal hate detection, meme classification, meme sentiment classification
5. Urls: Paper URL: https://arxiv.org/abs/2304.02906v1, Github: https://github.com/ckoutlis/memefier
6. Summary:

- (1): 本文的研究背景是通过深度学习自动识别网络上的图像梗，并且鉴别这些梗是否存在辱骂、攻击等情况。
- (2): 过去的方法通常是依靠手动标注等传统方式，但是这些传统方式需要大量的人力、时间和精力，并且识别效果较差。本文提出了一种基于深度学习的双阶段多模态融合模型，可以较好地解决多模态识别困难的问题。本文的方法已经在三个广泛采用的基准测试中进行了广泛实验，并在某些情况下超过了现有技术的水平。
- (3): 本文提出的方法是双阶段多模态融合模型。第一级融合阶段使用融合模块产生包含模态一致性信息的特征向量，捕捉模因间的非平凡关系；第二级融合阶段利用Transformer编码器学习令牌级别的模因间相关性，并产生信息丰富的表示。另外，作者考虑到外部知识作为额外的输入以及背景图像字幕监督作为正则化的组成部分。
- (4): 本文的方法在三个泛化性强的基准测试中进行了广泛的实验，即Facebook Hateful Memes、Memotion7k和MultiOFF，结果表明我们的方法在某些情况下超过了现有技术的水平。本文的性能与其目标相吻合。
- (5): 本文的目的是提出一种深度学习方法来自动识别网络上的图像梗并评估其侮辱或攻击性，为限制网络上的仇恨言论传播提供支持。




 ## Paper:8




1. Title: Opportunities and challenges of ChatGPT for design knowledge management (《ChatGPT在设计知识管理中的机遇与挑战》)
2. Authors: Xin Hua, Yu Tian, Keisuke Nagato, Masayuki Nakao, Ang Liu (华昕，田煜，长门惠佑，中尾聪之，刘昂)
3. Affiliation: The University of New South Wales, Kensington, NSW, Australia, 2052 (新南威尔士大学)
4. Keywords: Engineering design, Knowledge management, ChatGPT, Responsible AI (工程设计，知识管理，ChatGPT，负责任人工智能)
5. Urls: paper: None, code: None
6. Summary:
- (1): 本文研究的背景是工程设计知识管理。
- (2): 过去的方法包括基于知识图谱、多目标进化算法等，这些方法在知识获取和利用的效率方面还有欠缺。文章以ChatGPT作为一种新的自然语言处理技术，探讨了它在设计知识获取方面的机遇与挑战。文章提到了使用ChatGPT的优点和问题，并对这些问题的应对提出了一些前瞻性研究方向。文章认为，既要充分发挥ChatGPT的优势，提高设计知识获取效率，也要解决ChatGPT在设计知识获取方面面临的问题，才能进一步推进工程设计领域中的知识管理。
- (3): 本文提出了将ChatGPT用于设计知识获取的研究方法，通过实验验证ChatGPT获取知识的优势和局限性，并在此基础上提出了一些前瞻性研究方向，如利用监督学习和强化学习算法增强ChatGPT的知识获取能力、优化ChatGPT的生成过程等。
- (4): 本文的实验结果表明，使用ChatGPT能够帮助设计者获取来自不同领域的有针对性的知识，但是ChatGPT生成的知识质量很大程度上取决于生成提示的质量。文章认为，ChatGPT可作为设计领域中一种新的知识获取手段，但仍需要持续地优化和完善。
- (5): 本文的动机是基于自然语言处理的技术ChatGPT，探讨其在工程设计知识管理方面的机遇与挑战，并进一步提高 ChatGPT 在工程设计方向中的应用效果，解决 ChatGPT 在技术细节与知识质量上的问题，以推进 ChatGPT 在工程设计中的广泛应用。




 ## Paper:9




1. Title: Pragmatically Appropriate Diversity for Dialogue Evaluation (检验语言行为在对话生成中的多样性)
2. Authors: Katherine Stasaski, Marti A. Hearst
3. Affiliation: Salesforce AI Research∗ (Salesforce AI Research) 
4. Keywords: Pragmatically Appropriate Diversity, Dialogue Evaluation, Speech Acts, Neural Dialogue Agents
5. Urls: Paper (N/A), Github: None 
6. Summary: 

- (1): 进行对话生成时，在保持机器会话的多样性时存在瓶颈。传统的自动度量方法并没有考虑到语言行为的影响。因此，本文提出了基于“语言行为”的概念，以便更好地评估机器生成的对话多样性。
  
- (2): 以前的方法是使用自动度量标准来评估机器生成对话的多样性，但这些度量标准并没有考虑对话中的语言行为。本研究通过提出“语言行为”的概念，将能更好地评估机器协作对话中生成的多样性。实验结果表明，使用考虑到语言行为的方法，生成多样性更好，更符合语言学的期望。 
  
- (3): 本文提出了一种基于“语言行为”的算法，分析对话中不同语言行为对机器生成多样性的影响，帮助机器生成多样性更好的对话。
  
- (4): 研究结果表明，使用考虑到语言行为的方法，机器生成的对话多样性更好，更符合语言学的期望。
 
- (5): 研究的动机是为了更好地评估机器生成对话的多样性，进而能够更好的服务于相关应用。




 ## Paper:10









 ## Paper:11




1. Title: When do you need Chain-of-Thought Prompting for ChatGPT?

2. Authors: Jiuhai Chen, Lichang Chen, Heng Huang, and Tianyi Zhou.

3. Affiliation: Maryland大学 (University of Maryland).

4. Keywords: Chain-of-Thought prompting, ChatGPT, Large Language Models, LLMs, pretraining dataset leakage, reasoning tasks.

5. URL: arXiv:2304.03262v1 [cs.AI] 6 Apr 2023 or Github: None.

6. Summary: 

- (1): 本文研究Chain-of-Thought Prompting (CoT)在ChatGPT上的有效性，考察其是否能够增强模型的推理能力，以及对预训练数据泄漏的风险进行分析。

- (2): 本文对比了不同prompting方式下ChatGPT在多种推理任务上的表现，发现对于某些任务，CoT并不一定有效，并分析其可能的原因和隐患。文章的方法和分析得到了充分的动机和解释。

- (3): 本文在CoT Prompting的基础上，提出了一种新的分析方法，即Dataset Inference Attack (DIA)，用于推断LLMs中的预训练数据是否被泄漏，并利用其发现了ChatGPT中存在的instruction memorization和instruction bias风险。

- (4): 本文在多个任务上进行了实验，并提供了新的benchmark结果，表明CoT Prompting并不总是有效，且存在隐患。文章的实验结果，特别是DIA方法的验证，支持作者的研究目标。

- (5): 本文的研究动机是为了探索LLMs的推理能力和数据泄漏问题，尤其是在ChatGPT这一最先进的conversational agent上，旨在为之后的研究提供新的思路和分析。



