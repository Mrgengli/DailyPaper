# 2023_05_09 Arxiv更新论文汇总
今天共有31篇论文


 ## Paper:1




1. Title: IIITD-20K: Dense captioning for Text-Image ReID (IIITD-20K：稠密字幕在文本-图像重识别中的应用)

2. Authors: A V Subramanyam, Niranjan Sundararajan, Vibhu Dubey, Brejesh Lall

3. Affiliation: 印度信息技术学院Delhi研究所

4. Keywords: Text-to-image ReID, Benchmark, Synthetic data, IIITD-20K dataset (文本-图像重识别、基准测试、合成数据、IIITD-20K数据集)

5. URLs: 
- Paper: https://arxiv.org/abs/2305.04497
- Github: None

6. Summary:
- (1):本文研究的是文本-图像重识别问题，在现有数据集的基础上提出了新的数据集IIITD-20K。
- (2):先前的方法主要集中于提取全局特征，忽略了文本和图像间的细粒度关联，在描述较短或不含人物行为特征等问题上也存在限制。本文提出的方法主要关注在数据集构建和通过合成数据提高识别效果方面的创新，被充分论证合理。
- (3):本研究主要通过构建新的数据集IIITD-20K来解决过往数据集的局限性，在数据增强方面，本文进一步利用Stable-diffusion和BLIP模型对图像和字幕进行了生成，充实了IIITD-20K数据集的内容。
- (4):本文在现有数据集上对比了多个文本-图像重识别模型，结果表明本文提出的方法在准确率等指标上均值得提升，并且反应出本方法在文本-图像重识别领域具有较高的实用性。
- (5):本文旨在解决现有数据集存在的一系列问题，并提出新的数据集和数据增强方法来提高识别效果，促进文本-图像重识别领域的进一步研究。




 ## Paper:2




1. Title: DiffBFR: Bootstrapping Diffusion Model for Blind Face Restoration (无监督人脸修复的扩散模型)

2. Authors: Xinmin Qiu, Congying Han, ZiCheng Zhang, Bonan Li, Tiande Guo, Xuecheng Nie

3. Affiliation: 中国科学院大学

4. Keywords: Diffusion Probabilistic Model, blind face restoration, identity restoration, texture enhancement

5. Urls: arXiv: 2305.04517v1 [cs.CV] 8 May 2023, Github: None

6. Summary:
- (1): 本文涉及无监督的人脸修复技术，使得低质量人脸图像能以更生动、更准确的方式被修复。
- (2): 以往的无监督人脸修复技术使用 GAN 架构的方法，虽然赢得了质量和效率的平衡，但它们存在着训练不稳定，无法适应长尾分布的问题，无法同时保留源图像的特征和修复细节。然而，本文提出了一种基于 Diffusion Probabilistic Model 的框架 DiffBFR，以解决这些问题。DiffBFR 由两个步骤完成，先恢复低质量的图像并保留身份信息，再根据真实面部的分布增强纹理细节。DiffBFR 包括两个关键组件：1）身份还原模块（IRM），以保留结果中的人脸特征。我们提出了一种新颖的截取抽样方法，该方法从低质量图像中加入部分噪声，而不是使用作为逆向过程中的条件的低质量图像来进行纯高斯随机分布去噪。通过理论证明，我们证明这种方法可以缩小 Diffusion Probabilistic Model 的证据下界，从而恢复更多原始细节。针对这个问题，我们介绍了两个级联的条件 DPM，其具有不同的输入尺寸，以增强这种采样效果并降低直接生成高分辨率图像的训练难度。2）纹理增强模块（TEM）。 
- (3): 本文采用了基于 Diffusion Probabilistic Model 的框架 DiffBFR，将其分为两个步骤执行。首先，IRN 模块用于恢复低质量图像并保留身份信息，在此过程中使用了新的截断采样方法。然后，TEM 模块用于根据真实面部的分布增强纹理细节。
- (4): 本文的任务是无监督人脸修复， DiffBFR 方法与其他技术进行了比较，展现了更好的修复细节和信息恢复，并具有较好的客观和主观质量评估。这表明提出的方法可以很好地支持其目标。 
- (5): 本文的研究动机是开发一种无监督的人脸修复技术，使低质量图像能以更生动、更准确的方式被修复，并且能够同时保留源图像的特征和修复细节。




 ## Paper:3




1. Title: Enhancing Knowledge Graph Construction Using
Large Language Models

2. Authors: Milena Trajanoska, Riste Stojanov, Dimitar Trajanov

3. Affiliation: 第一作者：Faculty of Comp. Sci. and Eng. Ss. Cyril and Methodius University Skopje, Macedonia

4. Keywords: ChatGPT, REBEL, LLMs, Relation-extraction, NLP, Sustainability

5. Url: https://arxiv.org/abs/2305.04676 Github: None

6. Summary: 

- (1):本文研究大型语言模型在构建知识图谱方面的应用；
 
- (2):过去的方法存在一些问题，如无法将大规模的非结构化文本数据转换成实用的信息，本文引入大型语言模型使用NLP技术，能够从原始文本创建知识图谱和本体，并且自动产生相关实例，个体和属性；
 
- (3):本文提出了一种将NLP和机器学习技术相结合的知识图谱构建方法，利用可训练的大型语言模型，比较了 ChatGPT 和 REBEL 在关系提取方面的效果，使用持续发展为主题的文本数据作为案例来评估方法；
  
- (4):本文使用提出的方法并针对可持续性问题进行评估，在自动创建知识图谱的过程中取得了更高的准确性，并发现自动本体的创建也能进一步提高知识图谱的相关性和精度；
 
- (5):本研究旨在填补大型语言模型和语义技术结合应用的研究空缺，并探索将其应用于具体任务中的效果。




 ## Paper:4




1. Title: Toward Connecting Speech Acts and Search Actions in Conversational Search Tasks（探索在会话式搜索任务中连接语言行为与搜索动作）

2. Authors: Souvick Ghosh, Satanu Ghosh, Chirag Shah

3. Affiliation: Souvick Ghosh - San José State University（圣何塞州立大学）

4. Keywords: Conversational Search Systems, Wizard-of-Oz Study, Experimental User Study, Speech Acts, Dialogue Acts, Spoken Search（会话式搜索系统，绿皮书研究，实验用户研究，语言行为，对话行为，口述搜索）

5. Urls: http://arxiv.org/abs/2305.04858v1 

6. Summary:

- (1): 本文主要研究智能会话式搜索系统，探索解决用户实际需求，有效执行搜索任务的方法。

- (2): 过去的方法主要集中在简单的搜索任务和控制智能设备，没有涉及全面理解用户需求并执行相应的搜索行为。因此，需要建立可以理解用户对话的功能方面（搜索意图）的系统。本文旨在通过自动识别口语表达中的语言行为，预测系统级别的搜索动作，提出了一种新的研究方法。

- (3): 本文利用深度神经网络来理解自然语言，并预测语言行为。将语言行为输入模型，以预测相应的系统级别搜索操作。通过Wizard-of-Oz研究方法，收集数据验证算法的准确性。

- (4): 研究在两个不同数据集上达到了90.2％和72.7％的最大准确率，而搜索动作分类的最佳分类器分别达到了58.8％和61.1％的准确率。实验结果表明，提出的方法能够达到很好的性能并有效提高智能会话式搜索系统的用户体验。

- (5): 本文的研究动机在于提升智能会话式搜索系统的用户体验，探索解决用户实际需求，有效执行搜索任务的方法。




 ## Paper:5




1. Title: A Drop of Ink may Make a Million Think: The Spread (一滴墨水让万物激动：大语言模型中虚假信息的传播)

                2. Authors: Ning Bian, Peilin Liu, Xianpei Han, Hongyu Lin, Yaojie Lu, Ben He, Le Sun

                3. Affiliation: School of Computer Science and Technology, University of Chinese Academy of Sciences (中国科学院大学计算机科学与技术学院)

                4. Keywords: Large language models, false information, authority bias, in-context injection, semantic diffusion process

                5. URLs: Arxiv, Github: None

                6. Summary:

                - (1):该论文主要研究在大型语言模型（LLMs）中，虚假信息的存在对LLMs的可靠性和安全性造成的威胁，并研究了虚假信息在LLMs中的影响和传播机制。

                - (2):论文提出了源头权威性、注入模式和信息相关度等方面的实验，并研究了LLMs中的局限性和缺陷，指出LLMs易受到一些像新闻或研究论文这样的给人以信任感的虚假信息的影响，因此需要新的虚假信息防御算法。

                - (3):通过一系列实验，探究了虚假信息如何通过语义扩散过程在LLMs中传播和污染与之相关的记忆，并对三种不同程度的信息相关性进行比较，提出了新的方法，尝试消除LLMs中存在的局限性。

                - (4):本文的实验结果表明：（1）虚假信息会通过语义扩散过程在LLMs中污染相关记忆，即虚假信息除直接影响外还具有全局有害效应。（2）LLMs易受到源头权威性偏见的影响，即LLMs更容易遵循以新闻或研究论文等可信方式呈现的错误信息，从而导致信息的更深入和更广泛的污染。（3）LLMs通过上下文注入注入的虚假信息比通过基于学习的注入注入的虚假信息更敏感，即使所有的训练数据都是真实正确的，这也严重挑战了LLMs的可靠性和安全性。因此，需要新的虚假信息防御算法和新的对齐算法，以按照内部人类价值观而非表面模式为导向地引领LLMs的发展。

                - (5):本研究的动机在于探讨在LLMs中虚假信息的存在对LLMs的可靠性和安全性所造成的挑战问题。同时，论文提出了虚假信息防御算法和对齐算法，尝试对这一问题进行改善和解决。




 ## Paper:6




1. Title: Can Diffusion Model Achieve Better Performance in Text Generation?（扩散模型在文本生成中能否取得更好的性能表现？）

2. Authors: Zecheng Tang, Pinzheng Wang, Keyan Zhou, Juntao Li, Ziqiang Cao, Min Zhang

3. Affiliation: 中国，苏州大学，计算机科学与技术学院

4. Keywords: Diffusion model, Text generation, Exposure bias, Downsampling, Distance penalty, Adaptive decay sampling

5. Urls: Paper: https://arxiv.org/abs/2305.04465; Github: https://github.com/CODINNLG/Bridge_Gap_Diffusion

6. Summary:

- (1): 该论文研究扩散模型在文本生成中的应用，并提出了方法来解决扩散模型在训练和推理中存在的不一致问题。

- (2): 以前的方法存在着训练和推理不一致的问题，这会导致错误积累。牺牲精度来加速生成过程的下采样方法也会导致扩散模型在训练和推理过程中轨迹不匹配。本文提出了两种简单有效的方法（即距离罚项和自适应衰减采样），可以使用更好的性能来加速扩散模型的推理过程。

- (3): 本文提出了两种跨训练和推理阶段的方法，以缩小扩散模型的错误积累并加快生成速度：距离惩罚和自适应衰减采样。 在进行文本生成时，这两种方法都可以改善性能。

- (4): 在6个不同的文本生成任务中进行实验，结果表明，我们的方法可以提高100×至200×的速度，并在性能上获得更好的结果。实验结果支持了本文的研究目标。

- (5):本文的研究动机是解决扩散模型在文本生成中性能下降的问题，并提出了改进方法来应对训练和推理阶段之间的差异，从而提高性能和速度。




 ## Paper:7




1. Title: ToolCoder: Teach Code Generation Models to use API search tools
                2. Authors: Kechi Zhang, Ge Li, Jia Li, Zhuo Li, Zhi Jin
                3. Affiliation: Kechi Zhang belongs to Key Lab of High Confidence Software Technology, MoE (Peking University)
                4. Keywords: deeplearning, code generation, API search, natural language processing, tool integration
                5. url: https://arxiv.org/abs/2305.04032 , Github:None
                
                6. Summary: 
                
                - (1): 本文针对代码生成模型在特定上下文下难以选择合适API的问题，受到人类开发者使用搜索工具查找API的启发，提出一种新的方法，即将API搜索工具与现有模型集成以帮助选择合适的API。
                
                - (2): 过去的大规模代码生成模型在选择API时经常会遇到困难，会生成不符合要求的API或参考第三方库中不存在的API，尤其是对于不太知名或私有库。而本文提出的方法将API搜索工具与现有模型集成，将搜索工具的使用信息添加到源代码数据中，辅助精细调整代码生成模型，在预测过程中将搜索工具集成到生成过程中，使模型能够自动使用搜索工具在选择API时获取建议。方法具有较好的实用性、普适性和鲁棒性，比现有方法改进了至少6.21%的pass@1指标和9.64%的pass@5指标。本文相对较小的ToolCoder模型与现有最佳模型GPT-3.5的性能相当，凸显了将编程工具纳入代码生成过程的潜力。
                
                - (3): 本文提出的方法是通过整合搜索工具来辅助选择API的，具体而言，通过自动化数据注释方法将搜索工具的使用信息添加到源代码数据中，然后使用ChatGPT等方式微调代码生成模型，在预测时通过集成API搜索工具来获取建议。
                
                - (4): 本文的方法在五个公开和私人图书馆代码生成基准测试中，具有较好的性能和普适性，比现有方法改进了至少6.21%的pass@1指标和9.64%的pass@5指标。实验结果还表明，相对较小的ToolCoder模型性能与现有最佳模型GPT-3.5相当，说明了将编程工具纳入代码生成过程的潜力和实用性。


                - (5): 本文的研究动机是解决代码生成模型在选择API时的困难，以帮助准确表达程序语义，并高效地解决问题，同时具有实用性、普适性和鲁棒性，通过与搜索工具的整合，使模型能够自动选择合适的API。




 ## Paper:8




1. Title: Fractal derivatives, fractional derivatives and q-deformed calculus (分形导数、分数阶导数和q-变形微积分)

2. Authors: Airton Deppman, Eugenio Megías, Roman Pasechnik

3. Affiliation: Airton Deppman: 巴西圣保罗大学物理学研究所；Eugenio Megías: 西班牙格拉纳达大学原子、分子和核物理学系和基础物理和计算物理学卡洛斯一世研究所；Roman Pasechnik: 瑞典隆德大学物理学系 

4. Keywords: fractional derivatives, fractal derivatives, q-calculus, Caputo’s derivative, fractal geometry(分数阶导数、分形导数、q-微积分、Caputo导数、分形几何)

5. Urls: arXiv:2305.04633v1 [math-ph] 8 May 2023

6. Summary:
(1):本文研究了分数阶导数和分形导数的异同之处，以及与q-微积分的关系。
(2):以往的研究已经应用基于分数阶导数的方法描述复杂系统的行为，分形导数和分数阶导数有不同之处且分形导数的非局部性是一个重要的方面。有关Caputo导数的研究也是最常见的研究之一，但是与分形尚未完全理解的关系。根据本文的方法进行的拟合可视为一种分形导数的连续逼近和Caputo导数的逼近。
(3):本文探讨了不同连续逼近分形导数的方法，以及q-微积分导数是分形函数分形导数的连续逼近。该方法可用于分形空间上函数的导数，同时描述了Caputo导数的逼近。有助于研究分数阶微分方程、分形系统的异常扩散、信息和流行病的传播，以及分形几何等领域。
(4):该方法在分形空间上描述了分形函数的导数，同时得到了Caputo导数的拟合。得到的结果表明Caputo 的逼近与分形导数有关。
(5):本文为拓展标准微积分、包含分数阶导数和积分提供了一种有趣的研究方向。在物理学和其他领域的运用为分形数学与实际应用的结合提供了可行的思路。




 ## Paper:9




1. Title: Text-to-Image Diffusion Models can be Easily Backdoored  (文本到图像扩散模型易被植入后门)

2. Authors: Shengfang Zhai, Yinpeng Dong, Qingni Shen, Shi Pu, Yuejian Fang, Hang Su 

3. Affiliation: School of Software and Microelectronics, Peking University (第一作者机构：北京大学软件与微电子学院)

4. Keywords: Text-to-image synthesis, diffusion models, backdoor attack, conditioning mechanisms, regularization loss 

5. Url: Paper - https://arxiv.org/abs/2305.04175v1, Github - None 

6. Summary: 

- (1): 本文主要研究文本到图像扩散模型存在的后门问题。

- (2): 文章综述了现有的文本到图像合成方法及其存在的问题，提出利用多模态数据污染的BadT2I框架对文本到图像扩散模型进行后门攻击，并且进行了细致的实验分析。该研究方法的动机充分，问题研究的意义重大。

- (3): 本文提出了一种基于条件机制的文本到图像扩散模型后门攻击框架BadT2I，在图像各种语义层面（像素后门、目标后门、风格后门）进行后门攻击，并通过正则化损失，对大规模的扩散模型进行有效注入后门，同时保留其对良性输入的有效性。

- (4): 作者在稳定扩散（Stable Diffusion）数据集上进行了实验，证明大规模扩散模型可以在几个微调步骤内轻松被后门攻击。此外，作者还探讨了不同类型文本触发器的影响，介绍了后门攻击在进一步训练中的持续性，该研究可为后门防御方法提供参考。

- (5): 本文的主要动机在于揭示现有文本到图像扩散模型的不具有鲁棒性的问题，旨在更好地了解训练过程和相关风险。




 ## Paper:10




1. Title: Bootstrapping Advanced Large Language Models by Treating Multi-Modalities as Foreign Languages
其译名为: 通过将多模式视为外语来引导先进的大型语言模型

2. Authors: Feilong Chen, Minglun Han, Haozhi Zhao, Qingyang Zhang, Jing Shi, Shuang Xu, Bo Xu

3. Affiliation: 该论文的第一作者陈飞龙(Feilong Chen)所属单位为中国科学院自动化研究所(Institute of Automation, Chinese Academy of Sciences)

4. Keywords: Large language models, multi-modalities, X-LLM, GPT-4, language conversion

5. Url: arXiv:None, Github: https://x-llm.github.io

6. Summary:
- (1):本文的研究背景为大型语言模型(LLMs)不断发展，多模式语言模型得到了快速发展，在图像描述、视觉问答、视觉对话、视频描述和口语对话等任务中表现优异。
- (2):过去的方法主要集中在单模式或较少的模态上，而本文提出的方法X-LLM通过X2L接口将多模式转换为外语，将多模式能力引入大型语言模型(ChatGLM)中，可以更好地实现多模式能力。
- (3):本文提出的X-LLM方法包括三个步骤：(1)将多模态信息转换为语言；(2)单模式编码器与LLM之间的相互对齐；(3)利用X2L接口将所有单模式编码器与LLM对齐，实现多模态能力与LLM的整合。
- (4):与GPT-4相比，本文的方法取得了很好的表现，在模拟多模态指令跟随数据集中获得了84.5%的相对分数，并在语音识别和多模式语音识别等方面得到了实验数据的支持。 
- (5):本文的研究动机是为了能以更好的方式将多模态能力与LLM相结合，为语言模型的发展和语音识别的发展做出贡献。




 ## Paper:11




1. Title: Learning Summary-Worthy Visual Representation for Abstractive Summarization in Video

2. Authors: Zenan Xu, Xiaojun Meng, Yasheng Wang, Qinliang Su, Zexuan Qiu, Xin Jiang, and Qun Liu.

3. Affiliation: 中山大学计算机科学与工程学院, 中国/Huawei Technologie/香港中文大学/广东大数据分析与处理重点实验室

4. Keywords: Multimodal abstractive summarization, Generative pre-trained language model, Audio-visual information, Deep learning 

5. URLs: Paper - https://arxiv.org/abs/2305.04824, Github - None.

6. Summary:
- (1):本文研究多模态抽象摘要生成中的视觉表示问题。
- (2):先前的方法通常使用通用的视觉特征提取器提取视觉信息，但是这些特征可能会忽视一些与摘要相关的重要信息，从而影响模型的性能。本文提出了一种学习适合抽象摘要任务的摘要相关视觉表示方法，该方法利用跨模态转录数据和伪摘要中提取的知识，实现了从文本和视觉角度的有效信息提取，能够支持抽象摘要的生成。
- (3):本文提出的方法通过两个端到端的网络实现，一个是文本信息编码器，另一个是基于视觉的关键信息提取器，两个网络相互协作，充分利用文本信息和视觉信息之间的相关性，提取摘要相关的视觉表达，并生成抽象摘要。
- (4):本文在三个公共数据集上进行了广泛实验证明，本文提出的方法在小规模数据集或者限制训练数据的情况下均能展现出居于竞争方法之上的良好性能，超过同类相关工作。
- (5):本文旨在解决多模态抽象摘要生成中视觉特征提取不给力的问题，提出了基于深度学习的视觉特征提取方法，实现了抽象摘要任务的自动化生成。




 ## Paper:12




1. Title: Reinforcement Learning for Topic Models (强化学习在主题模型中的应用)

2. Authors: Jeremy Costello and Marek Z. Reformat

3. Affiliation: Department of Electrical and Computer Engineering, University of Alberta (加拿大阿尔伯塔大学电子与计算机工程系)

4. Keywords: reinforcement learning, topic modeling, variational autoencoder, policy gradient algorithm

5. Urls: Paper: arXiv:2305.04843v1 [cs.CL] Github: None

6. Summary: 

- (1):本文研究主题模型中强化学习的应用。

- (2):传统的主题模型方法为Latent Dirichlet Approximation (LDA)，近年来Neural Topic Models (NTM) 逐渐取代这一方法。本文针对 NTM 中的 ProdLDA 方法，用连续动作空间的强化学习策略代替变分自编码器。文章指出ProdLDA使用的VAE缺点在于实现较为复杂并且不能很好的处理过多的噪声。本文通过强化学习方法，在从未知标签的情况下，在 11 个数据集上将模型的表现与监督学习表现进行比对。结果表明，本文所提出的无监督模型优于其他无监督模型，且与大部分需要监督学习方法的模型表现相当或更好。

- (3):本文使用 REINFORCE 算法进行训练，并通过改进神经网络结构、给损失函数设定权重、使用上下文嵌入、监测主题多样性和凝聚性指数等阶段，对 ProdLDA 方法进行改进。

- (4):文章在11个不同的数据集上进行了实验，其无监督模型可以在很多任务上超过LDA等传统模型、unsupervised GSDMM、supervised SEAT等模型，达到了不错的效果。同时，还进行了灵敏度分析和模型可解释性对比等实验，验证了模型改进的效果。

- (5):本文主要动机是通过借用强化学习领域中的技术，将其应用于主题模型的无监督学习任务之中，提升原有模型的表现，同时也在本文中提出了一些关于 ProdLDA 实现方面存在的问题和改进方法。




 ## Paper:13




1. Title: Towards Zero-Shot Frame Semantic Parsing with Task Agnostic
 Ontologies and Simple Labels

2. Authors: Danilo Ribeiro, Omid Abdar, Jack Goetz, Mike Ross,
 Annie Dong, Kenneth Forbus and Ahmed Mohamed

3. Affiliation: 1Meta AI

4. Keywords: deeplearning, NLP, frame semantic parsing, task-oriented dialogue systems, zero-shot learning

5. Urls: 
 - Paper: [arXiv](https://arxiv.org/abs/2305.03793)
 - Github: None

6. Summary: 
- (1):本文的研究背景是利用对话系统中的框架语义分析来识别用户输入意图和细节内容，以及添加新的领域来扩展虚拟助手的能力。
- (2):过去的方法需要大量的训练数据才能成功地识别用户输入的意图和细节内容，且需要高度专业化的自然语言处理领域知识。作者提出了一种新的方法，允许非自然语言处理专家根据少量的简单标签来创建新的领域，并且利用句子编码器的匹配算法来预测用户输入中的意图和细节内容。该方法受到良好的激励。
- (3):本文提出了一种名为OpenFSP的框架，它可以接受开发人员的定义函数和其注释的输入，以便为新的任务扩充一个现有的助手系统。OpenFSP由两个模块组成，通用语义解析器和匹配模块。通用语义解析器可以根据预定义的领域无关槽来识别意图和细节内容。基于这些注释，匹配模块可以预测用户输入中的意图和槽。 
- (4):在TopV2数据集上进行的实验证明，作者的模型在使用简单标签的情况下胜过强基线模型。利用作者提出的方法，可以实现不需要任何完整注释语义分析实例的领域扩展，但需要人工标准化数据库来进行学习。
- (5):该研究的动机是希望通过开发一种新的框架，使非专业人士也能够创建新的领域，从而帮助扩展虚拟助手的能力。




 ## Paper:14




1. Title: No More Manual Tests? Evaluating and Improving
ChatGPT for Unit Test Generation

2. Authors: Zhiqiang Yuan, Yiling Lou, Mingwei Liu, Shiji Ding, Kaixin Wang, Yixuan Chen, Xin Peng

3. Affiliation: 江西师范大学 (Jiangxi Normal University)

4. Keywords: Unit Test Generation, ChatGPT

5. Urls: None, arxiv: 2305.04207v1 [cs.SE] 7 May 2023

6. Summary:

- (1): 本文针对单元测试生成进行了研究。

- (2): 传统单元测试生成技术存在一定的问题，例如生成的测试代码难以理解、难以应用等，本文提出了利用深度学习技术和大型语言模型实现自动生成高质量单元测试的方法。

- (3): 本文采用深度学习技术以及大型语言模型（ChatGPT）生成测试用例，通过评估其生成单元测试的质量，并用CHATTESTER模型进一步改进它们。

- (4): 本文提出的方法在正确性、充足性和可读性方面都表现出拓展性和良好的结果，尤其是CHATTESTER方法比默认的ChatGPT方法分别增加了34.3%和18.7%的可编译测试和带有正确断言的测试。

- (5): 本文的研究动机是解决传统单元测试生成技术的问题，开发出高质量自动生成的单元测试方法。




 ## Paper:15




1. Title: CHAI-DT: A Framework for Prompting Conversational Generative AI Agents to Actively Participate in Co-Creation


                2. Authors: Brandon Harwood


                3. Affiliation: 作者所在机构为IBM。


                4. Keywords: HCI, Artiﬁcial Intelligence, Generative AI, Co-Creation, Design Thinking


                5. Urls: arXiv:2305.03852v1 [cs.HC] 5 May 2023


                6. Summary:
 
                - (1): 本文研究利用生成AI模型在面向团体的共创框架中增强商业创新和共创背景下的问题解决和构思的潜力，并提出了一种新的提示技术，以启用交互生成AI代理参与设计思维。
 
                - (2): 本文探索了人类和AI之间的协同框架，提出了一种基于设计思维带有提示技术的对话型生成AI智能体的提议。本文还讨论了使用生成AI模型进行协同构思的潜在好处、局限性和风险，并提出了未来研究的建议。
 
                - (3): 本文提出了一种通过传统的“人际”推进和指导方法启发的提示技术，以启动对话型生成智能体与人类的协作，从而在团体共创框架中为参与者和促进者利用生成型创意代理带来实际效益。通过对这种提示技术的实验，作者证明了具有上下文特定、有用和创造性输入的ChatGPT等对话式生成转换器可以为设计思维活动做出贡献。
 
                - (4): 本文通过提出自然语言的基于对话生成模型的轮次中依据提示技术的积极参与及输入设计思维过程、激发了对话对方的创意。
 
                - (5): 本文研究利用生成AI模型在面向团体的共创框架中增强商业创新和共创背景下的问题解决和构思的潜力，并提出了具有实用性的解决方案，为未来AI与人类间的协同构思提供了新导向。




 ## Paper:16




1. Title: Sparks of Artificial General Recommender (AGR)
2. Authors: Guo Lin, Yongfeng Zhang
3. Affiliation: Rutgers University (both authors)
4. Keywords: ChatGPT, Artificial General Recommender, Conversational Recommender System, Multi-task Recommender System, Multi-domain Recommender System
5. Urls: arXiv:2305.04518v1 [cs.IR] 8 May 2023
6. Summary:

- (1): 本文旨在探讨基于LLMs（Large Language Models）的最新进展，以开发具有普适性和对话性的Artificial General Recommender（AGR）的可行性。
- (2): 过去的方法存在单一性或固定性等限制，不足以支持复杂、多领域的需求。本文提出的AGR应遵循十个基本原则，并对ChatGPT进行测试评估。针对ChatGPT的局限和改进的方向也进行了讨论。
- (3): 本文采用了类似于Microsoft GPT测试的实验方法，利用ChatGPT进行测试，以评估其作为一个AGR的能力。同时，使用了十个基本原则对ChatGPT进行测试。
- (4): 本文通过测试ChatGPT的性能发现，ChatGPT在多个任务和多个领域方面表现优异，表明它在服务于AGR方面潜力巨大。但同时也发现了一些限制和改进的方向。
- (5): 本文的研究动机是寻求一个具有多领域支持和自然对话交互能力的普适推荐系统。




 ## Paper:17




1. Title: ReGeneration Learning of Diffusion Models with Rich Prompts for Zero-Shot

                2. Authors: Yupei Lin, Sen Zhang, Xiaojun Yang, Xiao Wang, Yukai Shi (*corresponding author)
                
                3. Affiliation: 广东工业大学 (Guangdong University of Technology)

                4. Keywords: text-to-image generation, image editing, diffusion model, shape consistency
                
                5. Urls: paper: https://arxiv.org/abs/2305.04651, Github: None
                
                6. Summary:
 
                - (1):这篇文章主要探讨了零样本条件下针对图像生成和编辑的问题。

                - (2):在现有的零样本图像对图像的转换方面，存在一些限制。现有的方法需要用户提供精确的指导信息，也不能在图像编辑的过程中保持原来图像的形状一致性。本文对图像到图像扩散模型 (ReDiffuser) 中的再生学习进行了探索。该模型可以在没有人的指导情况下保留原始图像的内容，并且编辑的方向也可以在文本嵌入空间中自动发现。为了确保在图像编辑期间形状始终保持一致，我们提出了基于再生学习的交叉关注引导。这种新颖的方法可以增强目标域特征的表达同时保持图像的原始形状。此外，我们还引入了一种协作更新策略，可以实现对图像的原始形状的高效保护，从而改善了形状保持质量和一致性。所提出的方法利用了现有的预训练文本-图像扩散模型而不需要额外的训练。

                - (3):本研究使用基于再生学习的交叉关注引导实现形状的一致性。在编辑阶段，我们提出了一个协作更新策略来提高形状的保持质量和一致性。我们的方法利用现有的预训练文本-图像扩散模型，无需额外的训练。

                - (4):在大量的实验中，我们的方法在真实和合成图像编辑方面均优于现有的工作，良好地保持了形状的一致性。

                - (5):本文主要的动机在于解决现有图像编辑方法在零样本下的限制，提高形状保持和目标域表达质量。




 ## Paper:18




1. Title: Controllable Mixed-Initiative Dialogue Generation through Prompting (中文翻译：可控的混合主动对话生成)
                
                2. Authors: Maximillian Chen, Xiao Yu, Weiyan Shi, Urvi Awasthi, Zhou Yu 
                
                3. Affiliation: Columbia University (哥伦比亚大学)
                
                4. Keywords: Mixed-initiative dialogue, Language models, Prompting, Dialogue policy planner
                
                5. Urls: Paper: arXiv:2305.04147v1 [cs.CL] 6 May 2023. Github: None.
                
                6. Summary: 
                
                - (1): 该研究关注于混合主动对话这一任务，旨在通过提示来构造具有可控性的对话生成模型。
                
                - (2): 过去的方法通常采用预先训练好的语言模型并进行fine-tuning，以便按照对话策略和意图生成回答。然而，这种监督式生成模型在数据标注成本和质量方面存在一定限制。因此，该文提出了Prompting方法，通过将预先训练大型语言模型作为替代品，实现对有控制性的混合主动对话的生成，并在人工评估和自动度量方面，针对两个任务（PersasionForGood 和 Emotional Support Conversations）取得了优于Fine-tuning和Ground truth responses的结果。
                
                - (3): 该文中正式建立了以Prompting为基础的可控混合主动对话生成模型构建框架，实现了对话策略的有效执行，避免了数据标注不准确和响应不一致的问题。
                
                - (4): 该文的研究成果在PersasionForGood 和 Emotional Support Conversations两个任务中，取得了优于Fine-tuning和Ground truth responses的人工评估和自动度量结果，证明了其对解决混合主动对话任务的实用性和有效性。
                
                - (5): 该文的研究动机在于解决现有的混合主动对话生成方法在进行Fine-tuning过程时，需要大量数据标注和对多种数据特征进行考虑的问题，提高对话生成的可控性和适用性。




 ## Paper:19




1. Title: ARDIE: AR, Dialogue, and Eye Gaze Policies for Human-Robot Collaboration
机器人协作的增强现实、对话和眼部注视策略

2. Authors: Chelsea Zou, Kishan Chandan, Yan Ding, Shiqi Zhang

3. Affiliation: Chelsea Zou

4. Keywords: human-robot collaboration, augmented reality, decision theoretic framework, natural language, eye gaze

5. Urls: https://arxiv.org/abs/2305.04685 

6. Summary: 

- (1): 本研究探讨机器人协作的相关问题，特别关注于增强现实在人机交互中的应用。
- (2): 过去的方法中，一些使用数字信息的机器人交互技术难以实现人与机器人的相互理解和场景理解的共享。本文提出了一种使用增强现实、自然语言和眼部注视的智能代理系统ARIDE，它可以为人类和机器人之间的交互提供多模态反馈。此外，本文还提出了决策论框架，进一步实现了目标物体的场景可视化，并通过这些可视化来进行任务调整。
- (3): 本文提出的ARIDE使用多种反馈模态，如眼部注视，自然语言互动等，经过决策论框架的支持，对目标物体的场景进行实时可视化，并进一步提高人机交互的效率。
- (4): 本文在物品堆放领域进行了测试，该方法能够帮助人类在操作物品时，可视化物品的未来状态，并根据未来状态进行调整，提高了人与机器人之间的协作效率。
- (5): 本文的研究动机主要是探索增强现实技术在人机交互中的应用，并提高人机交互的效率。




 ## Paper:20




1. Title: Replicating Complex Dialogue Policy of Humans via Ofﬂine Imitation Learning with Supervised Regularization
                2. Authors: Zhoujian Sun, Chenyang Zhao, Zhengxing Huang, Nai Ding
                3. Affiliation: Zhejiang Lab
                4. Keywords: Dialogue policy learning, imitation learning, task-oriented dialog system
                5. Urls: https://arxiv.org/abs/2305.03987
                6. Summary:

                - (1): 本文旨在通过离线模仿学习，在不涉及与用户模拟器的在线交互的情况下，实现复杂人类对话策略的复制。
  
                - (2): 过去的方法包括监督学习和强化学习，但监督学习的性能受到协变量漂移问题的限制，而强化学习的训练需要与用户模拟器的交互，并且难以模拟复杂的人类策略。本文提出了一种离线模仿学习的方法，利用实际对话数据进行训练，并利用状态转移信息缓解了协变量漂移问题。同时，本文还引入了正则化技巧，使模型的优化更加有效。
  
                - (3): 本文提出的方法是通过将人类的决策过程转化为连续的序列决策问题，然后通过模仿人类的决策过程进行策略学习。该方法可以通过使用实际对话数据进行离线学习，不需要与用户模拟器进行在线交互来训练模型。
  
                - (4): 实验结果表明，本文提出的模型在实现任务时表现出更好的准确率。这些表现支持了本文的研究目标，即实现复杂人类对话策略的复制。
  
                - (5): 本文的动机在于解决现有方法难以模拟复杂人类策略的问题，引入一种利用实际对话数据进行离线模仿学习的方法实现复杂人类对话策略的复制。




 ## Paper:21




1. Title: U-NEED: A Fine-grained Dataset for User Needs-Centric E-commerce Conversational Recommendation（面向用户需求的电子商务对话推荐数据集）
                
2. Authors: Yuanxing Liu, Weinan Zhang, Baohua Dong, Yan Fan, Hang Wang, Fan Feng, Yifan Chen, Ziyu Zhuang, Hengbin Cui, Yongbin Li, and Wanxiang Che
                
3. Affiliation: Independent（独立）
                
4. Keywords: Conversational recommendation, User needs, Dialogue corpus
                
5. Urls: https://doi.org/10.1145/3539618.3591878
                
6. Summary: 
- (1): 这篇论文研究的背景是要建立一个根据用户需求进行对话推荐的数据集，以推进对话推荐领域的研究。
- (2): 之前的方法大多数是通过合成对话或模拟对话进行数据集构建，与真实世界场景有较大差距。而本文提出的方法，即面向用户需求的电子商务对话推荐，是通过真实世界的电子商务场景建立数据集，使数据集更加真实可靠。并提供五个重要任务，涉及对话理解、用户需求启发式推荐、对话生成等方面，以期针对这个数据集进行对话推荐领域的研究。
- (3): 本文的研究方法是通过真实世界的电子商务场景构建数据集，采用五个任务以推进对话推荐的研究。
- (4): 实验结果表明针对不同类别的电子商务对话推荐，存在不同的挑战，且所提供的任务和基准方法都能够有效评估本文数据集的适用性。
- (5): 本文的研究动机在于建立一个更真实、更细粒度的数据集，以推进对话推荐领域的研究。




 ## Paper:22




1. Title: From Unstructured to Structured: Transforming Chatbot
Dialogues into Data Mart Schema for Visualization (从无结构到有结构：将Chatbot对话转换为可视化的数据库模式)

2. Authors: Mark Edward M. Gonzales, Elyssia Barrie H. Ong, Charibeth K. Cheng, Ethel Chua Joy Ong, Judith J. Azcarraga

3. Affiliation: 作者：Mark Edward M. Gonzales；机构：德拉萨大学，马尼拉，菲律宾

4. Keywords: Healthcare chatbot, dialogue processing, database design, online analytical processing (OLAP), data visualization (健康聊天机器人，对话处理，数据库设计，联机分析处理，数据可视化)

5. Urls:  论文链接: https://arxiv.org/abs/2305.04258v1

Github: None 

6. Summary: 

- (1): 本文研究背景是在菲律宾公立学校进行健康干预和监测，资源有限导致这些学校无法进行常规的健康检查。因此，本文提出了一种Chatbot协助的健康监测系统来提供替代方法。

- (2): 过去使用的方法需要人类医护人员进行身体检查并维护学生的健康记录，但由于资源有限和技术手段受限，这些方法变得不再实用。因此，作者设计了一个Chatbot协助的健康监测系统，能够自动地进行健康监测，处理学生与Chatbot的对话，将其转换为结构化的数据库模式，以便于进行数据可视化和分析。本文研究的方法的动机充分，相关方法和系统目前取得的成果仍有很大的提升空间。

- (3): 本文中提出的研究方法包括四个步骤：（i）通过实体提取和数据聚合来处理对话，（ii）将其存储为云端的NoSQL文档，（iii）将其转换为适用于联机分析处理的星型模式，并构建提取-转换-加载工作流程，（iv）创建一个基于Web的控制台，用于可视化汇总数据和报告。

- (4): 本文的方法在数据可视化和分析方面表现出色，通过性能评估来显示其提供的Dashboard可以在很短的时间内展示汇总、钻取和筛选结果。可以预见，在未来，我们可以将这些Chatbot协助的系统进一步完善并应用于更多领域的健康监测。然而，本文的方法还需要更多的改进，以便更好地支持其提出的目标。

- (5): 本文旨在探讨如何利用Chatbot技术来协助学生在学校中进行健康监测，帮助从事医疗事务的人员在不增加额外人力的情况下进行更好的数据分析和可视化。未来如果该研究能够成功地应用在学生的健康监测和医学教育中，将会为人们提供更好的健康监测和控制手段。




 ## Paper:23




1. Title: ChatUniTest: a ChatGPT-based automated unit test generation tool (ChatUniTest: 一种基于ChatGPT的自动化单元测试生成工具)

2. Authors: Zhuokui Xie, Yinghao Chen, Chen Zhi*, Shuiguang Deng, Jianwei Yin

3. Affiliation: 中国浙江大学(Zhejiang University)

4. Keywords: automated unit testing, ChatGPT, software development, test generation

5. Urls: arXiv:None, Github:None

6. Summary:

- (1): 本文探讨了软件开发中的任务——单元测试，以及解决该任务所需的自动化生成测试用例工具。
- (2): 传统的基于程序分析的自动化测试工具缺少对程序的理解，导致生成的单元测试难以阅读和断言有限。而基于深度学习的测试工具则难以正确生成单元测试。本文尝试使用基于聊天模型的ChatGPT，通过适应性上下文生成有效的单元测试，并通过规则修复和ChatGPT修复解决测试中的错误。 
- (3): 本文提出了一种基于ChatGPT的生成-验证-修复框架，首先通过解析项目，提取必要信息，并在预定义的最大提示令牌限制内创建自适应的焦点上下文，将上下文合并到提示中，并将其提交给ChatGPT。一旦接收到ChatGPT的响应，ChatUniTest会从响应中提取原始测试，然后验证测试，并使用基于规则的修复修复语法和简单的编译错误，随后使用基于ChatGPT的修复解决其他错误。 
- (4): 本文的方法称为ChatUniTest，该方法的测试效果超过了传统的工具EvoSuite，可以覆盖分叉和线路，超过了AthenaTest和A3Test，可以产生正确的焦点方法，同时使用模拟对象和反射实现测试目标。本文的严格评估表明，ChatUniTest可以产生有效的单元测试，可以更好地覆盖代码，同时高效地生成断言。 
- (5): 本文的研究旨在减轻开发人员的单元测试负担，提高测试的可读性和有效性。通过使用ChatGPT生成测试用例，本文的工具可以更好地理解程序，并生成易于理解的测试用例。




 ## Paper:24




1. Title: Improving Cross-Task Generalization with Step-by-Step Instructions (采用步骤说明提高跨任务泛化性能)

2. Authors: Yang Wu, Yanyan Zhao, Zhongyang Li, Bing Qin, Kai Xiong

3. Affiliation: Harbin Institute of Technology (哈尔滨工业大学)

4. Keywords: language models, instruction tuning, cross-task generalization, step-by-step instructions, NLP tasks

5. Urls: Paper url: arXiv:2305.04429 ; Github: None

6. Summary:
- (1): 本文主要研究如何采用步骤说明提高自然语言处理 (NLP) 模型在不同任务之间的泛化性能。

- (2): 先前的研究表明，指令调整 (instruction tuning) 方法可以提高语言模型在新任务上的推广能力。然而，先前使用的自然语言指令通常缺乏中间步骤，导致模型难以完成目标任务。本文提出采用步骤说明来帮助模型分解任务，提供详细和具体的完成目标任务的步骤。步骤说明是通过 ChatGPT 自动获取的，这是一种训练将自然语言指令转换为步骤说明的模型。本文深入探究了步骤说明对模型跨任务泛化性能的影响。

- (3): 本文提出的方法是 Step-by-Step Instruction Tuning，采用了 ChatGPT 模型自动生成步骤说明。方法的具体步骤包括将任务描述和正例输入到 ChatGPT 中，得到详细的步骤说明，并将步骤说明与原始指令结合起来进行模型微调。

- (4): 本文在一个包含多个 NLP 任务的数据集 SUP-NATINST 上进行了实验。结果表明，配合高质量的步骤说明可以提高模型在不同模型规模下的跨任务泛化性能，且步骤说明的顺序对效果影响明显。本文进一步释放了步骤说明和其人工质量评估的结果。

- (5): 本文的动机主要是为了解决 NLP 模型在面对新任务时的泛化能力问题，以期能够更好地服务于实际应用。




 ## Paper:25




1. Title: DENSITY: Open-domain Dialogue Evaluation Metric using Density Estimation (基于密度估计的开放域对话评估度量)
                
                2. Authors: ChaeHun Park, Seungil Chad Lee, Daniel Rim, Jaegul Choo

                3. Affiliation: KAIST AI (韩国科学技术院)

                4. Keywords: deeplearning, open-domain dialogue, evaluation metric, density estimation

                5. Urls: https://arxiv.org/abs/2305.04720v1, Github: https://github.com/ddehun/DEnsity

                6. Summary:

                - (1): 该研究围绕开放域对话系统，目标是构建一个有效的对话评估度量标准。

                - (2): 以往的评价方法多采用基于参考标准的度量方式，并存在评估与真实人类话语评价不相关的问题。而本文作者提出基于密度估计的 DENSITY 评估度量，利用神经分类器的特征空间进行密度估计，度量一条对话性回答在人类对话分布中的出现概率。与基于分类模型或参考标准的度量相比，该方法具有更好的评估性能。既能解决因分类器过度自信而在未知数据上表现不稳定的问题，又能很好地与人类评价相关联。

                - (3): DENSITY 评估度量利用密度估计对回答进行评估，将神经分类器的特征空间作为概率密度估计的输入，衡量回答在人类对话分布中出现的概率。同时，作者采用对比学习法进一步降低特征空间的维度，提高了 DENSITY 的性能。

                - (4): 作者在多个回答评估数据集上进行了实验，结果表明 DENSITY 评估度量比已有的基于分类模型或参考标准的度量都具有更好的相关性。其取得的实验性能充分支持了作者的研究目标。

                - (5): DENSITY 是为了解决在开放域对话领域中，评估度量的不相关性问题而提出的一种新的方法，其能够更好地弥合分类模型与真实人类话语评价间的差距。同时，DENSITY 所提供的对话性回答的评估标准，将会有助于改善开放域对话系统的质量。




 ## Paper:26




1. Title: MultiModal-GPT: A Vision and Language Model for Dialogue with Humans
 
                2. Authors: Tao Gong, Chengqi Lyu, Shilong Zhang, Yudong Wang, Miao Zheng, Qian Zhao, Kuikun Liu, Wenwei Zhang, Ping Luo, Kai Chen
                
                3. Affiliation: 上海人工智能实验室
                
                4. Keywords: Vision and Language Model, Dialogue System, Low-rank Adapter, Multi-modality, Instruction Following
                
                5. Urls: https://arxiv.org/abs/2305.04790, Github: https://github.com/open-mmlab/Multimodal-GPT 
                
                6. Summary:
                
                - (1):本文主要研究多模态对话系统在给人类提供帮助时，如何通过视觉和语言指令实现更好的对话效果。
 
                - (2):传统的多模态对话系统在通过视觉数据生成文本时，计算量较大，而且缺乏可解释性，难以满足实际需求。本文提出的模型在处理视觉信息时，使用 Low-rank Adapter （LoRA）在多层的自注意力模块和门限交叉注意力模块中进行处理。并且能够利用模板对视觉和语言数据进行融合，完成多模态指令的处理和生成多回合对话的任务。
 
                - (3):本文提出的 MultiModal-GPT 模型通过使用视觉数据和纯语言数据两种指令类型进行联合训练，最终提高了对话系统的表现。该模型还使用了多模态指令模板和基于类别的蒸馏机制来强化对话效果。
  
                - (4):实验结果表明，MultiModal-GPT 模型在处理多模态对话任务时，能够产生流畅、详细的回答，并且能够正确理解和执行用户的指令。该模型在对话的语法正确性、多样性和相关性等方面达到了很好的表现，以达到实际应用的要求。
 
                - (5):本文旨在探索如何通过视觉和语言数据进行多模态指令处理的机制，提高对话系统的可用性和效率。同时，本文也尝试通过联合训练和指令模板等方法来弥补传统多模态对话系统的不足。




 ## Paper:27




1. Title: Evading Watermark based Detection of AI-Generated Content（AI生成内容的水印检测方式的规避）

2. Authors: Zhengyuan Jiang, Jinghuai Zhang, Neil Zhenqiang Gong

3. Affiliation: 首作者所在机构：Duke University ECE Department

4. Keywords: generative AI, watermark-based detection, AI-generated content, adversarial post-processing

5. Urls: Paper: None

6. Summary:

- (1): 本文研究背景是AI生成内容在信息真实性方面带来的挑战。
 
- (2): 过去的方法是在AI生成内容中嵌入水印以检测内容的真伪；但这种方法遇到了一些问题，如可见水印会被轻易地删除，而非学习型水印容易受到常见图像后处理方法干扰。本文提出了一种对抗性后处理方法来规避水印检测，并证明其对比JPEG压缩、高斯模糊和亮度/对比度等流行的后处理方法具有更强的稳定性。

- (3): 本文提出的方法是对抗性后处理，在AI生成水印图像中添加一些微小的、无法被察觉的扰动，从而导致水印误检。

- (4): 本文的方法在AI生成图像上的实验表明，该方法优于当前主流图像后处理方法，在逃避水印检测的同时保持了图像的视觉质量。

- (5): 本文旨在揭示当前水印检测方法的不足之处，提出对抗性后处理方法，为新模式、新方法的提出提供基础。




 ## Paper:28




1. Title: A Multi-Modal Context Reasoning Approach (一种多模态上下文推理方法)

2. Authors: Yunxin Li, Baotian Hu, Xinyu Chen, Yuxin Ding, and Lin Ma

3. Affiliation: 1. 哈尔滨工业大学深圳研究生院 Shenzhen Graduate School of Harbin Institute of Technology, 2. 美团 Meituan

4. Keywords: Multi-modal Reasoning, Textual and Visual Clues, Conditional Inference, Context Reasoning, Vision-Language Models

5. Urls: Paper: arXiv:2305.04530, Github: https://github.com/YunxinLi/Multimodal-Context-Reasoning

6. Summary:

(1): 本文的研究背景是多模态视觉和自然语言处理交叉领域的条件推理问题。

(2): 过去的方法通常采用预训练好的视觉-语言模型 (VLM)，但对于文本模态信息来说缺乏多模态上下文推理能力。在本文的动机下，提出一种名为 ModCR 的方法，通过引入可学习的对齐前缀来实现文本和视觉的多视图语义对齐信息嵌入，并将文本的抽象语义和目标图像信息作为先前上下文信息嵌入到语言模型中进行上下文推理，从而为解决这一问题提供了良好的动机。

(3): 本文提出的方法是一种多模态上下文推理方法，通过引入可学习的对齐前缀来实现文本和视觉的多视图语义对齐信息嵌入，并将文本的抽象语义和目标图像信息作为先前上下文信息嵌入到语言模型中进行上下文推理，以实现在文本和视觉线索的条件推理任务上的准确分类。

(4): 本文的方法在两个文本和图像数据集上进行了大量的实验证明其准确性。实验结果表明，相对于以前的强基线模型，本文的方法在 PMR 测试集上获得了 4.8% 的精度提高。这证明了 ModCR 的实用性和有效性。

(5): 本文旨在解决多模态视觉和自然语言处理中的条件推理问题，提出一种新的多模态上下文推理方法 ModCR，进一步提高了模型的准确性和实用性。




 ## Paper:29




1. Title: Multi-grained Hypergraph Interest Modeling for Conversational Recommendation (基于多粒度超图兴趣建模的对话推荐)

2. Authors: Chenzhan Shang, Yupeng Hou, Wayne Xin Zhao, Yaliang Li, and Jing Zhang

3. Affiliation: School of Information, Renmin University of China (中国人民大学信息学院)

4. Keywords: Conversational Recommender System, Hypergraph Learning

5. Urls: Paper: https://arxiv.org/abs/2305.04798, Github: https://github.com/RUCAIBox/MHIM

6. Summary:

- (1): 本文研究了对话推荐，在多轮对话中为用户提供高质量的推荐。作者认为目前的对话推荐系统大多数都只使用了当前的对话上下文信息，缺乏历史对话数据，导致数据稀缺问题。因此，本文探讨如何利用历史对话数据全面捕捉用户兴趣。
- (2): 先前的方法主要集中在当前对话上下文，忽略了历史对话数据。本文的方法是建立一个多粒度超图模型，从多个角度捕捉历史对话数据中的用户兴趣。为了克服数据稀缺问题，作者利用外部知识图谱构建了一个基于知识的超图。multi-grained hypergraph convolution被应用到二种超图中，并利用增强表示来开发兴趣感知的推荐系统。作者的方法在两个基准测试数据集 ReDial 和 TG-ReDial 上取得了较好的推荐性能和对话质量。
- (3): 本文提出一种基于多粒度超图兴趣模型的对话推荐方法。作者采用超图来表示历史对话数据中的语义关系，并使用外部知识图谱构建基于知识的超图。multi-grained hypergraph convolution被应用于两种超图中，利用增强表示来开发对话感知的推荐模块。
- (4): 本文的方法在两个基准测试数据集 ReDial 和 TG-ReDial 上取得了优异的推荐性能和对话质量。作者的方法在推荐任务和对话任务上都得到了显著的改进，性能支持他们的目标。
- (5): 本文的研究动机是基于历史对话数据，全面捕捉用户兴趣，以充实当前对话的上下文信息并改善对话的效果。




 ## Paper:30




1. Title: Bypassing antivirus detection: old-school malware, new tricks (绕过杀毒软件检测：老派恶意软件，新的伎俩)

2. Authors: Efstratios Chatzoglou, Georgios Karopoulos, Georgios Kambourakis, and Zisis Tsiatsikas

3. Affiliation: University of the Aegean (爱琴海大学)

4. Keywords: Malware, Antivirus software, Malware evasion techniques, ChatGPT

5. Url: arXiv:2305.04149v1 [cs.CR] 6 May 2023

6. Summary:

- (1): 本文针对现在恶意软件在逃避安全产品检测方面的新伎俩，提供了关于流行的、现成的反病毒和终端检测和响应引擎检测能力方面的实证评估，侧重于 MS Windows 平台，并且对根据公开的已知方法更少见和更少使用的遗留恶意软件进行混淆的能力进行了实验。该研究使用了 7 种传统的 AV 避免技术以及用 C++、Go 和 Rust 构建的 16 个可执行文件的混淆。此外，还开展了初始研究，关于 ChatGPT 聊天机器人在帮助威胁行为者生产成品恶意软件方面的能力。
 
- (2): 恶意软件是攻击者的低风险策略之一，常常伪装成合法的应用程序，使其更容易欺骗最终用户执行它。此外，恶意软件是创建僵尸网络的关键因素，常常用来发起大规模的灾难性分布式拒绝服务（DDoS）攻击，而代码混淆是恶意软件用来逃避静态分析方法和传统的反恶意软件解决方案的几种技术之一。
    
- (3): 本文使用已知方法将传统的恶意软件修改以便使其难以被杀毒软件检测，同时使用一些新技术（如 ChatGPT）来增加它们的复杂性和隐蔽性。在每次对恶意软件进行修改之后，列表中的杀毒软件进行检测。我们使用了 7 种传统的技术和 C++、Go 和 Rust 语言的代码混淆。

- (4): 在绕过杀毒软件检测方面，我们的方法被证明是非常有效的，12个受测杀毒软件中，有约一半的杀毒软件仅能检测少于测试恶意软件变体的一半，其中4个杀毒软件检测到了恶意软件变体的一半，而只有两个检测到除一个以外的所有变体。上述方法的训练过程没有使用任何具体的数据集。因此，这种方法对于检测强化过的旧恶意软件（即，经过成功的混淆）或快速开发新恶意软件而言非常有帮助，但仍需要进一步的研究和开发。

- (5): 本研究旨在寻找恶意软件隐藏的新方法，并开发反病毒技术以更好地保护计算机系统不受恶意软件攻击。




 ## Paper:31




1. Title: Do Large Language Models Show Decision Heuristics Similar to Humans? A Case Study Using GPT-3.5.
                
                2. Authors: Gaurav Suri, Lily R. Slater, Ali Ziaee, Morgan Nguyen
                
                3. Affiliation: Gaurav Suri is affiliated with San Francisco State University, Department of Psychology. Lily R. Slater, Ali Ziaee, and Morgan Nguyen are affiliated with Airbnb, Trust and Safety Division.
                
                4. Keywords: Large Language Models, decision heuristics, biases, GPT-3.5, cognitive processes, language
                
                5. Urls: Paper: https://www.frontiersin.org/articles/10.3389/fpsyg.2021.742606/full, Github: None
                
                6. Summary:
                
                - (1):本文旨在探讨大型语言模型（LLM）是否显示类似于人类的决策启发式。本文使用 GPT-3.5 作为案例研究。
                
                - (2):过去的方法包括心理学实验和行为经济学实验，这些方法并不能完全解释决策启发式。本文的方法充分考虑了人类认知的语言维度。
                
                - (3):本文使用了一系列新颖的提示来确定 ChatGPT 是否表现出启发式、偏见和其他决策效应，并在人类参与者身上测试了相同的提示，以比较两者的反应。
                
                - (4):本文的研究发现，ChatGPT 在做出判断时受到随机锚的影响，判断两个事件一起发生的可能性比任何一个单独事件的可能性要高，容易被引人注目的轶闻信息所误导，对于同样的信息，只要呈现方式不同，就会发生偏差。人类参与者也表现出了类似的影响。虽然 LLM 不具备像人类一样的认知和情感，但它仍然表现出这些效应。本文的表现支持其目标。
                
                - (5):本文的研究结果表明，在语言的层面上，特定的语言模式可能会产生启发式和类似的决策效应，这种现象在以前被认为不是这些效应发生的主要原因。这些结果对人类决策的认知和情感过程到底受到多大程度的影响，值得我们进行再次的思考和研究。



