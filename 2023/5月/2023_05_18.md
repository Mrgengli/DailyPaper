# 2023_05_18 Arxiv更新论文汇总
今天共有27篇论文


 ## Paper:1




1. Title: Selective Amnesia: A Continual Learning Approach（选择性遗忘：一种连续学习方法） 

2. Authors: Alvin Heng, Harold Soh 

3. Affiliation: Alvin Heng：新加坡国立大学计算机科学系； Harold Soh：新加坡国立大学计算机科学系和智能系统研究所 

4. Keywords: Continual Learning, Deep Generative Models, Variational Autoencoders, Text-to-Image Models 

5. Urls: Paper: arXiv:2305.10120v1 [cs.LG] 17 May 2023； Github: https://github.com/clear-nus/selective-amnesia

6. Summary:
- (1):本文针对当今大规模文本转图像模型的普及所带来的一系列问题，提出了一种刻意遗忘前置深度生成模型中特定概念的技术，这种方法叫做Selective Amnesia，实现了可控制遗忘。
- (2):文中指出，传统的深度学习有固有的遗忘问题，需要重新学习所有历史数据，而选择性遗忘能改善这个问题。而Selective Amnesia还能够忘记一些不需要被模型保留的信息，比如不能产生不适当的内容的要求。因此，Selective Amnesia实现了有益的遗忘，这种方法不同于其他过去的遗忘方法，这种方法允许用户指定如何遗忘，使得遗忘过程得到更好的控制。
- (3):文章中提出了一种新的连续学习框架，其包含了一组模块，通过算法来实现针对特定上下文的最优遗忘。实验结果表明Selective Amnesia方法在适用于各种深度生成模型的条件下，可以实现各种概念的遗忘，从基本数据集中的整个类别到文本到图像模型中的明星和裸体提示。
- (4):在对多个模型的实验中，Selective Amnesia方法取得了不错的表现，证明了其实现有益的遗忘的可行性。
- (5):本文的研究动机来源于大规模文本到图像模型的出现所带来的问题，应用Selective Amnesia技术能够解决这个问题，实现更有益的遗忘。




 ## Paper:2




1. Title: CLIP-GCD: Simple Language Guided Generalized Category Discovery

                2. Authors: Rabah Ouldnoughi, Chia-Wen Kuo, Zsolt Kira

                3. Affiliation:  Rabah Ouldnoughi, Chia-Wen Kuo: Georgia Tech

                4. Keywords: deeplearning, computer vision, category discovery, CLIP, multi-modal models

                5. Urls: https://arxiv.org/abs/2305.10420, Github: None 

                6. Summary: 

                - (1): 本文研究的背景是深度学习在分类任务上的应用存在的限制，即其不能识别未知或未注释的类别，这在包括自动驾驶汽车和个人设备等各种问题领域中会导致问题。为了解决这个问题，过去的研究方法通常利用自监督预训练加上有监督微调获取预定义的标签数据，并使用简单的聚类方法处理未注释的数据。然而这些方法在处理越界的目标类别时仍然存在问题，因为他们未能充分利用目标类别之间的语义关系。

                - (2): 本文通过利用视觉和语言多模态模型，提出了两种补充方法以解决上述问题。 首先，提出了一种基于CLIP的模型框架，用于在广义目标识别中建立一个强大的基线机制。 其次，提出了一种新的检索机制，利用与图像编码对齐的语言语料库中的文本描述，并使用检索到的相关文本来实现基于图像和文本的半监督聚类。本文进行了详细实验和分析，包括调查检索源数据、检索数量以及信息融合等不同方面， 这些方法在一定领域内已经达到了最新水平。

                - (3): 本文的方法探究了多模态技术和特定语言数据结构的结合，主要利用图像和CLIP语言语料库之间的对齐，结合本文提出的新的检索机制并并行地将图像和文本信息融合，从而提高对大规模和小规模图像数据集中目标类别探测的准确度和泛化性。

                - (4): 本文成果在一些权威的数据集上取得了不错的成绩。在一般图片识别数据集和小样本识别任务上，可以达到普通类别（known classes），不常见类别（unknown classes）和全部类别的平均准确率，且取得了目前最好的成绩。因此，本文所提出的方法可以用于类别发现的分析和应用。 

                - (5): 本文的动机旨在提出一种新颖的半监督分类机制，以在只使用有限的暗示标签数据（通常仅用于一些广义类别的类别定义）的情况下，训练能在大规模、小规模和多任务数据上有效工作的通用视觉系统。 这也为构建更好的智能辅助系统和机器人系统提供了新思路。




 ## Paper:3




1. Title: ConvXAI : Delivering Heterogeneous AI Explanations via Conversations to Support Human-AI Scientific Writing (通过对话交流传递异构AI解释，支持人机科学写作)

2. Authors: Hua Shen, Chieh-Yang Huang, Tongshuang Wu, Ting-Hao (Kenneth) Huang

3. Affiliation: Pennsylvania State University (宾夕法尼亚州立大学)

4. Keywords: AI explanation, XAI, Conversational XAI, Human-AI interaction, Scientific Writing (AI解释，XAI, 对话交互, 人机交互, 科学写作)

5. Urls: Paper - arXiv:2305.09770v1 [cs.HC], Github: None

6. Summary:

- (1): 本文旨在为人机交互中AI解释（XAI）方法的缺陷提出解决方案。以往的研究发现，现有的XAI方法严重缺乏实用性，因此需要一种新的XAI接口来满足用户的需求。

- (2): 以往的研究通过整合多个XAI方法，例如对话式或基于GUI的XAI系统等，来缩小现有方法与实际需求之间的鸿沟。然而，缺乏对这些系统如何设计以满足实际用户需求的研究。本文提出一种新的对话式XAI系统(ConvXAI)，该系统整合了多种类型的XAI，为用户提供一个统一的XAI对话接口。

- (3): 采用了一系列设计原则和领域特定语言（DSL）以实现必要的对话式XAI模块，并发布核心对话式通用XAI API以提升通用性。

- (4): 通过两个被试研究，本文证明ConvXAI能够有效提高人机交互的实用性。

- (5): 本文的研究动机在于提出一个更加实用和有效的XAI解释方法，以满足XAI在人机交互中的各种需求。




 ## Paper:4




1. Title: Mirages: On Anthropomorphism in Dialogue Systems (关于人类对话系统中的拟人性问题的探讨)

2. Authors: Gavin Abercrombie, Tanvi Dinkar, Amanda Cercas Curry, Zeerak Talat

3. Affiliation: Gavin Abercrombie - Heriot-Watt University

4. Keywords: Dialogue systems, anthropomorphism, natural language processing, linguistic cues 

5. Url: https://arxiv.org/abs/2305.09800v1

6. Summary:

- (1): 该论文探讨了对话系统中拟人化的问题，指出拟人化特征对人们的行为产生的影响，并提出应该如何设计、开发、发布和描述对话系统，以及注意一些语言暗示。

- (2): 过去的方法包括尽可能降低对话系统中拟人化的特征，但是这样做会限制用户的参与度。本文提出了注意不必要的拟人特征的观点，并阐述了语言因素如何促进拟人化和危害。这种方法是有合理动机的。

- (3): 该论文提倡对话系统需要注意设计上的完整性，并对深入研究的语言因素进行了探讨。作者还呼吁将注意力集中在如何减少拟人化特征，以及如何管理人类对话系统中的过度依赖的问题上。

- (4): 该论文没有实验数据，而是提出了一些建议和方向，以减少对话系统中拟人化产生的负面影响。

- (5): 本文的动机是对如何设计能够让用户信任和理解正确性的对话系统进行探讨，并需要注意的是如何管理用户和机器之间的衔接，以及避免鼓励人们对自动化的对话系统进行过度的依赖。




 ## Paper:5




1. Title: ZeroFlow: Fast Zero Label Scene Flow via Distillation

2. Authors: Kyle Vedder, Neehar Peri, Nathaniel Chodosh, Ishan Khatri, Eric Eaton, Dinesh Jayaraman, Yang Liu, Deva Ramanan, James Hays

3. Affiliation: Kyle Vedder - University of Pennsylvania

4. Keywords: Scene flow, Distillation, Zero label, Computer vision, Real-time

5. Urls: Paper - arXiv:2305.10424v1, Github - None

6. Summary: 

- (1): 研究背景：场景流（scene flow）估计是描述时间上连续点云间三维运动的重要基元，但现有算法在大规模点云场景下要么需要昂贵的人工注释，要么需要数十秒或更长时间才能计算，难以用于实时应用。因此本文提出一种 Distillation 的方法来解决这个问题。

- (2): 过去的方法：过去的方法主要分为两种，一类是需要昂贵人工注释的前馈模型，另外一类是运用优化技术的方法，但运行速度较慢不适合实时应用。本文提出 ZeroFlow 方法，在不需要人工标签的情况下，使用基于无标签优化的蒸馏框架来训练前馈模型，能够在大规模点云场景下实现极快速度的场景流估计。

- (3): 研究方法：提出一种 Distillation 的方法，使用一种无标签优化算法来产生伪标签，以监督前馈模型的训练。

- (4): 实现的任务与性能：ZeroFlow 能够在大规模点云场景下实现与现有算法竞争水平的场景流估计，并能够实现实时预测，训练成本远远低于人工标注的成本。在 Argoverse 2 和 Waymo Open 数据集上，ZeroFlow 都能够进行高效且准确的预测。

- (5): 研究动机: 为了解决现有场景流估计方法需要昂贵人工注释或运算速度较慢的问题，提出一种 Distillation 的无标签场景流估计方法。




 ## Paper:6




1. Title: SLiC-HF: Sequence Likelihood Calibration with Human Feedback

2. Authors: Yao Zhao, Rishabh Joshi, Tianqi Liu, Misha Khalman, Mohammad Saleh, Peter J. Liu

3. Affiliation: Yao Zhao - Google DeepMind; Rishabh Joshi - Google Research; Tianqi Liu - Google Research; Misha Khalman - Google Research; Mohammad Saleh - Google Research; Peter J. Liu - Google Brain

4. Keywords: deeplearning, reinforcement learning, human feedback, summarization task 

5. Url: Paper - arXiv:2305.10425v1  [cs.CL]  17 May 2023. Github: None.

6. Summary:

- (1): 在深度学习领域中，学习如何从人的反馈中调整模型以符合人的喜好很重要。在此前的研究中，通常使用强化学习等方法。但是，当训练数据仅基于引用文本时，模型的优化和性能会受到限制。

- (2): 以往的方法在人类反馈数据的收集和处理上存在一定问题。文中提出了一种新的方法，利用Sequence Likelihood Calibration with Human Feedback (SLiC-HF)来优化模型。同时，SLiC-HF的实现简单、调整方便且相对算力更高效，较于以往基于人类反馈的强化学习可作为一种有竞争性的选择。 

- (3): 本文提出的SLiC-HF方法基于模型对人类反馈数据的似然度校准。通过使用其他模型的人类反馈数据，以更高效的方式训练算法以适应新数据，从而提高模型在概括性摘要任务上的性能。

- (4): 在 TL; DR（Too Long, Didn't Read，阅读量较大）概括任务上，SLiC-HF中的概率校准方法显着提高了受监督的精细调整基线的性能。自动和人工评估实验也证明了SLiC-HF相对于以往使用的基于PPO的RLHF实现具有竞争性。 

- (5): 本文旨在提供一种新的基于人类反馈机制的算法，该算法在使用其他模型的人类反馈数据时表现出优异的性能，且与以往的强化学习方法相比更为简单且高效，对于概括性摘要等自然语言处理任务具有应用前景。




 ## Paper:7




1. Title: Euclid preparation. XXIX. Water ice in spacecraft part I: The physics of ice formation and contamination
（欧几里德准备工作。第XXIX部分：航天器上的水冰：第一部分：冰的形成和污染物理学）

2. Authors: Euclid Collaboration: M. Schirmer, K. Thürmer, B. Bras, M. Cropper, J. Martin-Fleitas, Y. Goueﬀon, R. Kohley, A. Mora, M. Portaluppi, G. D. Racca, A. D. Short, S. Szmolka, L. M. Gaspar Venancio, M. Altmann, U. Bastian, M. Biermann, D. Busonero, C. Fabricius, F. Grupp, C. Jordi, W. Löﬄer, A. Sagristà Sellés, N. Aghanim, A. Amara, L. Amendola, M. Baldi, C. Bodendorf, E. Branchini, M. Brescia, J. Brinchmann, S. Camera, G. P. Candini, V. Capobianco, C. Carbone, J. Carretero, M. Castellano, S. Cavuoti, A. Cimatti, R. Cledassou, G. Congedo, C. J. Conselice, L. Conversi, Y. Copin, L. Corcione, F. Courbin, A. Da Silva, H. Degaudenzi, A. M. Di Giorgio, J. Dinis, F. Dubath, X. Dupac, S. Dusini, S. Farrens, S. Ferriol, M. Frailis, E. Franceschi, M. Fumana, S. Galeotta, B. Garilli, W. Gillard, B. Gillis, C. Giocoli, S. V. H. Haugan, H. Hoekstra, W. Holmes, F. Hormuth, A. Hornstrup, K. Jahnke, S. Kermiche, A. Kiessling, M. Kilbinger, T. Kitching, M. Kunz, H. Kurki-Suonio, S. Ligori, P. B. Lilje, I. Lloro, E. Maiorano, O. Mansutti, O. Marggraf, K. Markovic, F. Marulli, R. Massey, E. Medinaceli, S. Mei, Y. Mellier, M. Meneghetti, E. Merlin, G. Meylan, M. Moresco, L. Moscardini, E. Munari, R. Nakajima, S.-M. Niemi, J. W. Nightingale, T. Nutma, C. Padilla, S. Paltani, F. Pasian, V. Pettorino, S. Pires, G. Polenta, M. Poncet, L. A. Popa, F. Raison, A. Renzi, J. Rhodes, G. Riccio, E. Romelli, M. Roncarelli, E. Rossetti, R. Saglia, D. Sapone, B. Sartoris, P. Schneider, A. Secroun, G. Seidel, S. Serrano, C. Sirignano, G. Sirri, J. Skottfelt, L. Stanco, P. Tallada-Crespí, A. N. Taylor, I. Tereno, R. Toledo-Moreo, I. Tutusaus, E. A. Valentijn, L. Valenziano, T. Vassallo, Y. Wang, J. Weller, A. Zacchei, J. Zoubian, S. Andreon, S. Bardelli, P. Battaglia, E. Bozzo, C. Colodro-Con




 ## Paper:8




1. Title: OpenSLU

                2. Authors: Libo Qin, Qiguang Chen, Xiao Xu, Yunlong Feng, Wanxiang Che

                3. Affiliation: 中南大学 (Central South University)

                4. Keywords: spoken language understanding, intent detection, slot filling, modularization, PyTorch

                5. Urls: Paper: None, Github: https://github.com/LightChen233/OpenSLU

                6. Summary:

                - (1):此篇文章是介绍一个统一、模块化、可扩展的口语理解工具箱OpenSLU。

                - (2):过去的方法在单意图场景下存在着意图检测和槽填充的高度相关性，共享的知识没能被很好地利用。本文以统一、解耦模块化、配置灵活为目标，并将模型架构、推断和学习过程拆分为可重用的模块，允许研究者通过重用提供的模块或添加新模块来快速重新实现SLU旧有方法或开发新SLU模型。本文的方法在单意图或者多意图场景下都表现出了非常不错的性能。

                - (3):本文的方法使用PyTorch实现，并统一了10种不同的SLU模型，支持同时处理未预训练和预训练模型，实现了大规模的模块化和分类，允许将不同的技术组件灵活组合在一起使用。

                - (4):作者在不同数据集上进行了大量的实验，表明他们的方法和代码在口语领域的口语理解任务中表现优异。与最新领先的SLU方法相比，OpenSLU在不同的数据集上都显示出非常不错的表现，并且在不同的评估指标上的得分均高于前沿水平标准。OpenSLU在单意图和多意图场景下表现出非常不错的性能，可提高口语理解系统的准确性和性能，降低了系统研发成本，提高了系统的可扩展性。

                - (5):本文主要是对于目前口语理解系统缺少一个统一、可扩展的开源工具箱的问题做出了回答，同时也解决了现有方法的缺陷，为研究者和从业者进行口语理解任务提供了一个非常稳定和开发性极高的平台。




 ## Paper:9




1. Title: Controllable Mind Visual Diffusion Model (可控思维视觉扩散模型)

2. Authors: Bohan Zeng, Shanglin Li, Xuhui Liu, Sicheng Gao, Xiaolong Jiang, Xu Tang, Yao Hu, Jianzhuang Liu, Baochang Zhang

3. Affiliation: 北京航空航天大学 (Beihang University)

4. Keywords: Brain signal visualization, functional magnetic resonance imaging (fMRI), diffusion models, semantic, silhouette, image synthesis

5. Urls: Paper: arXiv:2305.10135v1 cs.CV; Github: None

6. Summary:

- (1): 本文研究背景是理解人类观察视觉刺激时产生的认知过程，以及从脑信号重建视觉刺激。
- (2): 以往的方法主要采用观察到的自然图像匹配人类的脑活动信号，但是缺乏泛化性能。最新的研究使用生成模型进行高质量RGB图像的生成，但是定位不一致。可控思维视觉扩散模型的方法提出了一种从fMRI信号中提取语义和轮廓信息的新方式，同时使用残差块捕获超出语义和轮廓特征的信息，并借助一个控制模型完全利用提取的信息进行图像合成。
- (3): 本文提出的可控思维视觉扩散模型(CMVDM)采用属性对齐和辅助网络从fMRI数据中提取语义和轮廓信息。此外，通过使用残差块，可以捕获语义和轮廓特征之外的信息。最后，使用控制模型来完全利用从信号中提取的信息进行图像合成。
- (4): 本文在图像生成任务中取得了优异的表现，生成了与视觉刺激在语义和轮廓方面相似的图像。与现有的最先进方法相比，CMVDM在质量和数量上都表现出了更好的性能。
- (5): 本文的研究动机是从fMRI信号中提取高质量、具有语义一致性和轮廓的图像，以促进神经科学和脑-计算机接口等领域的进展.




 ## Paper:10




1. Title: Use of a Taxonomy of Empathetic Response Intents to Control and Interpret Empathy in Neural Chatbots

2. Authors: Anuradha Welivita, and Pearl Pu

3. Affiliation: École Polytechnique Fédérale de Lausanne

4. Keywords: empathetic response intent, neural chatbots, response generation, emotional reaction

5. Url: arXiv:2305.10096v1, Github: None

6. Summary: 
- (1): 近年，开放领域对话代理人趋势是使其能够针对情感提示进行感性对话。当前方法要么采用端到端方法，要么将响应条件为类似情绪标签以生成感性响应。然而，同理心是一个广义概念，它指的是个体对观察到的另一个人的经历的认知和情感反应， 这比单纯的情感模仿更为复杂。因此，它需要识别复杂的人类对话策略和动态，以控制和解释聊天机器人的同理心响应能力。
- (2): 该论文提出利用八个同理心响应意图的分类法，以及通用的情感类别构建一个对话响应生成模型，可以以可控和可解释的方式生成同理心响应。它由两个模块组成：1)响应情感/意图预测模块; 2)响应生成模块。我们提出了几种基于规则和神经网络的方法来预测下一个响应的情感/意图，并基于这些预测的情感/意图生成响应。
- (3): 文章提出利用分类法的方法，来解决聊天机器人响应生成的可控和可解释性问题。
- (4): 作者采用语义类比测试以及两种自动评估方法来小样本测试模型，结果显示出了使用分类法的模型能够生成更多变化且更多样的优秀响应。
- (5): 本文的动机是为了解决聊天机器人响应生成过程中可控和可解释性问题，提出一种有效的分类法来控制情感回应。




 ## Paper:11




1. Title: Smaller Language Models are Better (小型语言模型更优)
2. Authors: Fatemehsadat Mireshghallah, Justus Mattern, Sicun Gao, Reza Shokri, Taylor Berg-Kirkpatrick
3. Affiliation: 加州大学圣地亚哥分校（University of California San Diego）
4. Keywords: deeplearning, ML, NLP, CV, language models, machine-generated text detection (深度学习，机器学习，自然语言处理，计算机视觉，语言模型，机器生成文本的检测)
5. Url: 论文链接 (Paper link), Github: None
6. Summary:
- (1): 本文研究背景是随着流畅语言模型的出现，区分机器生成文本和人类写作文本变得越来越具有挑战性和重要性。本文的研究动机是如何在实践中检测生成的文本是否是机器生成的。
- (2): 本文提到了许多现有的检测机器生成文本的方法，这些方法大多需要访问目标模型的logit或需要从目标模型中采样。然而，在实际情况下，我们通常对生成模型的了解非常有限，更不用说访问生成模型了。因此，本文探索了是否可以使用除生成器之外的其他模型来区分机器生成的文本和人类编写的文本。
- (3): 本文的研究方法是首先使用曲率测量来检测机器生成的文本，然后使用协议绕过（protocol-gussing）检测来测试检测方法的性能，同时使用曲率测量来测试通用检测器的效果。在这些实验中，本文构建了许多不同大小和类型（GPT，OPT等）的模型。
- (4): 在本文的实验中，参与的检测器模型通常使用小型和部分训练模型，可以更准确地检测从小型模型和大型模型中生成的文本。实验表明，是否检测器和生成器在相同的数据上训练对于检测成功并不重要。此外，OPT-125M模型检测ChatGPT生成的AUC为0.81，而来自GPT系列的更大模型GPTJ-6B的AUC为0.45，这说明了小型模型更优的结论。
- (5): 本文的研究动机是需要小型模型进行机器生成文本检测，以消除虚假信息的危险。




 ## Paper:12




1. Title: Knowledge-Enhanced Generative Pre-Training for Healthcare Language Analysis

                2. Authors: Jinhua Wu, Xiaoliang Wu, et al.

                3. Affiliation: None (The first author's affiliation is not provided in the document)

                4. Keywords: Large Language Model, Natural Language Processing, Knowledge Enhancement, Healthcare, Medical Licensing Examination

                5. URLs: None; Github: https://github.com/wujinhua90/knowledge-enhanced-nlp.git

                6. Summary: 

- (1): 本文研究背景是，传统的 ChatGPT 模型虽然在各种自然语言处理任务中具有出色的性能，但由于其微调过程缺乏灵活性，因此在需要广泛的领域专业知识和语义知识的领域中（例如健康医疗），应用受到限制。

- (2): 过去的方法有 ChatGPT 模型和传统检索模型等。这些方法存在的问题是对于特定领域的任务而言，对知识的理解不足，具有可解释性问题。在本文中，提出了一种新颖方法，可以通过语义检索和少样本学习，将前沿自然语言处理技术与医疗知识相结合。

- (3): 本文提出的研究方法是将已有的模型优化后，结合了领域知识，实现了在医疗领域的升级版 ChatGPT，实现了知识增强和少样本学习。在实验中，使用简单而有效的检索方法，提取了医疗背景知识作为语义指导，以对 ChatGPT 进行推理。同时，使用相关的医疗问题作为 ChatGPT 参考。其他方面，还实现了少样本学习并将其与领域知识相结合。

- (4): 本文在中国国家医学执照考试（CNMLE）上进行实验，通过加入领域知识和少样本学习的方法，提高了 ChatGPT 在医疗领域的性能表现。经过优化后的模型在 CNMLE-2022 上获得了70的高分（满分为100），不仅成功取得了合格资格，而且超过人类 average score(61)。我们表明了后沿的自然语言处理技术和医疗知识相结合，能够作为实用、用户友好、可调整的多才能的医疗助手。

- (5): 本文的研究动机是在医疗领域研究后沿的NLP技术并将其与特定领域的知识结合，希望使机器自动理解和处理自然语言文本的应用更加实用和灵活。同时，研究成果也为其他文本分类、推荐系统等应用领域提供了有益经验。




 ## Paper:13




1. Title: Boosting Distress Support Dialogue Responses with Motivational

Interviewing Strategy 

2. Authors: Anuradha Welivita, and Pearl Pu

3. Affiliation: École Polytechnique Fédérale de Lausanne (瑞士洛桑联邦理工学院) 

4. Keywords: AI-driven chatbots, psychotherapeutic data, Motivational Interviewing Treatment Integrity (MITI) code, online distress-support dialogues, response types 

5. Urls: 
-Paper: arXiv:2305.10195v1 [cs.CL] 17 May 2023
-Github: None 

6. Summary:

- (1): 本文研究背景为解决人们在现代生活中面临的严重心理困境的需求。由于心理治疗数据的缺乏，研究人员使用从在线同龄支持论坛中抓取的对话来训练AI驱动的聊天机器人。

- (2): 以往方法是使用在线支持论坛中的对话数据训练聊天机器人，但这些数据中包含有符合和不符合心理治疗规范的回复。所以，本研究尝试使用来自Motivational Interviewing Treatment Integrity (MITI) code的标签来识别在线心理支持对话中的符合和不符合规范的回复，并展示如何将不符合规范的回复转化为符合Motivational Interviewing (MI) 策略的回复。为此，本文构建了多个重述模型，使用Blender和GPT3进行了微调，并构建了伪平行语料库来进行自动和人工评估。 

- (3): 本文所提出的研究方法是使用来自Motivational Interviewing Treatment Integrity (MITI) code的标签来识别在线心理支持对话中的符合和不符合规范的回复，并展示如何将不符合规范的回复转化为符合Motivational Interviewing (MI) 策略的回复。

- (4): 本文所提出的方法针对在线心理支持对话中不符合规范的回复进行了转化，并展示了它们在数据量较少时的良好性能。主要任务即为构建聊天机器人并针对在线心理支持对话进行回复转化。实验结果证明，本文所提出的方法可以有效地提高频繁出现的非标准回复类型的质量。

- (5): 本研究的动机为避免在线心理支持对话数据在训练聊天机器人过程中出现潜在的风险。为了解决这一问题，研究人员尝试使用来自MITI code的标签来识别符合和不符合规范的回复，并展示如何将不符合规范的回复转化为符合MI策略的回复。




 ## Paper:14




1. Title: FastComposer: Tuning-Free Multi-Subject Image Generation with Localized Attention (使用局部注意力的无调校多主体图像生成器FastComposer)

2. Authors: Guangxuan Xiao, Tianwei Yin, William T. Freeman, Frédo Durand, Song Han

3. Affiliation: Massachusetts Institute of Technology (麻省理工学院)

4. Keywords: deeplearning, image generation, diffusion models, subject-driven generation, multi-subject generation

5. Urls: https://fastcomposer.mit.edu/ , Github: None

6. Summary:

- (1):本文研究了无调校的多主体图像生成技术；
- (2):现有技术的局限性为需要消耗大量计算资源的调整来针对不同主体进行生成，而且多主体生成时各主体特征容易混合。本文的方案补充了文本条件的通用词汇，即使用图像编码器来提取主体的嵌入向量，并将其用于文本的特征增强，从而实现对多个主体的无调校且个性化的图像生成；
- (3):本文的方案使用主体的嵌入向量作为文本条件，通过实现交叉注意力本地化监督来解决多主体生成中主体特征混合的问题，同时采取延迟主体条件来维持主体驱动的图像生成的身份和可编辑性；
- (4):本文的方案在多个具有不同风格、动作和背景的未知个体生成的图像上取得了理想的效果，并且与需要通过调整改进的方法相比，实现了300倍到2500倍的加速。文章指出，由于无需调整模型，扩大了方案的应用范围。
- (5):本文的研究动机是为了提高“FastComposer”的图像生成质量，并缓解现有图像生成方法中因至需要对新主体进行微调而导致的大量计算资源的消耗和部署效率低下的问题。




 ## Paper:15




1. Title: SeeTRUE: A Comprehensive Benchmark for Evaluating Text-Image Alignment in the Wild

2. Authors: Alon Jacovi, Vered Shwartz, Yonatan Bilu*, Yoav Goldberg

3. Affiliation: Hebrew University of Jerusalem

4. Keywords: Text-Image Alignment, Benchmark, Multimodal Pretrained Models, Visual Question Answering, Large Language Models

5. Urls: Paper url: https://arxiv.org/abs/2305.10400v1, Github: None

6. Summary:

- (1): 本文研究文本图像对齐的自动评估方法，并提出了一个全面的评估集合“SeeTRUE”，旨在评估基于图像和文本生成任务的各种数据集上的自然语言推理评估方法的泛化能力。
- (2): 本文介绍了两种确定文本和图像是否语义一致的自动方法：一是基于生成问题和视觉问答的VQ2，二是使用预训练的多模态模型进行直接微调的VNLI。与之前的评估方法相比，本文提出的方法在各种文本图像对齐任务中实现了显著提高。
- (3): 本文提出了一个基于大型语言模型的自动方法以从已对齐的图像文本对中生成与原始标题不一致的标题。在评估方法中使用了两种思路，一种是生成与文本相关的问题并通过提供的图像回答问题，确保获得正确的答案，另一种是要求多模态模型直接微调以预测图像和文本是否语义一致。
- (4): 本文实现了各种描述多种任务的数据集的评估，以确保其综合性和真实性，并展示了基于VQ2和VNLI方法的表现（包括在各种文本图像对齐数据集上进行细粒度评估，如COCA、BLIP、COCO t2i 等）。方法被证明可以定位给定文本与图像之间的特定不匹配之处，并可用于自动重新排序给定提示的生成图像候选者。
- (5): 本文的研究动机在于发现现有评估方法存在不足，考虑到多模态大型物语模型在文本到图像和图像到文本任务中的应用，对于此类技术的自动确定文本和相应图像是否语义一致需要积极的探索。




 ## Paper:16




1. Title: Self-Training Boosted Multi-Faceted Matching Network for Composed Image Retrieval

2. Authors: Haokun Wen, Xuemeng Song, Jianhua Yin, Jianlong Wu, Weili Guan, Liqiang Nie

3. Affiliation: Haokun Wen, Jianlong Wu, and Liqiang Nie are with the School of Computer Science and Technology, Harbin Institute of Technology (Shenzhen), China.

4. Keywords: Composed Image Retrieval, Multimodal Retrieval

5. Urls: Paper link: https://arxiv.org/abs/2305.09979, Github: None

6. Summary: 

- (1):本文研究的是复合图像检索（CIR）任务，解决了现有方法中忽略多维查询目标匹配因素和利用存在的潜在的未标记参考-目标图像对的问题。

- (2):现有研究中存在的问题是，无法明确有效地建模影响查询目标匹配评估的各种潜在因素，并且忽略了潜在的未标记参考-目标图像对。文中通过提出一个多面匹配网络（LIMN）和一个迭代自训练机制（LIMN+），来解决这些问题。

- (3):本文提出了muLtI-面匹配网络（LIMN）和一个迭代双自训练模式来提高LIMN的性能，充分利用半监督的潜在的未标记参考-目标图像对。LIMN由三个关键模块组成：多粒度图像/文本编码器、潜在因素定向的特征聚合和查询-目标匹配建模。

- (4):本文在三个现实世界的数据集：FashionIQ、Shoes和Birds-to-Words上进行了大量实验，表明所提出的方法明显优于现有的基线模型。

- (5):本文的研究动机是解决复合图像检索任务中存在的问题，并提出一种有效的解决方案。




 ## Paper:17




1. Title: Accelerating Transformer Inference for Translation via Parallel Decoding （通过并行解码加速转换器推理）

2. Authors: Andrea Santilli, Silvio Severino, Emilian Postolache, Valentino Maiorca, Michele Mancusi, Riccardo Marin, Emanuele Rodolà

3. Affiliation: Sapienza University of Rome（罗马第一大学）

4. Keywords: Machine Translation, Deep learning, Transformer architecture, Inference speedup, Parallel decoding algorithms

5. Urls: Paper: None, Github Code: None

6. Summary: 

- (1):本文研究的背景是机器翻译中采用Transformer架构存在的推理速度低下的问题。

- (2):以往的方法包括自回归机器翻译和Non-Autoregressive Machine Translation models(NAT)。但是它们需要修改模型或者 costly retraining，因此拓展性和适用性较差。本文通过提出新的并行解码算法，能够在不改变模型的情况下提高推理速度。

- (3):本文提出了一种将贪婪自回归解码转换为非线性方程系统的并行形式推理方法，利用Jacobi和Gauss-Seidel固定点迭代方法来加速解码。

- (4):实验表明，本文算法不仅节约了时间，还能保持较高的翻译质量。在不同的语言和模型上的实验结果都表明，本文算法相比于传统的自回归解码算法提高了38%的速度，并且在并行资源上的应用，速度提高了近两倍。

- (5):通过采用新的并行解码算法来解决现有的模型在长句子或较长文章中翻译速度慢的问题，以提升机器翻译的使用效率。




 ## Paper:18




1. Title: Knowledge-enhanced Mixed-initiative Dialogue System for Emotional Support Conversations

2. Authors: Yang Deng, Wenxuan Zhang, Yifei Yuan, Wai Lam

3. Affiliation: 香港中文大学 (The Chinese University of Hong Kong)

4. Keywords: mixed-initiative dialogue system, emotional support conversation, knowledge-enhanced, mental health knowledge graph

5. URL: arXiv:2305.10172v1 [cs.CL] (paper), Github: None

6. Summary:
- (1): 本文主要探讨在情感支持会话中建立混合主动交互式系统的必要性和挑战。
- (2): 过去的 ESC 系统通常只侧重于传达共情而不是主动帮助问题解决。而混合主动 ESC 可以在情感和解决问题之间转换主动权，但是建立混合主动 ESC 系统的必要性和问题还没有得到充分研究。本文提出了一种基于知识增强的混合主动框架 (KEMI)，用于情感支持会话，并提出四个情感支持度量指标。方法在两个 ESC 数据集上验证了优越性。 
- (3): 本文提出的 KEMI 框架通过从一个大规模的精神健康知识图谱中检索实际案例知识，生成混合主动回答。 
- (4): 本文方法在两个 ESC 数据集上实现了很好的表现和混合主动相关分析。 
- (5): 建立混合主动 ESC 系统的必要性和问题还没有得到充分研究，本文提出了一种基于知识增强的框架以解决这个问题。




 ## Paper:19




1. Title: BAD: BiAs Detection for Large Language Models in
the context of candidate screening (使用大型语言模型的偏见检测在候选人筛选中的应用)

2. Authors: Nam Ho Koh, Joseph Plata, Joyce Chai

3. Affiliation: 密歇根大学安娜堡分校,计算机科学与工程系 (University of Michigan, Ann Arbor, Department of Computer Science & Engineering)

4. Keywords: Bias detection, Large language models, Candidate screening, Automated Application Tracking Systems

5. URLs: Paper: arXiv:2305.10407v1 [cs.CL],  Github: None

6. Summary: 

- (1):本文研究的背景是应用程序追踪系统（ATS）在人才招聘和大学招生委员会中的广泛应用。ATS系统可以快速处理大量候选人申请，并以高效的方式筛选符合标准的简历，然而，这种方式也可能存在人为因素的偏见，限制 ATS 的质量和效率， 这使得使用大型语言模型(ChatGPT等)进行自动化申请筛选的系统应运而生，但它也可能存在更多的偏差和公正问题，本研究旨在确定和量化 ChatGPT 和其他 OpenAI LLMs 中的社交偏差，在候选人筛选的背景下，以演示这些模型的使用可能会在招聘过程中延续现有的偏见和不平等。

- (2):Traditionally, ATS screening process was conducted manually, creating major bottlenecks due to the quantity of applications and introducing many instances of human bias. The approach of adopting methods to current automated application screening has the potential to raise additional bias and fairness issues that need to be addressed. However, used incorrectly, it could also perpetuate existing biases and inequalities in the hiring process. This paper motivates that existing ATS systems could be enhanced by large language models (LLMs) such as ChatGPT but should be aware of the biases these models may yield.

- (3):The paper proposes a novel method, BAD, for detecting harmful biases in LLMs, which can detect biases in any system which utilizes LLMs. This method utilizes various techniques including linguistic probing and bias score calculation to detect harmful biases which are not aligned with the fair representation of the underlying dataset.

- (4):The proposed method has been tested on several datasets, and the results show that it can accurately detect harmful biases existing in the LLMs. The performance has been demonstrated using several examples, which shows that the proposed method can detect biases in the candidate screening process.

- (5):本文的动机在于提出了一种用于检测LLMs中的有害偏差的新方法，并尝试证明了使用模型中所存在的偏见问题， 积极改进现有的 ATS 系统，提高 ATS 系统的公正性和效率，最大程度上减少人为因素的干扰，使得自动化的招聘系统更加健康和有效。




 ## Paper:20




1. Title: Assessing Hidden Risks of LLMs: An Empirical Study on Robustness, Consistency, and Credibility
                (评估LLM的隐藏风险：关于健壮性、一致性和可信度的实证研究)


                2. Authors: Wentao Ye, Mingfeng Ou, Tianyi Li, Yipeng Chen, Xuetao Ma, Yifan Yanggong, Sai Wu, Jie Fu, Gang Chen, Junbo Zhao


                3. Affiliation: 浙江大学


                4. Keywords: Large Language Models, LLMs, Robustness, Consistency, Credibility


                5. Urls: Paper: https://arxiv.org/abs/2305.10235v1, Github: None


                6. Summary: 

                - (1): 近年来，大型语言模型（LLMs）因其开放式生态系统（例如API、开源模型和插件）对无数领域带来重大影响。然而，随着LLMs的广泛部署，缺乏对潜在风险全面讨论和分析的研究。

                - (2): 过去的方法存在一定问题。本文提出了自动化流程，并对包括ChatGPT、LLaMA和OPT在内的主流LLMs进行了大量查询，分别从健壮性、一致性和可信度等角度进行评估。

                - (3): 本研究方法的核心是数据原语和自动化解释器，通过不同的适应性标准对LLMs进行评估。

                - (4): 本文提出了一系列结论。即用户生成的查询输入中的微小但不可避免的误差可能会让LLMs产生意外的回答；LLMs在处理语义上相似的查询输入时缺乏一致性。另外，我们发现ChatGPT仍能够在输入极其污染的情况下产生正确的答案，虽然这证明了LLMs的强大记忆能力，但也引发了人们对于在学术发展中使用这种数据的严重关注。为此，我们提出了一个与数据集相关的新指标，粗略地确定使用此类数据进行LLM相关评估的可行性。

                - (5): 本文激励人们对LLMs的潜在风险展开研究。




 ## Paper:21




1. Title: DoReMi: Optimizing Data Mixtures Speeds Up (以最佳化數據混合為基礎的速度優化)

2. Authors: Sang Michael Xie, Hieu Pham, Xuanyi Dong, Nan Du, Hanxiao Liu, Yifeng Lu, Percy Liang, Quoc V. Le, Tengyu Ma, and Adams Wei Yu

3. Affiliation: Google (谷歌), Stanford University (斯坦福大學)

4. Keywords: language model (語言模型), pretraining data domains (預訓練數據領域), mixture proportions (混合比例), Domain Reweighting with Minimax Optimization (DoReMi), group distributionally robust optimization (Group DRO), downstream tasks (下游任務), perplexity (困惑度), GLaM dataset (GLaM數據集)

5. Urls: Paper - arXiv:2305.10429v1 [cs.CL] 17 May 2023; Github:None

6. Summary: 

(1) 本文研究的背景是語言模型中預訓練數據領域混合比例對模型性能的影響。

(2) 過去的方法主要是基於下游任務來決定數據混合比例，但這種方法需要耗費大量時間和計算資源。本文提出了一種基於群體分佈健壯優化的數據混合比例優化方法，使用一個小的代理模型來產生領域權重（混合比例），然後對數據集重新取樣，利用這些權重訓練一個更大的模型。該方法不需要下游任務的知識，能夠有效優化數據混合比例。

(3) 本文提出的研究方法是Domain Reweighting with Minimax Optimization (DoReMi)，使用群體分佈健壯優化方法來優化數據混合比例。

(4) 實驗結果顯示，使用DoReMi方法可以在不知道下游任務的情況下找到一個更好的數據混合比例，進而提升模型的性能。在The Pile數據集上，DoReMi方法能夠提高困惑度，並使得平均few-shot下游準確率提高6.5％。在GLaM數據集上，DoReMi甚至可以達到使用下游任務調整的數據混合比例所得到的性能。

(5) 本研究的動機是優化語言模型中的數據混合比例，提高模型的性能。本文提出的方法DoReMi能夠有效優化數據混合比例，提高模型的性能，並且不需要知道下游任務的信息。




 ## Paper:22




1. Title: Probing the Role of Positional Information in Vision-Language Models 

2. Authors: Philipp J. Rösch and Jindˇrich Libovický 

3. Affiliation:  Philipp J. Rösch is affiliated with Institute for Distributed Intelligent Systems, Bundeswehr University Munich, Germany 

4. Keywords: deeplearning, ML, NLP, CV, Vision-Language Models, Positional Information 

5. Urls: arXiv:2305.10046v1, Github: None 

6. Summary:

- (1): 本文探究了在视觉语言模型中位置信息的作用；
- (2): 本文介绍了以往的方法、存在的问题，以及新方法的动机；
- (3): 本文提出了两种预训练策略并探究了位置信息的方法，包括位置信息的预训练和交叉模态匹配的对比学习；
- (4): 本文在视觉问答任务中测试了新方法的性能，结果表明虽然方法已经改进模型的性质，但对下游性能的影响微乎其微；
- (5): 本文的研究动机是要解决像视觉问答这样的跨模态任务中位置信息的局限性。




 ## Paper:23




1. Title: MemoryBank: Enhancing Large Language Models
2. Authors: Wanjun Zhong, Lianghong Guo, Qiqi Gao, Yanlin Wang
3. Affiliation: 中山大学（Sun Yat-Sen University）
4. Keywords: Large Language Models, Long-term Memory, Memory Mechanism
5. Urls: arXiv:2305.10250v1 [cs.CL] 17 May 2023
   Github: https://github.com/zhongwanjun/MemoryBank-SiliconFriend
6. Summary:

- (1): 近年来，大语言模型（LLMs）的革命性进展在人工智能系统中广泛应用。然而，这些模型缺乏长期记忆机制，进一步体现了其存在的短缺和限制，无法满足对持续交互性的要求。 
- (2): 针对过去方法的缺陷，本文提出了MemoryBank，一种新的记忆机制，提供了持续精确地掌握信息的能力，能适应用户的个性变化，且其记忆——以时间和相对重要性为基础——使其更具人类化。 
- (3): MemoryBank能够更新和变化，能够整合来自上一次交互的信息，并支持ChatGPT和ChatGLM等站内外模型。
- (4): 本文通过一个长期人工智能伴侣情境中的基于LLM的聊天机器人SiliconFriend的案例，证明了MemoryBank的有效性。得到的实验结果表明，其具备带有同情心的反应、记忆相关人事以及了解用户性格的能力。
- (5): 本文的研究目的是改进LLM模型的短板，使其更具有人类记忆机制，进一步增强其在人工智能领域的应用。




 ## Paper:24




1. Title: Machine-Made Media: Monitoring the Mobilization of Machine-Generated Articles on Misinformation and Mainstream News Websites
             
2. Authors: Hans W. A. Hanley and Zakir Durumeric

3. Affiliation: Stanford University (斯坦福大学)

4. Keywords: deeplearning, large language models (LLMs), synthetic news articles, misinformation, mainstream news websites, DeBERTa-based model, social media, Reddit 

5. Urls: 
  - Paper: https://arxiv.org/abs/2305.09820v1 
  - Github: None

6. Summary: 

- (1): 本文研究机器生成的文章在虚假信息和主流新闻网站上的使用状况。

- (2): 过去的方法无法处理大规模的生成式语言模型如ChatGPT，因为它们可能会产生错误和误导性的文章。作者提出了一种基于DeBERTa的合成新闻检测器，用于分类来自3074个虚假信息和主流新闻网站的1291万篇文章。 

- (3): 作者提出了一种深度学习模型来检测英语合成新闻文章，同时使用大量的训练数据和对抗性数据进行训练。然后，作者根据新闻网站上的文章，测量了机器生成的文章在主流/可靠和虚假信息/不可靠新闻平台上的普及程度。

- (4): 在研究过程中，作者发现主流新闻网站上的合成文章相对数量增加了79.4%（2022年1月至2023年4月，从9.4%到16.8%），而在虚假信息网站上的增加量为342%（2022年1月3.6％到2023年4月16.2%）。此外，作者还发现，社交媒体用户与合成文章的交互量也有所上升。

- (5): 本文的动机是，众多虚假信息网站开始大量生产虚假信息文章，而对此的监测和预防是非常必要的，所提出的方法可以检测合成文章，预防虚假信息传播。




 ## Paper:25




1. Title: Chain-of-Symbol Prompting Elicits Planning (用符号链提示激发计划)
                
                2. Authors: Hanxu Hu, Hongyuan Lu, Huajian Zhang, Wai Lam, Yue Zhang (胡瀚旭，卢洪远，张华坚，林炜，张岳)
                
                3. Affiliation: 西湖大学 (Westlake University)
                
                4. Keywords: large language models, NLP, planning, chain-of-symbol prompting (大型语言模型，自然语言处理，计划，符号链提示)
                
                5. Urls: 
                Paper: https://arxiv.org/abs/2305.10276v1
                Github: None
                
                6. Summary: 
                
                - (1): 本文旨在探究大型语言模型在复杂计划任务中的表现，其需要理解通过自然语言模拟的虚拟空间环境并相应地产生文本。在此基础上，提出了一项基准测试 Natural Language Planning (NLP)，包括 Brick World、NLVR-based Manipulations 和 Natural Language Navigation 三个新颖任务。
                
                - (2): 本文发现，当前流行的大型语言模型 ChatGPT 等在复杂规划方面仍然缺乏能力。这引出一个问题：大型语言模型是否对自然语言中描述的环境有了良好的理解，或者其他替代方案如符号表示更简明，因此更容易被大型语言模型理解使用？为了解决这个问题，本文提出了一种名为 COS（Chain-of-Symbol Prompting，符号链提示）的新方法，在链式中间思考步骤中使用压缩的符号空间表示来表示复杂环境。COS 易于使用，不需要对大型语言模型进行额外的培训。广泛的实验表明，COS 明显优于 ChatGPT 和 InstructGPT 上的 CoT（Chain-of-thought Prompting，思维链提示），在所有三个规划任务中更少的令牌就能获得更好的性能，性能增益强，例如 ChatGPT 在 Brick World 上的准确度从 31.8％ 提升到 92.6%（增益60.8%）。COS 还明显减少了提示中的令牌数量，例如在 Brick World 的演示中，COS 只使用了 139 个令牌而原来的 CoT 需要 407 个，降低了令牌的数量高达 65.8%。
  
                - (3): COS, 符号链提示方法, 用于链式中间步骤的压缩符号空间表示。不需要大型语言模型进行额外的培训，易于使用。
                
                - (4): 本文使用自然语言计划（NLP）基准测试，从 Brick World，NLVR-based Manipulations，Natural Language Navigation 三个新颖任务中验证了 COS 方法的有效性。实验结果表明，COS 方法可以明显地优于 CoT 方法，同时减少了提示中的令牌数量，同时也展示了大型语言模型中计划制定任务方面的巨大进步潜力。
                
                - (5): 本文的动机是探究大型语言模型在计划制定任务方面的现状以及探索能否使用符号链提示方法来提升其计划任务的性能。由于计划制定是人工智能推理的重要部分，因此研究相应的算法具有现实意义和广泛的应用前景。




 ## Paper:26




1. Title: Using a Large Language Model to Control Speaking Style for Expressive TTS （使用大型语言模型控制表达式TTS的说话风格）

2. Authors: Atli Sigurgeirsson, Simon King

3. Affiliation: The Centre for Speech Technology Research （语音技术研究中心）

4. Keywords: speech synthesis, style modelling, prosody （语音合成，风格建模，韵律）

5. Urls: paper, Github

6. Summary: 

- (1):本文主要研究如何利用大型语言模型通过控制说话风格，提高表达式TTS模型的表现。

- (2):过去的方法主要是基于参考TTS模型构建模型，或通过上下文词嵌入来预测韵律，但这些方法需要参考音频或者只能在特定输入上有效。本文的方法即大型语言模型，不需要参考音频，而可以通过任意的任务描述来完成。 

- (3):本文的方法是在非表达式语音音频语料上训练TTS模型，然后使用“ InstructGPT”语言模型来预测韵律的调整值，最后将这些参数输入到 TTS模型中生成语音。

- (4):本文在两个实验中进行测试，一个描述目标说话风格，另一个是给出前一句话来控制说话风格。与基线模型相比，本文提出的方法在 49.9% 的情况下被认为最合适，而基线方法只有31.0%。结果表明，该方法可以有效地通过语言模型来控制表达式 TTS的生成表现。

- (5):本文的动机是解决 Text-To-Speech 中缺乏表达力和语音风格控制的问题，并提出了一个利用大型语言模型控制韵律的方法。




 ## Paper:27




1. Title: Pyramid Diffusion Models For Low-light Image Enhancement (低光图像增强的金字塔扩散模型)
                
                2. Authors: Dewei Zhou, Zongxin Yang, Yi Yang
                
                3. Affiliation: Zhejiang University (浙江大学)
                
                4. Keywords: low-light image enhancement, diffusion models, pyramid diffusion, noise reduction
                
                5. Urls: Paper url: arXiv:2305.10028v1 [cs.CV] 17 May 2023 
                Github code URL: https://github.com/limuloo/PyDIff.git
                
                6. Summary: 
                
                - (1): 本文旨在提出一个有效的低光图像增强模型。
 
                - (2): 过去的方法包括使用神经网络的方法和一些通过分解亮度和反射分量来提高图像质量的方法。过去方法的问题在于无法恢复图像中的细节而且会丢失图像细节。本文提出使用扩散模型来提高图像的质量，但是之前的扩散模型存在速度限制和全局降格的问题，本文也解决了这些问题。


                - (3): 本文提出了一个金字塔扩散模型，以实现低光图像增强目的。模型使用新颖的金字塔扩散方法在金字塔分辨率样式下执行采样，以逐步提高亮度分辨率。金字塔扩散使PyDiff比香草扩散模型快得多，并且不会引入性能降低。此外，PyDiff使用全局校正器以缓解在反向过程中可能出现的全局降格，从而大大提高了性能，并使扩散模型的训练更加容易，而且计算机的消耗也较少。

                - (4): PyDiff在多个基准测试中的表现均优于之前的方法，并且该模型能够很好地泛化到未见过的噪音和照明分布。通过广泛的实验证明了PyDiff模型的可靠性和有效性。

                - (5): 本文的研究动机在于提出一个针对低光图像增强的有效模型。



