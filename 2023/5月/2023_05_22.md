# 2023_05_22 Arxiv更新论文汇总
今天共有38篇论文


 ## Paper:1




1. Title: Towards Collaborative Plan Acquisition
合作计划获取：通过理论模型在情境对话中实施

2. Authors: Cristian-Paul Bara, Ziqiao Ma, Yingzhuo Yu, Julie Shah, Joyce Chai

3. Affiliation: Cristian-Paul Bara, Ziqiao Ma, Yingzhuo Yu, Joyce Chai - University of Michigan

4. Keywords: Collaborative planning, situated dialogue, theory of mind modeling, missing knowledge prediction, joint task completion.

5. Urls: 
- Paper: arXiv:2305.11271v1  [cs.AI]  18 May 2023
- Github: None

6. Summary:

- (1): 该论文研究如何在机器人与人类的协作中，通过情景对话获取完整的计划，达到共同完成任务的目标。

- (2): 过去的方法需要人工编写完整计划或运用规则，且很难与人类合作完成任务。而本文采用理论模型实现排除人与机器人之间存在的知识瓶颈，提出了一种预测缺失任务知识的方法。此方法通过建模对话者的动作和心态，来预测自己和伙伴的缺失任务知识。

- (3): 本文采用MindCraft这个在3D virtual world进行对话协作的benchmark，通过fine-grained dialogue moves对对话模型进行训练和预测。

- (4): 本文的方法能更好地预测伙伴缺失的任务知识，其表现也更稳定。并且在对称性的合作任务中，另一个伙伴的缺失任务知识比自己缺失更易于预测。实验结果为今后的机器学习，尤其是在合作任务中的机器人协作，提供了有益的启示。

- (5): 本文的动机在于，如何提高人机协作的效率和效果，并为未来的人机交互提供指导方法。 




 ## Paper:2




1. Title: Evaluating task understanding through multilingual consistency (通过多语言一致性评估任务理解)

2. Authors: Xenia Ohmer, Elia Bruni, Dieuwke Hupkes

3. Affiliation: Ω Osnabrück University (奥斯纳布吕克大学), ∞ FAIR 

4. Keywords: Deep learning, natural language processing, multilingual consistency, benchmarking, language models

5. Urls: arXiv:2305.11662v1, Github: None 

6. Summary:

- (1): 本文的研究背景是随着大型语言模型(LLMs)能力的不断增长，如何创建未来可靠的测试集来评估它们对于一致的理解变得越来越具有挑战性。

- (2): 过去的方法通常评估自然语言理解的能力，如常识推理、探测项等。但由于评估数据的不断添加和模型的更新，如何评估这些模型是否真正理解了它们所说的话变得越来越困难。因此，本文提出了一种基于多语言一致性的评估模型方法以及该方法的可行性分析。

- (3): 本文提出了一种全新的方法来评估LLMs的任务或世界观。该方法将正确的世界理解定义为相同意义的不同意见之间的一致性，并通过评估模型自身生成的多个语义方面的一致性来衡量其是否理解任务。文章通过在不同语言之间进行多语言一致性测试，展示了该方法的可行性，并以ChatGPT为案例进行了实验验证。

- (4): 本文在两个不同任务和三种不同语言上评估ChatGPT的多语言一致性，结果表明其多语言一致性仍然不足，其任务和世界理解因此不能独立于语言。作者认为，他们的方法为未来基准测试工作提供了廉价且易于扩展的方法。但是，本文并没有提供传统评估方法的可比性分析。

- (5): 本文的动机在于解决现有评估方法的局限性，提出了一种新的方法评估LLMs的任务和世界理解，同时为多语言一致性研究提出了有趣的视角。




 ## Paper:3




1. Title: Efficient Cross-Lingual Transfer for Chinese Stable Diffusion  
(中文翻译：高效的跨语言转移方法用于中文稳定扩散) 

2. Authors: Jinyi Hu, Xu Han, Xiaoyuan Yi, Yutong Chen, Wenhao Li, Zhiyuan Liu, Maosong Sun  

3. Affiliation: 
Jinyi Hu, Xu Han, Yutong Chen, Wenhao Li, Zhiyuan Liu and Maosong Sun: 清华大学计算机科学与技术系，北京，中国； 北京国家信息科学技术研究中心； Tsinghua-Berkeley Shenzhen Institute (清华大学-伯克利深圳学院)；中国语言与知识工程国家重点实验室
Xiaoyuan Yi: 微软亚洲研究院

4. Keywords: 
deeplearning, NLP, computer vision, text-to-image synthesis, cross-lingual transfer 


5. Urls: 
Paper: https://arxiv.org/abs/2305.11540 
Github: None


6. Summary:
- (1): 本篇文章主要研究跨语言转移方法在中文稳定扩散（Stable Diffusion）上的应用。
- (2): 先前的中文稳定扩散方法基于稳定扩散的源代码训练中文模型很难处理原有文本到图像的速度问题。本文提出的跨语言转移方法能够将英文中稳定扩散模型的效果转移到中文领域来更高效地生成图像。具体来说，该方法使用英文IAP模型进行训练，然后训练一个中文模型，该模型的文本编码器与英文模型的文本编码器进行交互，通过图像对齐技术，来使用英文模型已学习到的信息来帮助中文模型更好地处理原有文本到图像的速度问题。本文提出的方法的动机充分。
- (3): 本文提出的跨语言转移方法借鉴了 Contrastive Language–Image Pretraining（CLIP）模型的思想，在保证训练关键参数固定的前提下，优化中文文本编码器的参数，将中文语义空间与英文相对齐并且最小化注意特征的距离以确保语义的相似性。
- (4): 通过实验，本文提出的跨语言转移方法在处理稳定扩散问题时表现出非常好的性能，不仅节省了大量的计算资源，而且有效减少了英文到中文文本到图像的转换时间。
- (5): 本文的动机是为了让稳定扩散模型能够更加方便地应用在中文领域，并且节省大量计算资源和时间。




 ## Paper:4




1. Title: Plug-and-Play Medical Dialogue System (插拔式医疗对话系统)
2. Authors: Chengfeng Dou, Zhi Jin, Wenping Jiao, Haiyan Zhao, Zhenwei Tao, Yongqiang Zhao
3. Affiliation: School of Computer Science, Peking University (北京大学计算机科学学院)
4. Keywords: medical dialogue generation, Large Language Models (LLMs), in-context learning, dialogue strategies, medical conversation tasks
5. URLs: Paper - arXiv:2305.11508v1 [cs.CL]; Github - None
6. Summary: 
- (1): 本文研究插拔式医疗对话系统，旨在解决医疗对话生成中的精确性问题以降低诊断费用和提高医疗效率。
- (2): 过去的方法包括注入调用知识和微调模型等，但精度仍有限且贵损。本文提出了一种以 Large Language Models (LLMs) 为基础、利用上下文学习的插拔式医疗对话系统，能够准确地进行诊断和咨询。本文的方法动机充分。
- (3): 本文提出了两个模块，即提示生成 (PG) 和响应排序 (RR)，用于改善 LLMS 的对话效果。PG 模块能够捕捉全局和局部的上下文信息，并针对病人症状适当地选择提示；RR 模块通过精细调校的语言模型 (SLMs) 作为响应过滤器，选择合适并由 LLMs 产生的响应。
- (4): 本文的方法在三个医疗对话数据集上进行了实验，包括自动评估和手动评估，证明了其在医疗对话任务中的有效性。本文的方法在 intent 和医疗实体匹配方面，表现优于微调和启发式方法。
- (5): 本文的研究动机是要通过揭示 LLMs 的潜力和应用，提高医疗对话生成的准确性和效率。




 ## Paper:5




1. Title: RECIPE: How to Integrate ChatGPT into EFL Writing Education

2. Authors: Jieun Han, Haneul Yoo, Yoonsu Kim, Junho Myung, Minsun Kim, Hyunseung Lim, Juho Kim, Tak Yeon Lee, Hwajung Hong, So-Yeon Ahn, Alice Oh 

3. Affiliation: KAIST (Korea Advanced Institute of Science and Technology) / 韩国科技院大学

4. Keywords: generative AI, ChatGPT, EFL education, writing, interactive platform 

5. Urls: https://doi.org/10.1145/3573051.3596200, Github: None

6. Summary: 

- (1): 本文旨在探讨ChatGPT在使用英语为外语的写作教育中的应用，此前已有相关工作，但尚未得到充分验证。

- (2): 以往工作中，类似的基于生成式AI模型的语言生成任务的研究都仅限于阅读理解和语言生成的领域，且大多数是独立于一对一教学的。然而，这些研究仅关注了自然语言生成，在学习过程中缺乏互动性和反馈。此文提出了一种集成ChatGPT的旨在提高英语写作能力的交互式平台，该平台在小规模的实验中得到了可观的表现。

- (3): 文章提出了一个交互式写作平台“RECIPE”，其中包括两种有效的互动形式以增强学生与ChatGPT对话互动的流畅性：一种隐藏式的互动模式，主要让ChatGPT作为一名EFL老师；另一种开放式的互动模式允许学生自由发挥来与ChatGPT进行对话。实验总共有213名使用英语为外语的文科本科生或研究生和7名导师参与。文章总结了学生每次使用RECIPE的互动以及他们对平台的意见和反馈。此外，还与6名学生和一名学生的口语老师进行了重点小组访谈和个体访谈，以探索AI模型在EFL教育中的运用与优化机会。

- (4): 本文使用了213个EFL语言学习者的作品来评估chatGPT。 研究发现，与未使用ChatGPT的单人写作环境相比，在基于ChatGPT平台下的文学创作和互动性的创作环境中，学生的自我学习能力和积极性都有所提高。此平台不仅促进了学生与ChatGPT之间自信的互动，还为教师提供了关于学生评论和反馈的有用信息。

- (5): 本文的主要动机是要改进目前普遍存在的低效但高成本的一对一教学模式。 通过运用一种新的交互式平台，可增强使用英语为外语的学生对写作的学习信心和参与度，减轻人力成本，提高写作教学效果。




 ## Paper:6




1. Title: Graphologue: Exploring Large Language Model Responses (Graphologue: 探索大型语言模型响应)

2. Authors: Peiling Jiang, Jude Rayan, Steven P. Dow, Haijun Xia

3. Affiliation:  作者Peiling Jiang归属于“University of California San Diego” (加利福尼亚大学圣迭戈分校) 

4. Keywords: Large Language Model, Graphical User Interface (大型语言模型，图形用户界面)

5. Url: https://arxiv.org/abs/2305.11473 

6. Summary:
- (1): 本文旨在探究大型语言模型联络界面的缺陷及其解决方案。近年来，由于其易于访问和在多个应用领域表现出的非凡智能，大型语言模型（LLMs）变得越来越流行。然而，LLMs通过以文本为基础的媒介对话的方式进行交互，这在支持复杂信息任务方面存在显著限制。

- (2): 过去的方法主要依赖于以文本为基础的媒介对话，这会导致机器生成的响应冗长繁琐，难以快速理解和与之灵活交互。本文提出了Graphologue，一个交互式系统，将LLMs生成的文本响应转换为图形化的图表，从而更好地支持信息搜索和问答任务。Graphologue采用新颖的提示策略和界面设计，从LLM响应中提取实体和关系，并实时构建节点-链接图。此外，用户可以与图表交互，灵活地调整图形呈现，并提交特定上下文的提示以获取更多信息。通过利用图表，Graphologue实现了人与LLMs之间的图形、非线性对话，促进了信息探索、组织和理解。

- (3): 本文提出的方法，即Graphologue，是一种将LLMs生成的文本响应转换为图形化图表的交互式系统。Graphologue利用新颖的提示策略和界面设计，从LLM响应中提取实体和关系，并实时构建节点-链接图。此外，用户可以与图表交互，灵活地调整图形呈现，并提交特定上下文的提示以获取更多信息。

- (4): 本文所提出的方法在信息搜索和问答任务上具有显著的优势，能够有效地支持信息探索、组织和理解。通过对十名参与者进行的形态研究，得出Graphologue系统能够显著提高用户对LLM响应的理解和交互能力，同时提高了信息搜索和问答任务的效率。

- (5): 本文的研究动机在于探究大型语言模型联络界面的缺陷及其解决方案，并提出了一种新颖的交互式系统，Graphologue，用于将LLMs生成的文本响应转换为图形化的图表，从而更好地支持信息搜索和问答任务。




 ## Paper:7




1. Title: Information Screening whilst Exploiting! (中文翻译：同时利用信息筛选)

2. Authors: Shengqiong Wu, Hao Fei, Yixin Cao, Lidong Bing, Tat-Seng Chua

3. Affiliation: 国立新加坡大学计算机学院（National University of Singapore）

4. Keywords: Multimodal Relation Extraction, Feature Denoising, Multimodal Topic Modeling, NLP, CV, ML

5. Urls: Paper: None, Github: https://github.com/ChocoWu/MRE-ISE

6. Summary: 

- (1): 本文研究的背景是多模态关系抽取领域中的两个挑战：内部信息过度利用和外部信息被低效利用。

- (2): 过去的研究方法无法充分地利用来自两个信息视角的特征源，且不完全利用图像信息和文本信息在关系推理中的作用。文章的方法具有较好的动机。

- (3): 文章提出了一个新的框架，它同时实现了内部信息筛选和外部信息利用。首先，用视觉和文本场景图表示输入图像和文本的细粒度语义结构，然后将它们融合成一个统一的跨模态图（CMG）。基于CMG，我们使用图信息瓶颈原理进行结构细化，主动去噪不重要的特征。接下来，我们对输入的图像和文本进行主题建模，将潜在的多模态主题特征纳入来丰富上下文。

- (4): 该方法在基准MRE数据集上表现优越，目前已发表的最佳模型性能都被超越。实验结果表明，文章的方法对多模态关系抽取任务有巨大的潜力。

- (5): 本文的研究动机在于解决多模态信息的有效利用问题，提高多模态关系抽取任务的性能。




 ## Paper:8




1. Title: Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning with LLMs

2. Authors: Pranjal Aggarwal, Aman Madaan, Yiming Yang, Mausam

3. Affiliation: 印度德里印度理工学院计算机科学系 (Department of Computer Science, Indian Institute of Technology, Delhi)

4. Keywords: large language models, self-consistency, majority voting, adaptive-consistency, model-agnostic, stopping criterion

5. URLs: 
Paper: https://arxiv.org/abs/2305.11860
Github: None

6. Summary:

- (1): 本文研究了如何提高大型语言模型的输出正确性问题。
 
- (2): 过去的方法是使用 Self-Consistency 技术，即对语言模型进行多次采样，输出出现次数最多的结果。但是现有的 Self-Consistency 技术每个问题都要绘制固定数量的样本，且采样时间和计算成本随着模型大小和复杂度的增加而增加，导致性能受到重大挑战。因此，本文引入了一种自适应一致性的多数投票方法，通过基于已绘制样本的一致性量来非均匀地分配可用预算，来动态调整每个问题的样本数量。Adaptive-Consistency 是一种成本有效的、模型通用（model-agnostic）的方法，其轻量级的停止准则可以动态调整样本数量，实验显示 Adaptive-Consistency 最多可以将样本预算降低 6.0 倍，而平均精度下降少于 0.1%。
 
- (3): 本文提出的 Adaptive-Consistency 模型利用 Dirichlet 分布对唯一样本之间的概率分布进行建模，能够量化大多数元素的领先优势和对其他元素的影响，从而能够判断是否需要绘制更多的样本。这种自适应的投票方法不需要训练，适用于所有预训练的语言模型，平衡了计算成本和性能。
  
- (4): 本文在13个数据集和两种不同规模的 LLMs 上进行了实验，表明 Adaptive-Consistency 可以以更少的样本数量来获得与 Self-Consistency 相当的性能，与固定预算方法相比，Adaptive-Consistency 模型能够在线真正动态调整所需的样本数量，从而提高计算效率。
 
- (5): 本文的研究动机是提高大型语言模型的输出正确性，通过自适应一致性多数投票技术来减少样本数量和计算成本。




 ## Paper:9




1. Title: Text2NeRF: Text-Driven 3D Scene Generation with Neural Radiance Fields (基于NeRF和文本的3D场景生成)

2. Authors: Jingbo Zhang, Xiaoyu Li, Ziyu Wan, Can Wang, and Jing Liao

3. Affiliation: Jingbo Zhang, Ziyu Wan, Can Wang and Jing Liao are with the Department of Computer Science, City University of Hong Kong. Xiaoyu Li is with Tencent AI Lab. (张静波、万子昱、王灿、廖劲为香港城市大学计算机系, 李晓宇为腾讯AI实验室)

4. Keywords: Text-to-3D, NeRF, 3D scene generation, scene inpainting, depth alignment

5. Urls: Paper URL: https://arxiv.org/abs/2305.11588v1, Github: None

6. Summary: 

- (1):本文研究背景是文本驱动的3D场景生成。

- (2):先前的方法,例如CLIP-Mesh, Dream Fields, DreamFusion,和Magic3D等，需要大量配对的数据或使用预训练的文本图像模型作为显式先验，这使3D场景的生成依赖于图片的高级语义控制而忽略了低级细节的特点。 本文提出了一种基于NeRF的文本驱动3D场景生成框架，该框架使用将文本相关图像用作内容先验，并利用单目深度估计方法提供几何先验。本文方法的最大特点在于无需其他训练数据就可以生成多视角一致，多样的3D场景。

- (3):本文提出了一种名为PIU的逐步补洞和更新策略，以保证不同视角之间的纹理和几何一致性，并采用NeRF作为3D表示方法，并利用先前提到的文本图像扩散模型作为数据先验。内容和几何先验均被利用于优化NeRF模型。

- (4):该方法在多个数据集中进行的实验展示了其相比于现有方法的更高性能，能够生成真实感大，多视角一致和多样化的3D场景，展现了其高效性和实用性。

- (5):以往的3D场景生成过程多以图片为基础，而本文通过借鉴预训练文本图像模型，提高了对3D场景的掌控性，实现了基于单一文本描述的3D场景生成框架。




 ## Paper:10




1. Title: MD3: The Multi-Dialect Dataset of Dialogues

2. Authors: Jacob Eisenstein, Vinodkumar Prabhakaran, Clara Rivera, Dorottya Demszky, and Devyani Sharma

3. Affiliation: Google Research (第一作者)

4. Keywords: dialect, world Englishes, dialogue

5. URLs: 
- Paper: https://arxiv.org/abs/2305.11355v1
- Dataset: https://www.kaggle.com/datasets/jacobeis99/md3en

6. Summary: 
- (1): 本文主要研究方言的语音处理，介绍了一个包含印度、尼日利亚和美国英语的对话数据集，用于跨方言的比较研究。
- (2): 过去的方法主要集中在脚本化的对话或开放式对话，缺少明确的任务目标和跨方言比较研究，而本文利用信息共享任务的方式搜集数据，更贴近真实场景，且可以避免任务结构对方言特征的压抑，因此方法具有很高的现实意义和启发性。
- (3): 本文提出了一个新的对话数据集，并通过猜词游戏的方式，收集了三种全球英语时区的对话。通过清晰定义logo目标语音任务，同时又不限制对话的词汇或语法结构，可以更有效地评估自然语音处理系统在各种方言上的鲁棒性。
- (4): 实验结果表明，该数据集在句法和话语标记的使用方面有显著的差异性。本文的方法不仅可以用来检测方言特征的鲁棒性，还可作为全球英语研究的一个基准测试集。
- (5): 本文旨在推动方言语音处理及其在提高全球语言技术方面的应用研究。




 ## Paper:11




1. Title: Reducing Sequence Length by Predicting Edit Operations with Large Language Models
降低序列长度：使用大型语言模型预测编辑操作

2. Authors: Masahiro Kaneko, Naoaki Okazaki
作者： Masahiro Kaneko, Naoaki Okazaki

3. Affiliation: Tokyo Institute of Technology
机构：东京工业大学

4. Keywords: Large Language Models, local sequence transduction tasks, edit operations, instruction tuning, downstream tasks
关键词：大型语言模型、局部序列转换任务，编辑操作，指令调整，下游任务

5. Urls: 
论文链接:https://arxiv.org/abs/2305.11862v1
GitHub链接: None

6. Summary:
- (1) 本文研究背景是针对大型语言模型在处理局部序列转换任务时存在的目标序列过长、计算量过大问题。
- (2) 过去的方法是直接生成全部目标预测结果，即使有大量的无需修改的标记，这样的方法既低效又可能导致预测失误影响后续预测，本文提出的方法是预测源文本中的一组编辑操作来减少目标序列的长度，从而降低了计算量。本文的方法是有前瞻性的。
- (3) 本文提出使用指令调整，并在编辑操作的监督数据上进行指令调整，以降低目标序列的长度并减少计算时间。 
- (4) 本文的方法在四个任务中（重述任务、正式风格转移任务、语法错误纠正任务和文本简化任务）取得了与基线相当的性能，尽管目标文本长度减少了最多21％，同时指令调整与该方法在四个任务中都取得了最新的最佳表现。 
- (5) 本文的动机是尝试应用大型语言模型在局部序列转换任务中降低目标序列长度和计算时间，同时保持高精度。




 ## Paper:12




1. Title: Towards Human-AI Collaborative Urban Science Research Enabled by Pre-trained Large Language Models

                2. Authors: Jiayi Fu, Haoying Han, Xing Su, and Chao Fan

                3. Affiliation: College of Civil Engineering and Architecture, Zhejiang University, Hangzhou, 310058, China

                4. Keywords: Urban science, pre-trained large language models, opportunities, challenges

                5. Urls: Paper: https://www.sciencedirect.com/science/article/pii/S0040162523008494 , Github: None

                6. Summary:

                - (1): 本篇论文主要是探讨预训练大型语言模型（PLMs）在城市科学研究中的应用前景和挑战。

                - (2): 目前在城市科学研究中，传统方法无法解决大数据量、复杂性、较弱的语义理解问题等，而PLMs能够有效地应对这些问题。然而，该技术也存在技术限制、安全问题、隐私问题和社会偏见等严重威胁。

                - (3): 本研究基于ChatGPT模型探讨了PLMs在城市制度、城市空间、城市信息和公民行为研究中的七个潜在应用。同时，从技术和社会两个维度讨论了PLMs在城市科学研究中存在的挑战。最后，我们提出




 ## Paper:13




1. Title: Enhancing Vision-Language Pre-Training with Jointly Learned Questioner and Dense Captioner (基于联合学习的问题生成器和密集字幕优化视觉语言预训练)

2. Authors: Zikang Liu, Sihan Chen, Longteng Guo, Handong Li, Xingjian He, Jing Liu

3. Affiliation: Institute of Automation, Chinese Academy of Sciences (中国科学院自动化研究所)

4. Keywords: vision-language pre-training, pre-training data generation, natural language processing, computer vision

5. URLs: Paper: https://arxiv.org/abs/2305.11769v1, Github: None

6. Summary:

- (1): 本文研究的背景是视觉语言预训练的应用，并且认为现有的大多数方法对于视觉和语言模态之间的精细特征对齐不够关注。 

- (2): 目前已有的方法主要基于从互联网收集的图像文本配对数据集进行预训练，但这些方法忽略了需要深入理解图像和语言表达之间的微妙差异。同时，通常由于手动数据收集和标记工作的限制，公开的VQA和密集字幕数据集规模有限。本文提出的方法可以通过联合学习得到问题生成器和密集字幕来生成和过滤大规模的VQA和密集字幕数据集。这个方法可以应用于Conceptual Caption（CC3M）数据集，生成一个新的数据集CC3M-QA-DC。 

- (3): 本文提出的方法是Joint QA and DC Generation (JADE)，它利用预训练的多模态模型和易于爬取的图像文本对自动生成和筛选大规模的VQA和密集字幕数据集。 

- (4): 实验结果表明，在多任务训练中使用本文提出的CC3M-QA-DC数据集，可以在无论是哪一种骨干网络下的下游任务上提高其性能。JADE可以自动生成大量的可靠VQA和密集字幕样本，以及可以在一些数据较多的任务中等效地利用更少的数据来提高性能。

- (5): 本文旨在提出一种有效的方法，旨在获得图像和文本模态之间更精细的特征对齐，并且可以快速生成VQA和密集字幕数据集来提高视觉语言预训练性能。




 ## Paper:14




1. Title: Cinematic Mindscapes: High-quality Video（电影般的心理景观：高质量视频）
2. Authors: Zijiao Chen, Jiaxin Qing, Juan Helen Zhou 
3. Affiliation: National University of Singapore（新加坡国立大学）(Zijiao Chen), The Chinese University of Hong Kong（香港中文大学）(Jiaxin Qing), National University of Singapore（新加坡国立大学）(Juan Helen Zhou)
4. Keywords: Reconstruction, video, deep learning, fMRI 
5. Urls: https://arxiv.org/abs/2305.11675 (paper), Github: None
6. Summary:

- (1): 本文旨在通过脑活动数据的连续记录，从大脑活动中重建人类视觉，从而了解人类的认知过程。最近的研究已经可以从无创脑记录中恢复静态图像，但恢复视频尚存在挑战。
- (2): 本文提出的MinD-Video通过“面具”脑建模，多模态对比学习和时空注意力的组合，以及与网络时间膨胀结合的增强扩散模型协同训练，从连续的fMRI数据中逐步学习时空信息，使用对抗指导重建任意帧速率的高质量视频。与最先进的方法相比，我们的方法在语义分类任务和结构相似性指数（SSIM）方面的平均准确率达到了85%和0.19，分别超过了之前的最优结果45%。此外，我们还证明了我们的模型是生物可行和可解释的，并反映了已知的生理过程。
- (3): MinD-Video通过三个步骤：masked brain modeling，multimodal contrastive learning，co-training with an augmented Stable Diffusion model，逐步学习时空信息，并使用对抗指导重建视频。同时，作者使用了各种方法来验证他们的模型是否生物合理和可解释。
- (4): MinD-Video在语义分类任务和结构相似性指数（SSIM）方面的平均准确率分别达到了85%和0.19，优于之前的方法。这表明MinD-Video可以高质量地重建视频，并且可以用于研究人类视觉过程。 
- (5): 了解活跃大脑区域和它们如何在认知任务中相互作用的复杂性是神经科学的一个基本挑战。本文的目的是使用深度学习技术从fMRI扫描中重建动态视觉体验。




 ## Paper:15









 ## Paper:16




1. Title: LLM Itself Can Read and Generate CXR Images

2. Authors: Suhyeon Lee, Won Jun Kim, and Jong Chul Ye

3. Affiliation: 韩国科技院(KAIST)

4. Keywords: deeplearning, CXR images, multimodal tasks, large language models, VQ-GAN framework

5. Urls: arXiv:2305.11490v1 [cs.CV] 19 May 2023

6. Summary:

- (1): 本文要解决的问题是如何使用大型语言模型将自然语言与图像相结合，提供一种新的方法，使预训练的LLM能够像阅读文本一样读取和生成图像，从而可以促进多模态任务的发展。

- (2): 文章认为现有的方法只是将LLMs作为图像解码器，在生成图像方面并没有尝试过像自然语言一样进行生成。因此，文章提出了一种基于VQGAN框架的方法，将图像的潜在表示作为文本标记，通过微调预训练的LLM，实现对图像的生成与读取。文章认为这种方法在不需要任何结构性变化、额外的训练目标或专门的网络训练的情况下，仍然保持着LLM的指令跟随能力，并可用于翻译和生成复杂的CXR图像任务。

- (3): 本文提出的方法是通过使用VQ-GAN框架，利用预定义的文本标记将图像的潜在表示作为一种形式的文本，在不进行结构性变化的情况下对其进行微调，从而将LLMs转化为生成和阅读复杂图像的方法。

- (4): 本文在CXR图像生成和报告生成任务上进行了测试，取得了令人满意的效果，证明所提出的方法在图像生成任务上是有效的。

- (5): 本文旨在将LLMs与其他模态的信息相结合，提出了一种新的、基于VQGAN框架的方法，使LLMs可以像自然语言一样生成和读取CXR图像。这对于解决多模态任务中的信息翻译和生成问题非常有帮助。




 ## Paper:17




1. Title: Late-Constraint Diffusion Guidance for Controllable Image Synthesis (基于后置约束扩散指导的可控图像合成)

2. Authors: Chang Liu, Dong Liu

3. Affiliation: University of Science and Technology of China (中国科学技术大学)

4. Keywords: Deep Learning, Image Synthesis, Diffusion Models, Late Constraint

5. Url: https://arxiv.org/abs/2305.11520v1 , Github: None

6. Summary:
- (1):本篇论文研究的背景是控制图像合成过程中的输出。
- (2):先前的方法是用早期约束法解决这一问题，但是不适用于多条件合成和普适性较差。本文提出了使用后置约束法的图像合成方法，相对于早期约束法普适性更好维持合成图像的质量。 
- (3):本文提出了使用后置约束法的图像合成方法，相对于早期约束法的优点包括更好维持合成图像的质量，同时具有更好的普适性。
- (4):本方法在多种条件下合成出具有很好质量是的图像，演示了后置约束法的可用性和普适性给出了较好的成果，支持了本文的目标。
- (5):研究的目的是为了提高图像合成的普适性以及质量。




 ## Paper:18




1. Title: Enhancing Personalized Dialogue Generation with Contrastive Latent Variables: Combining Sparse and Dense Persona
(增强个性化对话生成的对比潜变量模型：结合稀疏和密集的人物角色)

2. Authors: Yihong Tang, Bo Wang, Miao Fang, Dongming Zhao, Kun Huang, Ruifang He, Yuexian Hou

3. Affiliation: 1. 天津大学新闻与传播学院; 2. 天津大学智能与计算学部; 3. 中国移动通信集团天津有限公司AI实验室; 4. 东北大学秦皇岛校区计算机与通信工程学院

4. Keywords: Personalized Dialogue Generation, Contrastive Learning, Latent Variables, Dense Persona Description, Sparse Persona Attributes 

5. URLs: Paper URL https://arxiv.org/abs/2305.11482, Github None 

6. Summary:
- (1): 个性化对话生成研究，探索对话生成和人物角色之间的一致关系。（Personalized dialogue generation explores the consistent relationship between dialogue generation and personality.）
- (2): 使用的过去方法主要是从三个资源模型来提高生成回应的个性化程度：1) 稀疏的人物角色属性，2) 密集的人物角色文本，3) 对话历史记录。但是这些资源都有各自的缺点。作者提出的方法是通过将稠密的人物角色描述聚类成稀疏的类别，然后与历史查询结合来生成个性化的回应。（The past methods aimed to enhance the personalization of generated responses by modeling persona profiles from three resources: 1) Sparse persona attributes, 2) Dense persona description texts, 3) Historical queries of current dialogue. However, each of these resources has its advantages and disadvantages. The method proposed by the authors clusters dense persona descriptions into sparse categories, which are combined with the history query to generate personalized responses.）
- (3): 作者提出的 Contrastive Latent Variable-based model (CLV) 结合对比学习来分离包含在密集人物角色文本中的人物信息，这些信息是由一个具有多个变量的潜变量来控制的。CLV 模型可以将稠密的人物角色描述聚类成稀疏的类别，并使用历史查询和获取的稀疏人物角色属性生成个性化的回应。（The proposed Contrastive Latent Variable-based model (CLV) partitions persona information using a latent variable with multiple variables, which is controlled by contrastive learning. The CLV model clusters dense persona descriptions into sparse categories, and uses both historical queries and obtained sparse persona attributes to generate personalized responses.）
- (4): 实验结果表明，该方法在提高个性化对话生成方面具有优越性，同时在机器翻译任务（多语言翻译体裁）的评估中也取得了良好的结果。（Experimental results demonstrate the superiority of this method in enhancing personalized dialogue generation, while achieving good results in evaluations, including multi-lingual translation tasks.）
- (5): 本文的重点在于提出了一种对比潜变量模型以及其具体应用于增强生成回应的个性化程度。该方法充分利用稀疏和密集的人物角色信息，可以真正提高生成回应的个性化程度，同时在机器翻译任务方面也有应用前景。（The main contribution of this paper is proposing a contrastive latent variable model and its specific application in enhancing the personalization of generated responses. This method makes full use of sparse and dense persona information, and can truly improve the personalization of generated responses. Furthermore, it also has potential applications in multi-lingual machine translation tasks.）




 ## Paper:19




1. Title: CM-MaskSD: Cross-Modality Masked Self-Distillation for Referring Image Segmentation 

2. Authors: Wenxuan Wang, Jing Liu, Xingjian He, Yisi Zhang, Chen Chen, Jiachen Shen, Yan Zhang, Jiangyun Li 

3. Affiliation: 该文章第一作者所属机构为北京科技大学自动化与电气工程学院 

4. Keywords: Referring Image Segmentation, Cross-Modality Guidance, Masked Self-Distillation, Vision and Language 

5. Urls: 链接地址: arxiv.org/abs/2305.11481, Github: None 

6. Summary: 

- (1): 该文章主要研究目标为在视觉与语言的多模态场景下，实现指代图像分割任务，其中涉及采用掩蔽式跨模态蒸馏技术实现图像与文本的特征对齐，以及结合CLIP模型对图像与文本语义信息的转移对分割精度进行改善。 

- (2): 过往的指代图像分割方法大多要么引入了复杂的模块以实现细粒度的视觉与语言特征对齐，要么是由于缺乏必要的特征对齐而导致可扩展性问题或超/低分割等误分问题。而本文提出的方法通过采用掩蔽式跨模态蒸馏技术，在共享特征提取层的基础上，通过引入只有很少参数的控制模块，实现了在跨模态情况下特征对齐，避免了传统方法的缺陷，优化了分割精度。 

- (3): 该文提出了一种掩蔽式跨模态蒸馏框架，称为CM-MaskSD，该方法主要包含两个分支，一个是主分割分支，用于提取图像特征并实现预测；另一个是跨模态蒸馏分支，包含两个掩蔽模块分别用于图像与文本的特征提取，在经过特征蒸馏后得到的信息通过转移学习进行知识转移，最后实现对特定目标的细粒度特征对齐。 

- (4): 通过在三种数据集（RefCOCO， RefCOCO+， G-Ref）上进行的实验结果表明，CM-MaskSD模型表现优于现有的所有已知指代图像分割方法，且在计算资源以及模型参数占用量上都有所降低。 

- (5): 本文研究意义在于在指代图像分割任务中尝试跨模态特征蒸馏技术实现图像与文本特征的对齐，提高指代图像分割的精度。




 ## Paper:20




1. Title: Information-Ordered Bottlenecks for Adaptive Semantic Compression

2. Authors: Matthew Ho, Xiaosheng Zhao, Benjamin Wandelt

3. Affiliation: Institut d’Astrophysique de Paris, CNRS & Sorbonne Université (Matthew Ho)

4. Keywords: deep learning, neural network, compression, latent space, dimensionality reduction

5. Urls: arXiv:2305.11213v1, Github: None

6. Summary:

- (1): 本文旨在提出一种信息排序瓶颈 (IOB) 神经层，以通过可能性最大化自适应压缩数据到按顺序排列的潜在变量中。 

- (2): 过去的方法存在一些问题，如不适合非线性数据，难以处理高维数据等。通过深度自编码器，本文提出的 IOB 方法成功解决了这些问题，并在特定的编码结构下实现了近乎最优的压缩效果。 

- (3): 本文提出的方法通过将潜在信息分层嵌入，并在推理时动态地调整瓶颈宽度，以确保可能性最大化。 

- (4): IOB 在图像和文本数据的嵌入上具有显著的压缩能力，并能够为潜在信号分配具有语义意义的顺序。 本文还提出了一个新的用于估计全局内在维度的理论，并证明了 IOB 对于复杂的合成数据恢复 SOTA 维度估计的能力。通过在异构数据集上的应用，本文展示了这些模型在探索性分析方面的实用性，可以帮助计算机辅助发现数据集的复杂性。 

- (5): 本文的研究意义在于提出了一种新的自适应压缩方法，使得深度神经网络在处理复杂数据时可以更高效、可解释和鲁棒。




 ## Paper:21




1. Title: HELMA: A Large-Scale Hallucination Evaluation Benchmark (HELMA：大规模幻觉评估基准测试)

2. Authors: Junyi Li, Xiaoxue Cheng, Wayne Xin Zhao, Jian-Yun Nie, Ji-Rong Wen

3. Affiliation: Gaoling School of Artificial Intelligence, Renmin University of China (中国人民大学高灵智能学院)

4. Keywords: Large language models, hallucination, evaluation benchmark, ChatGPT, natural language processing

5. URLs: Paper url: None, Github url: https://github.com/RUCAIBox/HELMA

6. Summary: 

- (1): 本文用于评估大型语言模型在生成内容时出现幻觉的现象，旨在增加对此类问题的认识与解决方案的提出。

- (2): 以往的方法主要着眼于特定任务和小型语言模型的幻觉问题，缺少大型语言模型的大规模全面评估。本文提出了一个值得推广的基于ChatGPT模型的幻觉生成方法，通过两个步骤生成包含幻觉内容的文本，同时开展了大量的人工干预来验证它们的结果。本文的方法非常有前瞻性和创造性。

- (3): 采用ChatGPT模型，通过两个不同的采样方法生成可能出现幻觉的文本，然后使用一个加强型的筛选方法来选择最佳的一段幻觉内容。同时，聘请人类标注者对ChatGPT的回应应回答中的幻觉内容进行注释，使得样本更加真实且可评估。

- (4): 本篇文章通过大量的实验研究，充分证实了使用大型语言模型时存在幻觉现象。同时，本文所提供的基准测试可用于对大规模语言模型的性能进行评估，为之后的研究和创新提供了良好的试验平台。

- (5): 通过本篇文章的研究，可为大型语言模型的研究与发展提供有益的参考，同时对社会大众和工业界相关的自然语言处理技术的使用具有积极意义。




 ## Paper:22




1. Title: Chain-of-thought prompting for responding to in-depth dialogue questions with LLM

2. Authors: Hongru Wang, Rui Wang, Fei Mi, Zezhong Wang, Ruifeng Xu, Kam-Fai Wong

3. Affiliation: 香港中文大学 (Chinese University of Hong Kong)

4. Keywords: deeplearning, ML, NLP, dialogue response generation, personality, emotions, psychology, large language models

5. Urls: Paper - https://arxiv.org/abs/2305.11792v1, Github - https://github.com/ruleGreen/Dialogue_CoT.git

6. Summary: 

- (1):本文研究背景为大型语言模型直接回答深入对话问题存在困难，需要综合理解对话内容并进行多步推理才能生成个性化、同情心和同理心的回应。

- (2):过去的方法在回答有关感性问题的问题时存在问题，而本文提出的方法，通过构建 Chain-of-thought prompting 模式并中间推理生成回应可以更好地理解对话文本，并在多个数据集上表现出良好的效果。

- (3):本文通过数据集构建，并在此基础上将大型语言模型 (LLMs) 应用在个性化回答深入对话问题上，通过中间推理过程维护上下文语义相关性，最终生成更加符合用户状态和需求的回应。

- (4):作者在包含3种不同用户状态的6个对话或问答数据集上进行了实验验证，并提出了一种具有创新性的演示选择策略，既考虑到中间推理的语义相似性，又在零点和单点设置下考虑到了方法的有效性和稳健性。实验结果表明，与标准提示相比，本文方法在所有数据集上的有效性和可接受性都表现出优势，而且不受所使用的LLMs影响。

- (5):本文的动机是针对现有方法不能够很好地回答有关感性问题的问题，提出了一种个性化的解决方案，为用户提供更加定制化、更加有互动性的体验。




 ## Paper:23




1. Title: DIFFUSIA: A Spiral Interaction Architecture for Encoder-Decoder Text Diffusion

                2. Authors: Chao-Hong Tan, Jia-Chen Gu, Zhen-Hua Ling

                3. Affiliation: 中国科学技术大学语音与语言技术国家  级工程研究中心

                4. Keywords: Diffusion models, Deep generative models, Text generation, Encoder-decoder architecture, DiffuSIA

                5. Urls: https://arxiv.org/abs/2305.11517, Github: None

                6. Summary:

                - (1): 本文研究了通过扩展encoder-decoder架构来提高生成式文本模型的条件建模能力。

                - (2):文章讨论了现有的一些单一编码器架构下的文本生成方法，他们虽然进行了部分噪声处理，但是对条件建模的灵活性有限。为了突破这个限制，本文提出了一个螺旋交互架构来进行编码器-解码器文本扩散，使其更灵活和可扩展。

                - (3):本文提出了一种新的螺旋交互架构DiffuSIA，该架构包括两个分离的编码器和解码器，以及两个跨注意力流，用于捕捉文本的条件和目标信息。这两种信息交互运行于多层交互螺旋，以实现深层次的融合和理解。

                - (4):文章的DiffuSIA模型及其在四个文本生成任务（包括解释复述、文本简化、问题生成和开放域对话生成）上的实验结果表明，新方法的性能在所有任务上均可与之前研究中的方法媲美,证明了该方法的有效性和泛化能力。

                - (5):本文的动机是通过提供更灵活的条件模型来改进文本生成任务，将传统的编码器-解码器架构扩展为足够灵活的条件模型，以提高模型的性能。




 ## Paper:24




1. Title: Exploring the Upper Limits of Text-Based Collaborative Filtering Using Large Language Models: Discoveries and Insights

2. Authors: Ruyu Li, Wenhao Deng, Yu Cheng, Zheng Yuan, Jiaqi Zhang, Fajie Yuan

3. Affiliation: 浙江西湖高等研究院 (Westlake University)

4. Keywords: Text-based collaborative filtering, language models, recommendation system, deep learning

5. Url: https://arxiv.org/abs/2305.11700

6. Summary:

- (1):本文研究的背景是文本数据快速增长使得推荐系统在众多领域中变得越来越重要，而且文本内容推荐，如商品说明、评价、新闻文章等，已成为了许多推荐系统的核心技术。

- (2):现有的文本协同过滤模型主要使用小型或中型 language models (LMs) 作为文本编码器，使用协同过滤技术来生成用户-item匹配分数。然而，这些模型性能的瓶颈仍然很明显，尤其是嵌入文本的自然语言处理技术的最新发展。本文提出使用最大最强大的LMs，即拥有1.75万亿参数的GPT-3模型，来代替item encoder，从而揭示 TCF配方式的性能极限。

- (3):本文提出了一种基于大型LMs的文本协同过滤新模型，通过增加item encoder的规模来探究TCF范式的性能极限，并考察这些极端大的LMs是否能够实现推荐任务的普适的item表征。此外，本文将使用最强大的LM的TCF范式的性能与当前主流的基于ID嵌入的范式进行比较，并调查这种TCF范式的可移植性。最后，本文将TCF与最近流行的使用ChatGPT1的Prompt-based推荐进行比较。

- (4):本文所提出的新模型在多个NLP数据集上进行实验，证明了使用大型LMs可以获得更好的性能。与当前主流的ID-embedding-based方法相比，本文提出的方法显著提高了推荐准确度。此外，还发现了TCF新模型的部分负面影响，这可以为进一步的研究提供指导。

- (5):本文旨在探索一种能够在大规模文本数据上处理推荐任务的新技术，同时提高准确度和范式的可移植性。




 ## Paper:25









 ## Paper:26




1. Title: Solving NLP Problems through Human-System Collaboration: A Discussion-based Approach (通过人-系统协作解决NLP问题：一种基于讨论的方法)

2. Authors: Masahiro Kaneko, Graham Neubig, Naoaki Okazaki

3. Affiliation: Affiliation: 1东京理工大学 (Tokyo Institute of Technology); 2 卡内基梅隆大学 (Carnegie Mellon University)

4. Keywords: Natural Language Processing, Human-System Collaboration, Discussion-based Approach

5. Urls: Paper: arXiv:2305.11789v1  [cs.CL]  19 May 2023; Github: https://github.com/kanekomasahiro/discussion_nlp

6. Summary:

- (1): 本文研究如何通过人-系统协作解决自然语言处理中的问题。

- (2): 以往的方法主要是在说明系统预测的基础上输出解释，要求使用者具备深度学习方面的专业知识，并不能进行深入的讨论和交流。而本文提出的基于讨论的方法，则可以实现人-系统之间的对话，相互交流优化预测结果，从而提高系统的性能和可靠性。

- (3): 针对这一目标，本文尝试创建一个数据集和计算框架，以支持人-系统之间基于对话的预测问题的合作。在实验中，作者通过人-系统讨论，取得了相对于普通预测模型高达25个百分点的性能提升。

- (4): 本文重点研究了自然语言推断任务，并通过实验得出了方法在该任务上的较好表现。如果方法可以得到进一步发展，或许可以在解决一些群众和专业人士的实际问题中起到更好的作用。

- (5): 通过本文的研究，我们可以更好地理解人-系统协作的价值，也为后续的研究提供了有益的参考。




 ## Paper:27









 ## Paper:28




1. Title: RCOT: Detecting and Rectifying Factual Inconsistency in Reasoning by Reversing Chain-of-Thought

2. Authors: Tianci Xue, Ziqi Wang, Zhenhailong Wang, Chi Han, Pengfei Yu, Heng Ji

3. Affiliation: Department of Software, Nanjing University (徐天赐), Department of Computer Science, University of Illinois Urbana-Champaign (all other authors)

4. Keywords: Large language models, chain-of-thought prompting, factual consistency, fine-grained feedback

5. Urls: Arxiv: https://arxiv.org/abs/2305.11499v1 

6. Summary:

- (1): 本文研究的背景是为了提高大型自然语言模型在推理任务中的表现，尤其是在维持实际一致性方面的表现。

- (2): 过去的方法主要是使用笼统的反馈如正确与否来改善模型实际一致性的问题，没有对实际不一致性做出具体的讨论和分析；作者在文章中提出的方法是Reversing Chain-of-Thought (RCOT)，它可以检测和改正模型中存在的问题; 方法的动机充分。

- (3): 文章提出的RCOT方法是先让模型再次重构问题，然后将重构问题与原问题进行精细对比，可以看出原问题中的事实不一致性; 然后提取出检测到的问题并使用细粒度反馈来引导模型修正解决方案。

- (4): 本文在七个算术数据集上评估了RCOT的性能，实验结果表明RCOT的改进优于标准CoT；此外，本研究发现手动编写的细粒度反馈可以显着提高模型的推理能力，例如在GSM8K数据集上ChatGPT的准确率达到94.6％，这进一步促使研究社区进一步探索细粒度反馈生成方法。

- (5): 本文的动机在于改善大型自然语言模型的推理表现，尤其是针对实际一致性问题。




 ## Paper:29




1. Title: RoomDreamer: Room Synthesis via Deep Natural Language
2. Authors: Yujian Zheng, Yuanming Hu, Chuan Li, Raquel Urtasun, Saining Xie, Yaoliang Yu, Qifeng Chen
3. Affiliation: University of Toronto (多伦多大学)
4. Keywords: natural language processing, 3D scene synthesis, deep learning, indoor scene modeling
5. Urls: Paper: https://arxiv.org/abs/2103.04064, Github: None
6. Summary: 
- (1): 本文旨在使用深度自然语言技术进行室内场景的综合。
- (2): 传统的室内场景建模方法通常需要长时间的场景扫描和精细的人工建模工作，并且他们没有涉及到自然语言生成的基础。本文提出了一个新的方法使用自然语言描述场景和风格，并对场景和风格同时进行综合。该方法采用了一系列深度学习的技术，如自然语言处理和深度图像合成。这些方法旨在解决传统室内场景建模方法的局限性，例如人工建模的繁琐，时间消耗过高等问题。该方法在新颖性、有效性上具有很大潜力。
- (3): 本文提出了两个关键的技术组件：几何引导扩散和网格优化。前者使用2D语义处理技术，为整个场景设置前处理，使得场景的结构和纹理能够同时得到保留。后者则通过一个信号的优化处理，消除了原始扫描中的伪造和停滞问题。这些组件旨在使用自然语言描述场景和维护语义一致性。
- (4): 本文在几个数据集上测试了该方法，并从不同角度进行了评估。通过测试，证明了本文所提出的方法在合成室内场景方面的效果。该研究的目标是构建更快、更鲁棒的室内场景建模技术。
- (5): 在当前的计算机图形学领域，自然语言处理和深度学习技术在综合不同类型的场景方面具有很大的潜力。本文致力于通过结合这些技术，进一步推动室内场景的综合发展。




 ## Paper:30




1. Title: Multimodal Web Navigation with Instruction-Finetuned Foundation Models

2. Authors: Hiroki Furuta, Oﬁr Nachum, Kuang-Huei Lee, Yutaka Matsuo, Shixiang Shane Gu, Izzeddin Gur

3. Affiliation: Hiroki Furuta and Yutaka Matsuo are affiliated with The University of Tokyo; Oﬁr Nachum, Kuang-Huei Lee, Shixiang Shane Gu, and Izzeddin Gur are affiliated with Google Research, Brain Team.

4. Keywords: Multimodal Web Navigation, Reinforcement Learning, Finetuning, Vision-Language Models, HTML comprehension

5. Urls: Paper - arXiv:2305.11854v1 [cs.LG] Github: None

6. Summary:

- (1): This paper addresses the challenge of autonomous web navigation, which has traditionally relied on online reinforcement learning and domain-specific model designs. 

- (2): Prior works have used online RL or specialized models to handle the complex structures of web documents, but both methods have limitations. Online RL is risky because failures during web navigation could have serious consequences, while specialized models struggle to generalize to out-of-domain data. The proposed approach of ofﬂine training with vision-language foundation models, ﬁnetuned on a large corpus of demonstrations, overcomes these challenges.

- (3): The proposed method trains a multimodal agent called WebGUM, which uses both webpage screenshots and HTML information to output web navigation actions such as clicking and typing. WebGUM is trained by jointly finetuning an instruction-ﬁnetuned language model and a vision transformer. The models are pre-trained on large language and visual corpora, then ﬁnetuned on instructions and web navigation demonstrations. 

- (4): WebGUM outperforms prior works on two benchmarks: MiniWoB and WebShop. On MiniWoB, WebGUM improves over the previous best ofﬂine methods by more than 31.9%, and is close to reaching online-ﬁnetuned state-of-the-art performance. On WebShop, the proposed 3-billion-parameter model achieves superior performance to existing state-of-the-art models. The proposed method also collects 347K high-quality demonstrations using the trained models, which is 38 times larger than prior work.

- (5): The motivation for this research is to develop safe and efficient autonomous web navigation agents that can handle diverse web content and tasks. The proposed approach of ofﬂine training with vision-language foundation models allows for safe development and leverages out-of-domain data for improved performance.




 ## Paper:31




1. Title: Speech-Text Dialog Pre-training for Spoken Dialog Understanding (针对口语对话理解的语音文本对话预训练)
                
2. Authors: Tianshu Yu, Haoyu Gao, Ting-En Lin, Min Yang, Yuchuan Wu, Wentao Ma, Chao Wang, Fei Huang, Yongbin Li

3. Affiliation: 1) Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences (中国科学院深圳先进技术研究院); 2) University of Chinese Academy of Sciences; 3) Alibaba Group
        
4. Keywords: speech-text pre-training, spoken dialog understanding, multi-modal, alignment, downstream tasks

5. Url: paper (https://arxiv.org/abs/2305.11579), Github code (https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/SPECTRA)

6. Summary:
- (1):这篇文章的研究背景是语音-文本模态处理。
- (2):现有的语音-文本预训练方法往往是针对一个或两个特定的任务，难以征服广泛的语音-文本任务。尽管一些之前的语音-文本预训练模型已经取得了显著进展，但还存在一些挑战，如需要考虑上下文信息和最细粒度的语音-文本对齐等。文章提出了一种基于对话的语音-文本预训练模型，旨在更好地捕捉上下文信息和最细粒度的语音-文本对齐问题。
- (3):文章中提出了一种新颖的时间位置预测任务来考虑语音形态的时间性，并通过响应选择任务从文本情景下的预训练进行扩展，以捕获上下文信息。实验结果表明该方法可有效地得到语音-文本对齐和对话上下文的表示模型。
- (4):文章用四种不同的语音-文本任务对该方法进行了实验，结果表明，SPECTRA在学习语音-文本对齐和上下文信息方面具有优越性能，且可以很好地迁移到不同的下游任务上。
- (5):研究问题是为了提高到口语对话理解的准确性和鲁棒性，以更好地支持自然语言应用。




 ## Paper:32




1. Title: North Sámi Dialect Identification with Self-supervised Speech Models (使用自监督语音模型进行北萨米方言识别)

2. Authors: Sofoklis Kakouros and Katri Hiovain-Asikainen

3. Affiliation: Sofoklis Kakouros - University of Helsinki, 芬兰；Katri Hiovain-Asikainen - UiT The Arctic University of Norway, 挪威北极大学

4. Keywords: speech analysis, prosody, dialect identification, XLS-R, North Sámi dialects

5. Urls: paper - arXiv:2305.11864v1 [eess.AS] 19 May 2023, Github - https://github.com/skakouros/sami_dialects (代码链接)

6. Summary:

- (1):本文旨在研究北萨米语方言识别的任务。考虑到研究的方言可能受到主流语言的影响，研究者使用了多组状态最先进的方法进行了研究。

- (2):以往方法主要是基于文本或基于语音特征来识别方言。而本文使用了一些自监督语音模型来提取语音表示，以提高识别的准确性。同时本文还讨论了主流语言对方言的影响。

- (3):本文将语音信号表示为MFCCs特征和韵律特征，并采用自监督模型如XLS-R、WavLM和HuBERT，用于训练识别框架。

- (4):本文在北萨米语方言身份识别的任务上，使用XLS-R等多种方法，达到较高的分类准确度，证明了使用自监督语音模型进行方言识别的有效性，并探讨了主流语言对方言产生的影响。

- (5):本文的动机在于研究如何高效的识别北萨米语的方言，进而促进语音识别、机器翻译、语音合成等方面的研究。此外，该工作还为解决少资源语音识别提供了一些思路。




 ## Paper:33




1. Title: Few-shot 3D Shape Generation (少样本3D形状生成)

2. Authors: JingYuan Zhu, Huimin Ma, Jiansheng Chen, Jian Yuan 

3. Affiliation: JingYuan Zhu - 清华大学 (Tsinghua University), China

4. Keywords: Few-shot learning, 3D shape generation, Generative models

5. URL: arXiv:2305.11664v1 [cs.CV] 19 May 2023, Github: None

6. Summary: 
- (1): 本文研究目标是在有限的数据集下, 提高 3D 形状生成的多样性
- (2): 过去的方法通常使用大规模的数据集进行训练, 而当数据有限时容易出现过拟合, 只能生成与训练集类似的形状。本文提出的few-shot方法通过利用少量的目标样本, 并保留源域训练时获得的复杂的几何和纹理信息, 在仅使用目标物体的轮廓做为训练数据的情况下达到了良好的多样性生成效果。
- (3): 本文提出了利用预训练模型，并在具有相似数据分布的源域中对生成模型进行微调，以适应指定的目标域，并使用few-shot方法控制模型过拟合的提出了一种few-shot 3D形状生成算法。
- (4): 在3D数据集上进行了试验，与现有方法进行了对比，有效提高了生成3D形状的多样性和效果。
- (5): 目前使用大规模训练数据进行多样化3D形状生成已经较为成熟，然而当数据集较为有限时，对于少量目标，多样化的生成仍是一个问题，因此该研究的动机在于为少量数据下的多样化生成提供新方案。




 ## Paper:34




1. Title: Counterfactuals for Design: A Model-Agnostic (基于反事实的设计优化方法：无模型设计建议)
2. Authors: Lyle Regenwetter, Yazan Abu Obaideh, Faez Ahmed
3. Affiliation: Massachusetts Institute of Technology (麻省理工学院)
4. Keywords: Counterfactuals, design optimization, multi-objective optimization, machine learning, evolutionary algorithm (反事实, 设计优化, 多目标优化, 机器学习, 进化算法)
5. Urls: Paper-https://arxiv.org/abs/2305.11308v1, Github-https://github.com/regenwetter/MCD
6. Summary:
- (1): 本文的研究背景是关于如何提出一种设计优化的方法，使得工程师能够做出更好的设计选择。
- (2): 过去的方法存在的问题在于没有考虑多目标的查询问题，并且往往需要对反事实进行采样，消耗计算资源。本文提出的方法通过支持多目标查询并分离采样与设计优化过程来提高设计自动化方法的效率。该方法的算法基于进化算法，通过查询属性预测器（例如深度学习模型）来识别最优的设计调整方案。
- (3): 本文提出了一种名为“多目标反事实”（MCD）的新颖方法，旨在解决设计中的反事实问题。通过将反事实查询问题转化为设计优化问题，该方法可以有效地识别更好的设计选择方案。本文所提出的方法支持多目标查询，并通过分离算法中的反事实查询和采样过程来提高其效率。MCD的核心功能使用一个二维测试案例进行演示，随后使用三个自行车设计的案例研究展示了该方法在实际工程问题中的有效性。
- (4): 在三个自行车设计的案例研究中，MCD成功地推荐出能够显著提高设计性能的设计调整方案，例如重量减轻和结构安全系数的提高。同时，本文还展示了MCD通过与预训练语言模型协作，能够通过语言提示实现设计变更，并通过复杂的多模式查询展示了MCD的性能。该方法的性能能够支持其在多目标设计优化中的应用。
- (5): 本文的动机是帮助工程师和设计自动化研究人员通过探索假设的设计变化及其对多个设计目标的影响，为他们提供宝贵的建议。该方法为工程设计的自动化带来了新的思路，为设计改进提供了新的途径。




 ## Paper:35




1. Title: Scaling laws for language encoding models in fMRI（fMRI中语言编码模型的规模定律）

2. Authors: Richard Antonello, Aditya Vaidya, Alexander G. Huth

3. Affiliation: 理查德·安东尼洛，德州大学奥斯汀分校计算机科学系

4. Keywords: deeplearning, ML, NLP, CV, fMRI, language encoding models, transformer-based unidirectional language models, GPT-2, OPT, LLaMA, HuBERT, WavLM, Whisper, scaling laws, encoding model, brain prediction performance

5. Urls: arxiv.org/abs/2305.11863, Github: None

6. Summary:

- (1): 本文旨在将变形器语言模型应用于fMRI数据解析，并测试模型尺寸和数据大小对语言编码模型预测性能的影响。
 
- (2): 先前的方法主要使用GPT-2或类似尺寸的语言模型，本文测试了来自OPT和LLaMA家族等更大的开源模型是否能更好地预测fMRI记录的脑响应。结果发现，从125M到30B参数模型，预测性能随模型规模对数线性缩放，与3个受试者上的保留测试集的相关性测量表现出约15％的提高。当扩大fMRI训练集的大小时，也观察到了类似的对数线性行为。本文还对基于HuBERT、WavLM和Whisper的声学编码模型进行了特征缩放，并发现模型规模随比较大时会有类似的改进。这些结果表明，在模型和数据的规模都越来越大的情况下，将产生最有效的脑语言处理模型，从而实现更好的科学理解以及诸如解码等的应用。

- (3): 本文基于编码模型，通过同一自然语言刺激，构建一个模型，能准确地预测大脑对自然语言的响应。 本文使用了大型语言模型，比如GPT-2等编码模型解析fMRI记录的脑响应，以确定脑预测性能是否随模型尺寸和数据集大小呈对数线性缩放。

- (4): 本文提出的语言编码模型预测性能随模型规模对数线性缩放，从125M到30B参数模型，相关性表现出约15％的提高。大型高性能编码模型的噪声天花板分析表明，性能已经接近于像前驱皮层和更高的听觉皮层这样的大脑区域的理论最大值。这些结果表明，在模型和数据的规模都越来越大的情况下，将产生最有效的脑语言处理模型，从而实现更好的科学理解以及诸如解码等的应用。

- (5): 本文的动机是应用大型语言模型于fMRI数据解析，测试模型尺寸和数据大小对语言编码模型预测性能的影响，为更好的科学理解以及诸如解码等的应用提供支持。 




 ## Paper:36




1. Title: Carving 3D Clothed Humans from Skinned Shape Priors using 2D Diffusion Probabilistic Models 
(用 2D 扩散概率模型从被皮肤覆盖的形状先验中雕刻 3D 穿衣人物形象)

2. Authors: Byungjun Kim, Patrick Kwon, Kwangho Lee, Myunggi Lee, Sookwan Han, Daesik Kim, Hanbyul Joo 

3. Affiliation: 1Seoul National University (首尔国立大学)

4. Keywords: 3D generation, diffusion models, human digital avatars, SMPL-X, text-to-image generation 

5. Urls: 
- Paper: https://arxiv.org/abs/2305.11870
- Github code: https://github.com/snuvclab/chupa/

6. Summary: 
- (1): 本篇文章的研究背景是创建出多样、逼真的 3D 人物角色。
- (2): 过去的方法存在生成过程中的诸多问题。本文提出使用扩散模型生成人物的方法，并在此基础上进一步进行自然图像生成。使用“carve”对SMPL-X被皮肤覆盖的模型进行优化，以生成更具细节性的人物形象。这种方法在细节方面更为逼真。文章的方法是合理有效的。
- (3): 本文提出的研究方法基于扩散模型，通过2D 正算法生成人物表皮，并基于这些表皮进行3D 人物构建，以尽可能地逼真地生成3D 人物形象。
- (4): 作者们的方法可以生成更加逼真的 3D 人物形象，性能良好且具有高替代性，能够支持人物的身份的文本控制以及更加真实的3D人物呈现。
- (5): 本文的研究动机是提出一种更为高效、可靠、匹配和思路清晰的制作逼真肖像的方法。




 ## Paper:37




1. Title: Brain Captioning: Decoding human brain activity (大脑标题：解码人类脑活动) 

2. Authors: Matteo Ferrante, Furkan Ozcelik, Tommaso Boccato, Rufin VanRullen, Nicola Toschi 

3. Affiliation: 马特奥·费兰特，汤加大学的科学家，弗坎·奥兹切里克，Rufin VanRullen，Universite de Toulouse 的科学家，汤马索·波卡托和尼古拉·托斯基，罗马托尔维耶塔大学的科学家。 

4. Keywords: deep learning, machine learning, NLP, computer vision, brain decoding, functional magnetic resonance imaging (fMRI), image captioning, Generative Image-to-text Transformer (GIT), depth estimation, latent diffusion models 

5. Urls: arXiv:2305.11560v1 [cs.CV] 19 May 2023 

6. Summary: 
- (1): 本文的研究背景是人类在每天处理大量视觉信息，使用错综复杂的神经机制来传递和解释这些刺激。 
- (2): 过去的方法是通过功能性磁共振成像(fMRI)提取大脑活动信息并将其解码为图像，但由于图像大小的约束，图像解码不够灵活。本文通过使用创新的大脑标题方法，将大脑活动解码为有意义的图像和标题，提高了灵活性。方法利用最先进的图像标题模型，并结合潜在扩散模型和深度估计的独特图像重构管道，利用自然场景数据集，提出了一种新的基于潜在扩散模型的图像重建管道，使用GIT作为captioning主干，并使用正则化线性回归模型在脑活动和提取特征之间进行训练，还使用了ControlNet模型的深度图来进一步指导重构过程。 
- (3): 本文提出一种新的大脑标题方法，通过将大脑活动解码为图像和标题，以更加灵活的方式展示了人类的视觉加工过程。 
- (4): 本文采用定量度量方法评估方法生成的标题和图像，证明了本文提出的方法优于现有方法，而图像重构管道创建的图像在空间关系上也得到了改善。 
- (5): 本文旨在将图像和语言进行整合，更好地理解人类认知，并具有潜在的应用前景，例如神经艺术、样式迁移和便携设备。




 ## Paper:38




1. Title: SlotDiffusion: Object-Centric
Generative Modeling with Diffusion Models

2. Authors: Ziyi Wu, Jingyu Hu, Wuyue Lu, Igor Gilitschenski, Animesh Garg


3. Affiliation: 
1University of Toronto

2Vector Institute

4. Keywords: Object-centric learning, Latent Diffusion Model, unsupervised object segmentation, visual generation

5. Urls: arXiv:None, Github:None

6. Summary:

- (1): 本文着眼于提高视觉生成的质量，使用一种基于物体中心的 Latent Diffusion Model (LDM) SlotDiffusion 模型实现了更好的视觉生成效果。 

- (2): 该文介绍了过去的物体中心方法在生成模型上的缺陷，如图像模糊和物体形变等问题，并提出了不依赖于强先验的方法。作者结合 Slot Attention机制和 advanced architectures like Transformers，将图像转为 slot-based representations逐步提高了物体识别的精度。作者此外，作者还在物体分割和视频预测领域取得了好的表现。

- (3): 本文将图像转为 slot-based representations, 并将其输入到使用了Latent Diffusion Model (LDM) 的 SlotDiffusion model中。 

- (4): 该模型在六个数据集上表现出比以往物体中心模型更好的unsupervised object segmentation 和visual generation表现。它不依赖于强先验，并显示出具有良好的扩展性能。作者还将该方法应用于物体中心的视频预测，并取得了良好的效果。

- (5): 该文的研究动机在于提高现有物体中心方法在视觉生成方面的表现，在不依赖于先验假设的情况下提高物体分割和视频预测的性能。



