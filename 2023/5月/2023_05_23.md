# 2023_05_23 Arxiv更新论文汇总
今天共有50篇论文


 ## Paper:1




1. Title: Language-Agnostic Bias Detection in Language Models (语言无关的语言模型偏差检测)

2. Authors: Abdullatif Köksal, Omer Faruk Yalcin, Ahmet Akbiyik, M. Tahir Kılavuz, Anna Korhonen, Hinrich Schütze

3. Affiliation: Abdullatif Köksal: LMU Munich, Middle East Initiative, Harvard University; Omer Faruk Yalcin: University of Massachusetts Amherst; Ahmet Akbiyik: Harvard Kennedy School; M. Tahir Kılavuz: University of Cambridge; Anna Korhonen: University of Cambridge; Hinrich Schütze: LMU Munich, Munich Center for Machine Learning

4. Keywords: Pretrained language models, bias detection, nationality bias, language-agnostic, sentiment analysis

5. URLs: Paper: https://arxiv.org/abs/2305.13302v1, Github: None

6. Summary:

- (1): 本文研究的背景是针对预训练语言模型中存在的社会偏见进行检测和解决。预训练语言模型是NLP中的关键组件，但存在严重的社会偏见，这是道德使用的严重障碍。

- (2): 过去的方法主要集中在英语方面，这些方法存在局限性，如无法应用于非英语语言和存在膜填充目标的法性。另外，小型预训练语言模型对于模板的敏感性较高，这也是一个问题。本文提出了一种新的语言无关的方法，通过在预训练语言模型上训练一个情感分类器来检测偏见，使用模板来代替膜填充目标，以克服模板的敏感性，从而提高了检测偏见的鲁棒性。

- (3): 本文提出的研究方法是用模板来代替膜填充目标，在预训练语言模型的基础上训练一个情感分类器，来检测和评估偏见。与其他方法相比，这种方法具有高鲁棒性和更好的适应性，可以应用于多种语言和不同类型的PLM。

- (4): 本文以国籍为研究案例，表明本文提出的LABDet方法可以有效地检测国籍偏见。在六种语言的PLMs中，我们发现国籍偏见与历史和政治背景保持一致，在英语BERT中，通过LABDet检测到的偏见与预训练数据中的偏见具有显著的相关性。这表明本文是少数几个将预训练数据直接关联到PLM行为的研究之一。 

- (5): 本文的研究动机是为了解决预训练语言模型中存在的社会偏见及相关的道德问题。本文的方法提高了对预训练语言模型中偏见的检测能力，并为未来构建更公正和准确的自然语言处理系统提供了一条途径。




 ## Paper:2




1. Title: ChatGPT to Replace Crowdsourcing of Paraphrases for Intent

                2. Authors: Jan Cegin, Jakub Simko, Peter Brusilovsky

                3. Affiliation: Faculty of Information Technology, Brno University of Technology, Kempelen Institute of Intelligent Technologies, University of Pittsburgh

                4. Keywords: ChatGPT, crowdsourcing, paraphrase generation, intent classification, large language models 

                5. Urls: arXiv:2305.12947v1, Github:None

                6. Summary:

                - (1):本文探讨了生成式大型语言模型（LLMs）对众包的影响。特别是，文章讨论用于意图分类数据增强的同义重述生成这一众包任务，以及ChatGPT在此任务中是否能取代人工工作者。

                - (2):传统上，众包已被用于获得各种人工智能任务（包括涉及文本生成、修改或评估的任务）的解决方案。然而，众包存在一些问题，比如人力成本高、输出质量难以保证、流程设计和组织等开销。本文通过将ChatGPT代替人工工作者的方法，对现有同义重述生成的众包数据进行了模拟复制实验。文章得出的结论是：ChatGPT生成的同义重述更加多样化、其训练的模型的鲁棒性不亚于人工众包，具有很高的可靠性。因此，可以在一定程度上取代人工工作者的一些众包任务。

                - (3):本文的研究方法是通过模拟复制已有的同义重述生成数据集，比较ChatGPT与人工众包的生成结果，得出上述结论。具体地，本文使用与先前众包研究相同种子数据、类似规模的数据收集方法以及禁词技术，收集促发同义重述的数据，最终比较ChatGPT与人工工作者的数据生成结果。

                - (4):本文主要针对同义重述生成的任务，比较ChatGPT与人工工作者生成的数据量、数据多样性和生成数据在意图分类任务上训练的模型鲁棒性。实验结果显示，ChatGPT在同义重述生成任务中的表现优异，数据生成多样性较强，并且训练出的意图分类模型具有可比性。

                - (5):本文的研究动机在于探讨如何通过ChatGPT等生成式大型语言模型来代替人工众包完成一些NLP任务，从而提高数据生成效率，降低人力成本，以及提高数据生成的质量和鲁棒性。




 ## Paper:3




1. Title: A Pilot Study on Dialogue-Level Dependency Parsing for Chinese (一项关于中文对话层面依存分析的试点研究)
                
                2. Authors: Gongyao Jiang, Shuang Liu, Meishan Zhang, Min Zhang
                
                3. Affiliation: School of New Media and Communication, Tianjin University, China (中国天津大学新闻与传播学院)
                
                4. Keywords: dependency parsing, dialogue-level, Chinese, syntactic treebank, rhetorical structure theory
                
                5. Urls: https://arxiv.org/abs/2305.12441
                
                6. Summary: 
                
                - (1): 本文研究了中文对话层面依存分析的问题。
                
                - (2): 过去的方法大都是集中在句子层面上，而对于对话级别的依存分析关注较少。本文的方法集成了句法依存和修辞结构理论，通过构建高质量的人工标注语料库来解决这个问题。文章采用了零样本和少样本学习的方法，以及单视图和多视图数据选择的技术来提高模型的效果。文章的方法提出了很好的动机。
                
                - (3): 本文的研究方法是采用已有的句法树库来将句子内部单元间已见的依存结构转换成未见的相互关系。通过掩码语言建模技术来检测这种信号。文章还在数据选择方面采用了单视图和多视图的方法选取可靠的伪标签样本。
                
                - (4): 本文的方法在人工标注的850个对话和199,803个依存关系的中文对话级别语料库上进行了实验。实验结果表明本文的方法在零样本和少样本学习的情况下都取得了比较好的效果。文章的方法能够支持对话级别的依存分析，并取得了良好的性能。
                
                - (5): 本文的研究动机是关注对话级别的依存分析，在过去的研究中这个问题的关注度较少。文章通过引入修辞结构理论等方法来解决这一问题。




 ## Paper:4




1. Title: Multimodal Named Entity Recognition via Prompt ChatGPT
(基于Prompt ChatGPT的多模态命名实体识别)

2. Authors: Yaqian Zhou, Hao Zhou, Yu Wu, Weiran Xu, Yifan Gao, Jianxing Yu, Kang Liu

3. Affiliation: Y. Zhou and K. Liu are with AI Lab, DSIG, School of EECS, Peking University, Beijing, China; H. Zhou, Y. Wu, W. Xu, Y. Gao, and J. Yu are with DiDi Inc., Beijing, China.
(周亚倩，周昊，吴雨，许维然，高一凡，于建星，刘康。周亚倩和刘康属于北京大学 EECS 学院人工智能实验室; 周昊，吴雨，许维然，高一凡，于建星属于滴滴公司)

4. Keywords: Multimodal named entity recognition, Prompt ChatGPT, natural language processing, deep learning
(多模态命名实体识别，Prompt ChatGPT，自然语言处理，深度学习)

5. URLs: Paper URL: https://arxiv.org/abs/2109.09474, Github: None

6. Summary:

- (1): 该论文研究多模态命名实体识别（MNER）领域，通过整合图像信息进行文本实体预测，提高实体识别精度。
- (2): 现有的研究方法主要集中在最大化图像中的潜在信息利用，或者从显式知识库中整合外部知识。这些方法或忽略提供相关外部知识的必要性，或者从知识库中检索到高度冗余的外部知识。文章提出一种名为PGIM的二阶段框架，采用Prompt ChatGPT作为隐含知识引擎，获取辅助细化的知识。首先，利用多模态相似例知觉模块从少量手动注释的样本中选择合适的例子。然后，将这些例子整合到针对MNER任务的格式化提示模板中，引导ChatGPT生成辅助细化的知识。最后，将获取的知识与原始文本集成，并输入到下游模型中进行进一步处理。
- (3): 文章提出了Prompt ChatGPT In MNER（PGIM）的框架，利用ChatGPT作为一个隐含知识引擎，获取辅助细化的知识。该框架通过多模态相似例知觉模块从样本中选择例子，并将这些例子整合到针对MNER任务的格式化提示模板中，引导ChatGPT生成辅助细化的知识，最后与原始文本集成，由下游模型进一步处理。
- (4): 实验证明，文章提出的PGIM方法在两个经典MNER数据集上显着优于现有所有最先进方法。
- (5): 通过引入图像信息整合外部知识来提高MNER任务中实体预测的精度，以提高多模态命名实体识别的性能。




 ## Paper:5




1. Title: Is Synthetic Data From Diffusion Models Ready for Knowledge Distillation?

2. Authors: Zheng Li, Yuxuan Li, Penghai Zhao, Renjie Song, Xiang Li, Jian Yang

3. Affiliation: Nankai University (南开大学)

4. Keywords: Knowledge distillation, synthetic data, diffusion models, image generation

5. Urls: Paper: arXiv:2305.12954v1 [cs.CV] 22 May 2023, Github: https://github.com/zhengli97/DM-KD

6. Summary:

- (1): 本文研究了使用新型的生成模型——扩散模型生成的合成数据，是否能够在无法获取真实图像的情况下用于知识蒸馏，考察了合成数据在此任务上的适用性和有效性。

- (2):由于现有的基于数据的蒸馏方法往往需要训练集，受到科研安全和隐私保护等因素限制，无法应用于某些情况，于是提出了一些合成数据的蒸馏方法。本文重点考虑了扩散模型产生的合成图像对知识蒸馏的影响，并对比了其他合成数据蒸馏方法的性能。

- (3): 本文首先使用扩散模型生成了一批高保真度的合成图像，并在此基础上，通过大量的实验验证了合成数据的适用性和有效性。在实验过程中，论文首次提出了低保真度的合成图像更能作为教学音乐素材，以及相对较弱的分类器更能成为合适的教师等结论。

- (4): 本文实验结果表明，使用扩散模型生成的合成数据能够达到最先进的蒸馏方法的性能，且低保真的数据具有更好的蒸馏效果，相对较弱的分类器更有助于蒸馏。应用于图像分类任务时，本方法能够取得与真实数据训练媲美的性能。 

- (5): 本文在探索了合成数据在知识蒸馏中的可行性和适用性，为使用更少、更安全、更高效的数据进行知识蒸馏提供了一种全新的思路和解决方案。




 ## Paper:6




1. Title: A Deeper (Autoregressive) Approach to Non-Convergent Discourse

2. Authors: Yoav Tulpan, Oren Tsur

3. Affiliation: Yoav Tulpan is affiliated with Ben Gurion University of the Negev.

4. Keywords: online discourse, discourse parsing, contentious dialog, RoBERTa, GRN layers

5. Urls: arXiv:2305.12510v1, Github: None

6. Summary:

- (1): 本文探究了在线讨论中的议题多样性和不一致性的问题，基于一个新的多标签方案构建了一种深度学习模型，实现了对于内容复杂、多元化的讨论的分析和预测。 
- (2): 以往的对话分析方法需要大量关于标记组合和上下文信息的预先知识，这种方法虽然准确但缺乏泛化能力。文章提出了一种方法，只需要利用之前对话的表述特征，不再需要使用各种不同模型、不同体系结构来处理不同的标签信息，一个模型便能完成所有工作。这是一种有效且易于扩展复用的方法。
- (3): 本文的方法基于RoBERTa的文本嵌入，使用GRN层，通过一个不对称的损失函数将机器对话分析、预测问题转化为文本的多标签分类任务，利用自回归模型生成响应。算法结构简单，效率高，具有很高的解释性和泛化能力，适用于在大规模的社交媒体平台上进行实时的在线对话分析。
- (4): 本研究中使用的模型在公开数据集上展示出了比SOTA方法更好的RoC-Auc和Kendall’s Tau指标。因此，实验证明了本文的方法在对于不同标签的、复杂、多元的讨论进行分类任务有很好的效果。
- (5): 在线社交平台上的讨论具有高互动性和多方参与性，但面临着诸多挑战，如内容质量的保证、噪声过滤、讨论效果的衡量等。本文旨在提出一种新的方法，通过算法模型的改进和优化，促进在线讨论的生产力和质量。




 ## Paper:7




1. Title: ZS-MSTM:  零样式转移用于文本和语音驱动的手势动画，利用对多模态样式编码的对抗式分解

2. Authors: Mireille Fares, Catherine Pelachaud, Nicolas Obin

3. Affiliation: Mireille Fares隶属于法国巴黎索邦大学，ISIR, STMS；Catherine Pelachaud隶属于法国巴黎索邦大学，ISIR, CNRS；Nicolas Obin隶属于法国巴黎索邦大学，STMS。

4. Keywords: Multimodal gesture synthesis, Zero-shot style transfer, Embodied conversational agents, Multimodal behavior style, Transformers

5. Urls: arXiv:2305.12887v1  [eess.AS]  22 May 2023, Github: None

6. Summary: 

- (1): 本文研究人机交互虚拟代理人行为样式的建模和学习，在语音和文本驱动的情况下，提供一种机器学习方法来合成手势，其样式来自不同训练阶段中未见过的说话者。 

- (2): 本文提出的方法包括零样式转移和多模态数据，通过 Pats 数据库进行样式转移和神经网络学习过程中的训练。先前的方法往往会训练和微调，且很难捕捉样式。而本文的方法能够分离内容与样式，并且直接推断样式嵌入，避免了训练和预调，且泛化能力更强。
 
- (3): 文章提出了一种多模态编解码器，用于学习手势样式，以及一种无监督的多模态重构器，用于零样式转移，仅使用模态数据进行训练，克服了以往方法的问题。

- (4): 本文的方法在行为个性化上有了很好的效果，并在目标测试中也给出了定量和定性的分析证明了该方法的有效性，并且与两个基线方法进行了比较以进行验证。

- (5):本文的研究目的是为了解决行为个性化建模的问题，并尝试解决行为样式建模的挑战，致力于改进人机交互以及虚拟代理人的人性化设计。




 ## Paper:8




1. Title: Measuring and Controlling Agency in Dialogue Systems with Collaborative Design. 

2. Authors: Ramesh Manuvinakurike, Cecilia Ovesdotter Alm, and Marilyn A. Walker. 

3. Affiliation: Ramesh Manuvinakurike (University of Texas at Austin, USA), Cecilia Ovesdotter Alm (Rochester Institute of Technology, USA), and Marilyn A. Walker (University of California Santa Cruz, USA). 

4. Keywords: Dialogue systems, agency, collaborative design, intentionality, motivation, self-efficacy, self-regulation. 

5. Urls: Paper link: https://aclanthology.org/2021.findings-acl.303.pdf, Github: None. 

6. Summary: 

- (1): 本文探讨了对话系统中代理性 (agency) 的测量和控制。代理性指的是主动形塑事件的能力，是人类与其他人类相互交往和协作的关键。 

- (2): 过去的方法大多集中在对话的结构和语言特征上，忽略了对话参与者的心理状态。然而，在合作设计等一些特定的对话任务中，代理性尤为重要。本文通过 Bandura 所提出的社会认知理论，提出了一个由意图、动机、自我效能和自我调节四个特征构成的代理性框架，并通过收集并释放一个包含人-人合作室内设计对话的数据集，在此数据集上探索了测量和控制代理性的方法。 

- (3): 本文提出了一些方法来测量和控制代理性，如将目标和评估作为对话动态的基础。另外，本文还提出了一个代理性模型，并使用该模型对比了不同模型之间的差异和优劣，其中 baseline 模型表现出了一定的意图特征，但明显不足；而明显具有动机、自我效能和自我调节四个特征的模型则表现出较高的代理性。 

- (4): 本文的方法在对话系统中的合作设计任务中取得了较好的效果。研究表明，使用显式表现出较高动机、自我效能和自我调节特征的模型，能够更好地影响并推动最终决策的结果。 

- (5): 本研究的动机在于探索对话系统中代理性的测量和控制方法，以应对现有方法难以解决的问题。此外，合作设计这类任务的独特性也促使本研究更加关注代理性。




 ## Paper:9




1. Title: Hierarchical Integration Diffusion Model for Realistic Image Deblurring
2. Authors: Zheng Chen, Yulun Zhang, Ding Liu, Bin Xia, Jinjin Gu, Linghe Kong, Xin Yuan
3. Affiliation: Shanghai Jiao Tong University
4. Keywords: diffusion models, image deblurring, prior feature, generative models, latent space
5. Url: https://arxiv.org/abs/2305.12966, Github: https://github.com/zhengchen1999/HI-Diff
6. Summary:

- (1): 本文研究复杂场景下图像去模糊的问题。
- (2): 过去的方法通常将图像去模糊问题看作一个优化问题，并且采用自然先验来约束解空间。然而，这些算法在复杂场景下往往不能很好地泛化。此外，回归方法往往只能恢复得到较少的细节信息。本文提出的层次整合扩散模型可以在高度压缩的潜在空间中执行扩散操作以生成去模糊过程的先前特征，并通过回归方法实现去模糊，从而更好地保证畸变精度。此外，本文还设计了分层整合模块，以从多个尺度将先验融合到基于回归的模型中，使其可以在复杂的模糊场景中更好地泛化。
- (3): 本文提出的方法是将扩散模型与回归方法相结合。扩散模型在高度压缩的潜在空间中进行，以生成去模糊过程的先前特征。回归模型则用于去模糊，通过设计的分层整合模块可以更好地融合这两个方法，使其可以在复杂的模糊场景中更好地泛化。
- (4): 本文提出的层次整合扩散模型(HI-Diff)在合成和真实数据集上进行了实验，取得了优于其他方法的成果，证明了模型的有效性。
- (5): 本文的研究动机是提高图像去模糊模型在复杂场景下的泛化能力，并提高恢复的细节信息。




 ## Paper:10




1. Title: "GSURE-Based Diffusion Model"
2. Authors: Bahjat Kawar, Noam Elata, Tomer Michaeli, Michael Elad
3. Affiliation: 技术尼翁大学（Technion, Haifa, Israel）计算机科学系（Department of Computer Science）和电气与计算机工程系（Department of Electrical and Computer Engineering）
4. Keywords: Diffusion models, training, corrupted data, Generalized Stein's Unbiased Risk Estimator (GSURE), generative performance, downstream tasks.
5. URL: https://arxiv.org/abs/2305.13128v1 ; Github: https://github.com/bahjat-kawar/gsure-diffusion/
6. Summary: 

- (1)：本文研究的背景是要在没有训练数据的情况下，通过数据生成器模型的训练技术来实现分类任务或文本编辑等需求。
 
- (2)：过去的方法通常需要大量干净无损的训练数据，而且在某些情况下这些数据收集起来非常困难。因此，本文提出了新的训练方法，该方法基于数据损坏后的修复，通过基于广义均衡风险估计器（Generalized Stein’s Unbiased Risk Estimator, GSURE）的损失函数来训练生成扩散模型。与以往的方法不同，这种方法不需要任何干净的信号作为训练数据。该方法可大幅缓解数据收集成本，且经实验证明，该方法具有很好的动机和优化效果。

- (3)：本文提出了一种基于GSURE的新型训练技术，该方法仅基于数据损坏后修复的训练集构建扩散模型，且该方法不需要干净的训练数据。此外，在一定条件下，GSURE的损失函数与完全监督扩散模型的训练目标等效。

- (4)：该方法在各种应用中具有宽泛的适用性，并通过实验在人脸图像和医学影像（如MRI）等领域中展示出很好的表现。此外，该方法在训练集中传统上认为具有噪声、损坏的数据外，还能在完成相关任务时展现出有助于提高可用性的新的变化和性能。  本研究的目的是为了在训练许多机器学习模型时，帮助用户在训练前就能够了解整个源数据并检测不符合要求的数据，从而降低“数据噪声”的影响，以获得更准确的模型。

- (5)：通过提出基于GSURE的训练技术，本文的目的是旨在缓解数据收集过程中“噪声”造成的数据损坏，从而使训练更加简单和成本效益更高。




 ## Paper:11




1. Title: Evaluating Factual Consistency of Texts with Semantic Role Labeling (使用语义角色标注评估文本的事实一致性)

2. Authors: Jing Fan, Dennis Aumiller, Michael Gertz

3. Affiliation: Institute of Computer Science, Heidelberg University (海德堡大学计算机科学学院)

4. Keywords: automated evaluation, factuality, semantic role labeling, text summarization, fact tuples

5. Urls: Paper link: arXiv:2305.13309; Github: https://github.com/heyjing/SRLScore

6. Summary:

- (1): 该文章的研究背景是神经文本摘要系统的生产部署问题中，系统输出与人类偏好的相关性较低，其中的事实一致性问题是其中的重要问题，文中提出了一种使用语义角色标注来评估文本事实一致性的方法。

- (2): 过去的方法经常依赖于任务特定的语言模型进行评估，这在对生成得分进行解释时提供了很小的可能性。本文引入了SRLScore，这是一种无需参考的评估度量，旨在进行文本摘要评估。我们的方法从语义角色标签构造事实元组，应用于输入文本和摘要文本。通过调整评分机制来计算最终的事实性得分，这使得该方法可以在不同领域进行简单的适应。在英文摘要数据集上与人类判断的相关性表明，SRLScore与最先进的方法具有竞争力，并且在不需要进一步训练或超参数调整的情况下，具有稳定的普遍性。我们尝试进行了可选的共指消解步骤的实验，但发现性能提升主要被额外的计算所抵消。本文所提出的度量标准可在网上使用，网址为:https://github.com/heyjing/SRLScore

- (3): 本文提出了一种使用语义角色标注来评估文本事实一致性的评估方法。该方法使用语义角色标注生成抽象句子表示，这些表示与它们的句法构造无关。SRLScore中的事实元组是在输入文本而非摘要中生成的，因此我们的方法是无需参考的，并且可以在不需要标注数据集的情况下应用于评估。我们使用新颖的加权方案为事实元组比较提供了一种新的权重方案，可让用户进行优化。

- (4): 本文提出的方法是针对文本摘要的自动化评估方法。在评估与人类判断相关性的实验中，SRLScore表现良好，并在不同数据集上展现出稳定的普适性。我们的方法完全依赖于公开可用的软件组件，所有的实验都是在英文数据集上完成的。 SRLScore有望成为更高效的文本摘要生成系统性能评估指标。

- (5): 本文的动机为改善神经文本摘要系统失真结果的问题，保证输出与输入具有事实一致性。并且这种度量标准在机器学习领域具有推广价值。




 ## Paper:12




1. Title: Comprehensive Study on Gene Expression-Based Cancer Classification and Biomarker Discovery

2. Authors: Xiaobo Zhou, Weida Tong

3. Affiliation: 中国食品药品检定研究院 (Chinese Academy of Food and Drug Test)

4. Keywords: Cancer classification, Biomarker discovery, Gene expression analysis

5. Urls: Paper link:[https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2902826/], Github: None

6. Summary:

- (1):该文章探讨基于基因表达的癌症分类和生物标志物的发现；
- (2):过去的方法及其问题是使用不同的分类器和特征选择方法得到不同的分类结果，并且生物标志物发现方法通常忽略特征选择带来的偏差。作者提出了一种新的方法来解决这些问题，并且阐述了其优势；
- (3):作者提出了一种基于随机森林算法和Fisher-score特征选择方法的综合分析方法来实现癌症分类并发现生物标志物；
- (4):在研究中，作者用该方法对四种癌症进行分类，并发现若干生物标志物，并且该方法的性能优于其他方法；
- (5):该研究的动机是基于基因表达数据进行高精度的癌症分类，并发现在这些癌症中潜在的生物标志物。




 ## Paper:13




1. Title: ControlVideo: Training-free Controllable Text-to-Video Generation

2. Authors: Yabo Zhang, Yuxiang Wei, Dongsheng Jiang, Xiaopeng Zhang, Wangmeng Zuo, Qi Tian

3. Affiliation: 哈尔滨工业大学 (Harbin Institute of Technology)

4. Keywords: Deep learning, video generation, text-to-video, image generation, ControlVideo

5. URLs: Paper link: arXiv:2305.13077v1 [cs.CV] 22 May 2023; Github code link: https://github.com/YBYBZhang/ControlVideo

6. Summary: 

- (1): 本文的研究背景是控制可训练文本到视频生成问题，目的是实现自然而有效的文本到视频生成，同时减少长时间训练的需求和计算资源的开销。

- (2): 过去的文本到视频生成方法存在许多问题，如视频在外观与结构上的不一致性以及在长视频合成中易出现的结构性抖动等，并且其训练代价很高。因此，本文提出一种名为 ControlVideo 的无需训练的文本到视频生成框架，该框架采用诸如完全的跨帧交互、交替帧平滑等三个模块来提高视频生成质量。

- (3): 本文提出的方法首先从输入的运动序列中提取了粗略的结构一致性，然后通过在自注意力模块中加入完全的跨帧交互来确保帧间外观一致性、引入了交替帧平滑器来缓解视频抖动和使用分层采样器来快速持续地生成长视频。这些方法的设计使得所提出的 ControlVideo 框架能够在短时间内自然、高效地生成静态或动态视频，且在数量和质量方面都优于现有技术。

- (4): 本文的方法在进行了严格的实验评估后，证明其在视频生成任务上取得了令人瞩目的性能，比起现有技术，在大多数测评指标上都取得了更好的成果。

- (5): 本文研发的 ControlVideo 框架可为科学研究和商业开发提供更快速、经济、高效的文本到视频生成方法，解决了过去文本到视频生成技术的许多弊端。




 ## Paper:14




1. Title: Towards Robust Personalized Dialogue Generation via Order-Insensitive (基于无序表示正则化的强健个性对话生成)

2. Authors: Liang Chen, Hongru Wang, Yang Deng, Wai-Chung Kwan, Zezhong Wang, Kam-Fai Wong

3. Affiliation: The Chinese University of Hong Kong (香港中文大学)

4. Keywords: Dialogue generation, Personalized conversation, Representation regularization, Order-insensitive generation, Tansformer-based models

5. Urls: Paper: arXiv:2305.12782v1 [cs.CL] | Github: https://github.com/ChanLiang/ORIG

6. Summary:

- (1): 本文旨在通过解决在个性对话中出现的个性输入序列顺序的敏感性问题，提出一种基于无序表示正则化的强健个性对话生成框架。

- (2): 目前的生成个性对话模型通常通过将个性输入和对话历史作为单个输入序列进行微调进行训练。但是本文的分析表明这种方法很容易受到顺序敏感性的影响，不同输入序列可能会显著影响生成响应的质量和一致性，严重影响性能。为了解决这个问题，本文提出了一个模型无关的框架ORder Insensitive Generation (ORIG)，能够使对话模型在不同的个性顺序下学习相对鲁棒的表示，提高响应一致性生成。本文的方法在Persona-Chat数据集上得到良好的表现，验证了其优越性。

- (3): 本文提出了一种基于无序表示正则化的框架，通过学习对抗句子重排序的能力使模型更具鲁棒性和一致性。并提出了一种自适应的表示正则化机制，在目标任务和预训练模型之间进行平衡。

- (4): 本文的方法在Persona-Chat数据集上进行了实验，表明所提出的ORIG框架能够解决个性输入顺序敏感性问题，并提高响应的品质和一致性（GPT2下性能提升：29.4%，BART下性能提升：83.2%）。

- (5): 本文旨在解决基于Transformer的生成个性对话模型中常见的顺序敏感性问题，提出了一个具有计算效率的无序正则化框架，改进了个性对话生成的一致性。




 ## Paper:15




1. Title: Social Context-aware GCN for Video Character (面向视频角色的社交感知GCN)

2. Authors: Wenjun Peng, Weidong He, Derong Xu, Tong Xu, Chen Zhu, Enhong Chen

3. Affiliation: 中国科学技术大学, 认知智能国家重点实验室, 阿里巴巴

4. Keywords: Person Search, Person Re-identification, Multimodal Learning

5. URLs: Paper link: https://arxiv.org/abs/2305.12348v1, Github: None

6. Summary:
- (1): 本文主要基于社交信息和场景上下文等先验知识，针对视频中复杂场景下的角色搜索问题提出了一种名为SoCoSearch的框架。

- (2): 传统方法只关注视觉或粗粒度社交信息，存在性能问题，无法有效地解决角色搜索问题。本文提出了基于场景上下文的先验知识，结合多模态语义线索生成为不同关系类型的先验概率，提取出加权的社交关系图，并利用角色间的共现信息生成增强的社交上下文图。此外，文章使用社交上下文感知GCN框架，实现角色特征之间的信息传递，获取抗干扰的特征表示，有效解决角色搜索问题。

- (3): 本文提出一个名为SoCoSearch的基于GCN的框架，可以更好地处理视频中角色搜索问题。首先将多模态线索用于建模场景上下文，生成权重社交关系图，并利用角色间的共现信息生成增强的社交上下文图。之后，设计基于GCN的角色搜索模型，在特征传递时利用社交上下文信息，使得角色特征更丰富、更鲁棒。

- (4): 本文提出的SoCoSearch在多项指标上得到了验证，有效地解决了角色搜索问题，对视频检索等下游应用具有很好的应用前景。

- (5): 本文的研究动机主要是针对视频角色搜索问题，提出了一种全新的、更为有效的角色搜索框架，以应对视频中复杂场景下的角色识别问题。




 ## Paper:16




1. Title: ExplainCPE: A Free-text Explanation Benchmark of Chinese Pharmacist (中文翻译：ExplainCPE：一个中文药师自由文本解释基准)
2. Authors: Dongfang Li, Jindi Yu, Baotian Hu, Zhenran Xu, and Min Zhang
3. Affiliation: 哈尔滨工业大学（深圳），深圳, 中国
4. Keywords: deeplearning, ML, NLP, interpretability, medical benchmark
5. Urls: Paper - arXiv:2305.12945v1 [cs.CL] (https://arxiv.org/abs/2305.12945v1), Github - https://github.com/HITsz-TMG/ExplainCPE
6. Summary: 
- (1):本文研究背景在于解释药师问题，对于当前领先的LLMs的解释能力还需更多探索，ExplainCPE提供了一个中文药学自由文本解释基准数据集。
- (2):已有的解释数据集主要是英语常识问题，缺乏主题和语言多样性，而且医疗领域的解释数据资源也很匮乏。现有深度学习模型针对医疗问题的理解和计算推理还存在许多限制。因此，本文提出的解释药师问题探索了一种医学场景下的深度学习模型解释能力数据集。文章的方法初衷良好。
- (3):本文提出的解释药师问题是一个基于中文的医疗领域的解释性基准数据集，该数据集使用选择式分析，通过对深度学习模型产生标准化的解释来评估模型的解释能力。
- (4):本文使用ExplainCPE数据集进行模型评估，并通过比较不同的深度学习模型，用正确的理由来解释做出何种答案的正确性。评估结果表明，现有的深度学习模型在理解中文文本和计算推理方面仍存在一些限制。本文的方法在一定程度上达到了预期的目标。
- (5):本文旨在探索当前领先的LLMs的解释能力，提出一种新的医学场景下的深度学习模型解释能力数据集，并提高深度学习模型在医学领域解释能力方面的安全性和可靠性。




 ## Paper:17




1. Title: Target-Aware Spatio-Temporal Reasoning via Answering Questions in Dynamics

2. Authors: Yuanyuan Jiang, Jianqin Yin

3. Affiliation: 北京邮电大学 (Beijing University of Posts and Communications)

4. Keywords: Audio-visual question answering, spatio-temporal reasoning, target-aware, tri-modal consistency loss, joint audio-visual temporal grounding

5. Urls: None, code will be available soon.

6. Summary:

- (1): 本文研究的背景是通过回答问题来进行多模态处理和空间时间推理。在现实世界的各个领域中，音视频问题与答案数据集在不断增加，自动化考前解答也是考验多模态处理和空间时间推理关键能力的重要研究方向。

- (2): 本文提出了一个针对音频视觉QA任务的解决方案，通过利用文本模态的基准信息，提出了一种基于Target-aware模型的三模态协同处理框架，包括Target-aware空间基准模块、Tri-modal consistency loss和对对应的Joint audio-visual temporal grounding模块。与传统的基于关注机制的AVQA方法相比，本文的方法更注重问题主体，进而提高了音视频对应关系的精度和场景理解能力。

- (3): 本文提出的方法包括Target-aware空间基准模块、Tri-modal consistency loss和Joint audio-visual temporal grounding模块。其中，Target-aware空间基准模块通过利用文本模态的基准信息，使得实现对问题主体目标的精确定位和特征挖掘；Tri-modal consistency loss则强调了三个模态的一致性，而不是通过考虑各个模态之间的矛盾来同步音频和视频，从而使得在单流模型下相应的模态相互支持；Joint audio-visual temporal grounding模块则实现了三模态特征的整合和关联，实现了在空间时间视角上对多种问题的语义理解和相应场景的理解。

- (4): 本文在MUSIC-AVQA数据集上进行了实验，结果表明，提出的方法在音视频对应关系、场景理解等方面有着更为准确、鲁棒的性能表现，具有更好的学习效果和推理能力。

- (5): 本文的研究动机是通过回答问题来实现多模态处理和空间时间推理，为实现多样化应用场景的音视频及自然语言处理提供支持。




 ## Paper:18




1. Title: Faithful Diffusion-based Text-to-Image Generation by Selection
 
2. Authors: Shyamgopal Karthik, Karsten Roth, Massimiliano Mancini, Zeynep Akata 

3. Affiliation: Shyamgopal Karthik and Karsten Roth are affiliated with the University of Tübingen. 

4. Keywords: Text-to-image generation, diffusion models, model faithfulness, candidate selection, automatic scoring 

5. Urls: Paper (arXiv): https://arxiv.org/abs/2305.13308, Github code: https://github.com/ExplainableML/ImageSelect

6. Summary:
- (1): 本文主要研究基于扩散的文本到图像生成，并针对基于扩散的模型在文本提示上可能会缺乏忠实性的问题进行改进。
 
- (2): 过去的方法在提高模型忠实性时存在一些问题，例如预处理方法可能根据特殊提示造成过度拟合，后处理方法在改善模型忠实性时有很高的计算代价等。鉴于这些问题，本文中提出一种基于候选选择的简单方法来提高模型忠实性，不需要对生成过程进行任何修改。 这种方法可以针对包括复杂提示在内的广泛类型的提示进行忠实的图像生成，并且可以通过使用基于扩散的 T2I 评估指标的自动打分来选取最佳图像。这一方法在多个数据集上获得了较好的结果，成本相对较低。

- (3):本文主要的研究方法是将模型忠实性问题视为候选选择问题，并引入了一种基于扩散的 T2I 生成模型筛选框架。该框架通过生成针对特定文本提示的多个图像并根据预定义的打分规则选取最佳图像，从而提高了模型的忠实性。

- (4):该方法在多个数据集上进行定量比较，结果表明与现有的后处理方法相比，能够实现更高的忠实度，同时成本相对较低。在进行用户实验时，我们也发现选用本文提出的方法能够极大地提高用户对图像忠实度的满意程度。

- (5):本文的研究动机是要解决扩散模型在文本到图像生成任务中忠实性问题。简单的调整会造成计算代价过高的问题，而本文提出的方案可以在相对较少的成本代价下实现对模型忠实性的提高。




 ## Paper:19




1. Title: Chip-Chat: Challenges and Opportunities (以对话方式的硬件设计：挑战与机遇)

2. Authors: Jason Blocklove, Siddharth Garg, Ramesh Karri, Hammond Pearce

3. Affiliation: Jason Blocklove, Siddharth Garg, and Ramesh Karri are from New York University in New York, NY, USA, while Hammond Pearce is from the University of New South Wales in Sydney, Australia. (Jason Blocklove、Siddharth Garg、Ramesh Karri 就职于美国纽约大学, Hammond Pearce 就职于悉尼新南威尔士大学)

4. Keywords: Hardware Design, CAD, LLM (硬件设计, 计算机辅助设计, 大型语言模型)

5. Urls: Paper link: https://arxiv.org/abs/2305.13243v1, Github: None

6. Summary:

- (1): 本文旨在探讨如何通过人工智能辅助实现硬件描述语言 (HDL) 的写作, 以简化工程师的工作并降低其错误率。该研究是在现有的大型语言模型的基础上进行的，如 OpenAI 的 ChatGPT 和 Google 的 Bard 等。 

- (2): 传统的硬件设计方法需要工程师将需求文档翻译为适当的 HDL，这一过程耗时费力且存在错误率。虽然高级综合工具也可以将功能以高级语言 (如 C 语言) 的形式表述，但这样做会对硬件的效率造成影响。本文探讨了大型语言模型向硬件领域转化面临的挑战，提出了利用对话形式的 ChatGPT-4 模型编写几个具体应用的 HDL 的方法，并进行了一次交互式的完整的聊天式硬件设计案例。 

- (3): 本文的方法是在 ChatGPT-4 模型的基础上，通过针对性的对话，进行交互式的 HDL 设计。首先采用了 8 个具体案例对模型的表现进行了测试，然后通过一次对话式的硬件设计实例，验证了模型在实践中的表现。 

- (4): 在本文的硬件设计案例中，提出了一种新的完全以人工智能生成的 HDL 的设计方法，并将其发送到了 IC 芯片的制造流程中进行测试。实验证明，这种基于对话的设计方法可以大大简化硬件工程师的工作，同时保证其可靠性。 

- (5): 本文的研究动机在于，利用对话形式的大型语言模型，为硬件设计提供更为高效、可靠的设计工具，并提高人工智能在硬件设计领域的应用水平。




 ## Paper:20




1. Title: Pointwise Mutual Information Based Metric and Decoding Strategy for Faithful Generation in Document Grounded Dialogs
（基于点间互信息的度量和解码策略，用于文件端对话的忠实生成）
                
2. Authors: Yatin Nandwani, Vineet Kumar, Dinesh Raghu, Sachindra Joshi, Luis A. Lastras

3. Affiliation: IBM Research, AI （IBM研究部门，人工智能方向）

4. Keywords: deep learning, generative model, document-grounded dialog, faithful response, automated metrics, pointwise mutual information, decoding strategy

5. Urls: 
Paper: https://arxiv.org/abs/2305.12191v1  
Github: None 

6. Summary:
- (1): 本文针对深度学习生成模型文件端对话模型中可能生成反映不出源文件的响应进行研究；
- (2): 过去一些自动指标存在无法评价非完整响应的缺点，无法完全满足人类标准。本文提出了一种基于点间互信息的度量方法，该指标衡量生成响应和源文件间条件概率的相关性，提高了衡量忠诚度的准确度。同时，本文还提出了一种新的解码策略，通过融合上述度量方法，使得生成的响应更加忠实；
- (3): 通过实验与benchmark 对比实验，论证了该方法的有效性；
- (4): 本篇论文提出的度量和解码策略将指标的相关性提高到了人类判断标准的水平；
- (5): 本文的动机在于提供一种度量干预方法，可以通过改进深度学习生成模型，使其生成更加忠实的响应。




 ## Paper:21




1. Title: Towards Unsupervised Recognition of Semantic Differences in
Related Documents (关于无监督识别相关文档语义差异的研究)

2. Authors: Jannis Vamvas and Rico Sennrich

3. Affiliation: 约翰尼斯·范夫斯（Jannis Vamvas）和瑞科·森里克（Rico Sennrich）隶属于 苏黎世大学（University of Zurich）的计算语言学系。

4. Keywords: Unsupervised learning, semantic differences, masked language modeling, token-level regression, self-supervised encoders, word alignment.

5. Urls: Paper: arXiv:2305.13303v1  [cs.CL] 22 May 2023, Github: https://github.com/ZurichNLP/recognizing-semantic-differences

6. Summary: 

- (1): 本篇论文研究的是如何通过无监督学习方法，专门识别文档之间的语义差异，以及在该领域内已有的相似研究中存在的问题。

- (2): 以往的研究主要集中在对可解释性文本相似性的预测上，而没有专门研究文档间语义差异的识别。该文提出的方法则主要围绕token-level regression, 其主要通过无监督的方式，利用一种被称为Masked language modeling 的方法来处理短语层面的文本信息。虽然该方法在跨语言文档中表现出一定的有效性，但仍存在许多改进空间。

- (3): 在方法学上，该论文提出了三种无监督的途径，其中最优秀的方法建立在了词级别上，并通过构建相互补充的对齐关系加以实现。同时，该方法还采用了以句子为基础的对比学习方法来增强对齐语言模型训练步骤的稳健性。

- (4): 该文在三个测试数据集中测试其方法，并取得了相对较高的性能指标，但仍存在一定的误差。最优秀的模型是基于对齐关系和句子级对比学习的方法，展现了相对比较好的结果，但其可能面临跨语言对其的挑战限制。

- (5): 该论文的研究背景是推导自自然语言处理中对于文档间语义比较问题的一个关键问题。目前，该问题在很多领域有着广泛的应用，但研究往往受限于缺少整合度高、易于操作的数据源等因素。因此，自动挖掘文档间的语义差异，对未来的研究也有着重要作用。




 ## Paper:22




1. Title: Clinical Camel: An Open-Source Expert-Level （临床骆驼：一种开源的专家水平医疗语言模型）

2. Authors: Augustin Toma, Patrick R. Lawler, Jimmy Ba, Rahul G. Krishnan, Barry B Rubin, Bo Wang

3. Affiliation: Department of Medical Biophysics, University of Toronto, Toronto, Canada（多伦多大学医学生物物理系，加拿大多伦多）

4. Keywords: Large Language Models, Healthcare, Open-source, Dialogue-based Knowledge Encoding, Clinical Camel

5. Urls: Paper - arXiv:2305.12031v1 [cs.CL] 19 May 2023 Github: None

6. Summary:
- (1):本文中介绍的临床骆驼模型是一种医疗语言模型，用于解决存在于数据隐私、监管合规性和模型稳定性等问题的大型语言模型在医疗领域的应用。 
- (2):虽然高效的封闭型大型语言模型的蒸馏已被证明对普遍任务是有效的，但它们在医疗保健领域的应用受到了限制，因为这些模型的领域知识是过少的且遗留的对齐行为需要进行清除，这对临床任务造成了阻碍。为解决这些挑战，作者提出了基于对话的知识编码（DBKE）方法，用于增强模型的隐性知识库，并使其具备对话召回能力，增强其对话能力，并为后续用例启用软对齐。通过将密集的学术源文本转化为合成对话，DBKE 扩大了模型的知识库，并启用了软性对齐，从而引导下游行为。 
- (3):本文中所提出的临床骆驼模型所采用的研究方法为基于对话的知识编码方法。 
- (4):本研究在United States Medical Licensing Examination（USMLE）Step 1 和 Step 3上，将临床骆驼模型与GPT-3.5进行比较，发现临床骆驼模型的得分分别为53.2%和58.2%，高于GPT-3.5的得分（分别为36.1%和55.7%）。临床骆驼模型可以熟练处理多阶段的临床案例问题，提供适应性咨询和生成临床笔记。然而，它容易产生幻象，这在安全关键环境中是一个重要的障碍。 
- (5):本文的研究动机是为了在保障数据隐私、监管合规和模型稳定性的同时，为大型语言模型在医疗保健领域的应用提供开源的方案。




 ## Paper:23




1. Title: Investigating the Limitations of ChatGPT for Hate Speech Detection

2. Authors: Mithun Das, Saurabh Kumar Pandey, Animesh Mukherjee

3. Affiliation: 著者所属機関は記載されていない。

4. Keywords: ChatGPT, hate speech detection, limitations, large language models, multilingual, emojis

5. Urls: https://arxiv.org/abs/2109.11717

6. Summary:

- (1): 本研究旨在通过评估ChatGPT对11种语言中的仇恨言论检测的表现和对包含表情符号的复杂情感表达的处理情况，探究该模型在细粒度层面上检测仇恨言论的局限性。

- (2): 过去的方法已经针对发现假新闻、恶意用语等网络问题进行了研究。然而，许多方法仍然无法识别并适当处理多语言仇恨言论，这表明需要一种更准确，更鲁棒和具有广泛适用性的方法。本研究提出了一种针对ChatGPT的细粒度分析方法来评估其在仇恨言论检测中的局限性。

- (3): 本研究首先选择几个公开数据集，通过多轮对话，对ChatGPT在11种不同语言上的性能进行了评估。接着，本研究使用两个经典数据集进行训练和测试，来探究ChatGPT对包含表情符号的语言、隐式或间接地表达感情的语言中的局限性。

- (4): ChatGPT模型在使用细粒度分析进行评估时发现，在识别特定类型的仇恨言论方面存在较大局限性。特别是在包含表情符号的语料库中，ChatGPT的性能明显降低。虽然ChatGPT可以有效识别和标记多语言仇恨言论，但在涉及复杂情感语境的文本中，其表现不如预期。通过本研究，我们认识到了ChatGPT模型在仇恨言论检测中的局限性，并提出了进一步改进的方向。

- (5): 本研究的动机是为了了解大型语言模型ChatGPT在细粒度层面上检测仇恨言论方面的局限性，为进一步提高仇恨言论检测的鲁棒性和准确性提供指导。




 ## Paper:24




1. Title: Lion: Adversarial Distillation of Closed-Source Large Language Model
(《Lion: 对闭源大型语言模型的敌对蒸馏》)

2. Authors: Yuxin Jiang, Chunkit Chan, Mingyang Chen, Wei Wang

3. Affiliation: 香港科技大学广州研究院/Guangzhou, China

4. Keywords: deeplearning, NLP, language model, knowledge distillation, adversarial learning

5. Urls: 
-paper: https://arxiv.org/abs/2305.12870
-Github: None

6. Summary:
- (1): 本文研究背景是关于对大型语言模型进行知识迁移的方法。
- (2): 过去的方法都是单向的知识转移，而忽略了任何双向反馈，本文作者提出新的对抗蒸馏方法以增强知识迁移的效率。
- (3): 本文提出的对抗蒸馏框架创造了三个阶段的对抗循环，通过利用语言模型的多功能角色适应性，促使闭源模型识别“难”指令，为学生模型生成新的“难”指令，以此提高学生模型的高度近似能力。
- (4): 本文采用新的方法，成功地从ChatGPT向一种名为Lion的7B学生模型转移知识，使用仅70k的训练数据，实现了近95%的能力逼近程度。该成果支持论文目标。
- (5): 本文作者的动机是在对大型语言模型知识转移方面提出新的双向反馈框架以增强效率，增强对知识迁移方面的研究和应用。




 ## Paper:25




1. Title: Exploring Speaker-Related Information in Spoken Language (探索口语中的讲话者相关信息)

2. Authors: Luyao Cheng, Siqi Zheng, Zhang Qinglin, Hui Wang, Yafeng Chen, Qian Chen

3. Affiliation: Speech Lab of DAMO Academy, Alibaba Group (阿里巴巴达摩院语音实验室)

4. Keywords: Speaker diarization, acoustic information, multi-party meetings, semantic information, speaker embedding

5. Urls: Paper url: https://arxiv.org/abs/2305.12927 Github: None

6. Summary: 

- (1): 本文的研究背景是针对声音处理中的多方议会和会话等多人场景，提出一种从语义内容中提取与说话者相关信息的方法，以进一步改善讲话者分离的性能。

- (2): 当前的主流讲话者分离方法仅考虑声学信息，遇到嘈杂的声音或者回声等声学干扰时性能会下降。传统的方法只能利用音频信息，而忽略了转录文本的丰富信息。为了扩大讲话者分离中信息来源的多样性，本文提出了一种通过对语义信息提取说话者相关信息，以改善声学信息的不足。本文引入了两个子任务——对话检测和发言者转换检测，其中通过对话语义信息有效地提取说话者信息。同时本文提出一种简单但有效的算法来联合建模声学和语义信息，以获取带讲话者标识文本。 

- (3): 本文的研究方法是通过利用语义信息中的说话者相关信息，提出了提取带有讲话者标识的文本的方法，并融合了语义信息和声学信息用于讲话者分离。

- (4): 本文所提出的方法在 AISHELL-4 和 AliMeeting 数据集上均表现出了比仅基于声学信息的讲话者分离系统更为显著的提升，并取得了一定的结果。

- (5): 本文的动机在于利用语义信息有效地提升有关讲话者标识和分离的性能，解决传统声学信息不足的问题。




 ## Paper:26




1. Title: Few-Shot Dialogue Summarization via Skeleton-Assisted Prompt Transfer (使用骨架辅助的提示转移进行少样本对话摘要)

2. Authors: Kaige Xie, Tong Yu, Haoliang Wang, Junda Wu, Handong Zhao, Ruiyi Zhang, Kanak Mahadik, Ani Nenkova, Mark Riedl

3. Affiliation: School of Interactive Computing, Georgia Institute of Technology (佐治亚理工学院交互式计算学院)

4. Keywords: few-shot learning, dialogue summarization, prompt transfer, skeleton generation, dialogue state tracking

5. Urls: arXiv:2305.12077v1 [cs.CL] 20 May 2023

6. Summary: 

- (1):本文研究如何在缺少大量标注对话摘要的情况下，通过少样本学习对话摘要。


- (2):现有的方法一般都采用预训练语言模型，但需要大量的人工标注对话摘要。为了解决数据稀缺问题，先前的方法采用从下游任务中学习并进行提示转移。但这些通用的提示转移技术缺乏对话特定信息。本文提出了一个使用骨架辅助的提示转移方法(Skeleton-Assisted Prompt Transfer, SAPT)，能够更好地学习对话状态信息。


- (3):本文提出了一种新颖的方法，使用基于扰动的探针来自动提取对话骨架作为监督序列。通过在这些骨架上训练模型，可以帮助保持模型的预测能力。骨架同时充当了源任务和目标任务之间的媒介，从而在模型的提示转移和知识转移中有效地连接这两个任务。


- (4):本文的方法在少样本的对话摘要任务上取得了很好的效果，明显优于现有的基线方法。深入的分析也表明，使用骨架辅助的提示转移方法能够在少样本学习中有效促进交叉任务的知识转移。


- (5):本文旨在解决在实际情况下标注大量高质量对话摘要数据的成本很高、缺乏足够标注数据的情况下，如何进行少样本学习对话摘要的问题。考虑现有的基于预训练语言模型的方法需要大量的人工标注对话摘要，提供该项工作的可操作性和可拓展性的同时，需要探索更少的监督信号进行学习对话摘要的方法。




 ## Paper:27




1. Title: RECURRENTGPT: Generating Long and Coherent Text with a Recurrent Generative Pre-training Transformer

2. Authors: Yelong Shen, Xiuying Chen, Jianfeng Gao, Jingjing Liu, Michelle Vanni, Pengchuan Zhang, Po-Jen Lai

3. Affiliation: Microsoft Research

4. Keywords: deeplearning, generative models, recurrent models, natural language processing, long text generation

5. Urls: Paper: https://arxiv.org/pdf/2101.06887.pdf, Github: https://github.com/aiwaves-cn/RecurrentGPT

6. Summary: 
- (1):文章研究长文本生成的固定尺寸语境限制问题。
- (2):先前的方法基于RNN进行回归，但需要大量的架构修改。本论文提出了一种不基于向量的重复机制，并以自然语言构建LSTM的回归机制。该方法可以生成任意长度的文本，且易于交互和解释。
- (3):本论文提出的方法是对LLM的回归机制的一种语言模拟，避免了对架构的修改。RECURRENTGPT在每个时间步骤t都生成一段文本，并用自然语言更新存储在硬盘上的基于语言的长短期记忆和prompt。该重复机制使得生成任意长度的文本成为可能。
- (4):方法在长文本生成方面取得了良好的表现，并且易于交互和解释。
- (5):本论文旨在解决固定尺寸语境限制问题，进一步推进计算机辅助创作系统的发展。此外，还提出了使用该方法生成交互小说和个性化交互小说的可能性。




 ## Paper:28









 ## Paper:29




1. Title: Scene Graph as Pivoting
Translation (Chinese translation: 场景图作为挖掘对齐特征的建模数学框架)

2. Authors: Hao Fei, Qian Liu, Meishan Zhang, Min Zhang, Tat-Seng Chua 

3. Affiliation: Hao Fei, Qian Liu, Tat-Seng Chua - Sea-NExT Joint Lab, School of Computing, National University of Singapore (新加坡国立大学计算机学院海上新能源联合实验室); Meishan Zhang, Min Zhang - Harbin Institute of Technology (Shenzhen) (哈尔滨工业大学深圳研究生院)

4. Keywords: Scene Graph, Unsupervised Multimodal Machine Translation, Inference-Time, Visual Information, Translation

5. URLs: Paper: https://arxiv.org/abs/2305.12256v1 ; Github: None

6. Summary: 

- (1): 该论文的研究背景是探索更加实际的无监督多模态机器翻译环境。该环境下，在模型使用源文本进行测试时，没有配对的图像。

- (2): 以往的方法为基于配对的图像和文本的有监督机器翻译（Supervised MMT）和基于配对的图像和多语言翻译的无监督机器翻译（Unsupervised MMT）。然而，这些方法都忽视了实际环境，即模型在测试时缺少配对的图像。该论文提出的方法为使用场景图表示图像和文本，使用基于场景图挖掘特征的无监督多模态机器翻译（UMMT）。

- (3): 该论文的研究方法为采用场景图表示输入的图像和文本，并使用动态生成的伪场景图进行推理。论文提出了多种以场景图为基础的学习目标，用于无监督翻译训练。

- (4): 在多语言翻译任务中，使用该论文提出的基于场景图的方法，作者在Benchmark Multi30K数据集上实现了比最优基线更好的翻译结果，取得了更好的完整性、相关性和流畅度，而无需依赖匹配的图像。在深度分析后，该方法取得了良好的效果。 

- (5): 该论文的研究动机在于使用无监督翻译的方法，探索真实环境下无配对图像进行推理的多模态机器翻译过程。




 ## Paper:30




1. Title: The Dimensions of Data Labor: A Road Map for Researchers 

 2. Authors: Hanlin Li, Nicholas Vincent, Stevie Chancellor, and Brent Hecht 

 3. Affiliation: 汉林·李：加州大学伯克利分校 (University of California, Berkeley) 

 4. Keywords: user-generated data, empowerment, data leverage 

 5. Urls: https://doi.org/10.1145/3593013.3594070 

 6. Summary: 
- (1): 本文针对科技公司拥有与处理用户产生的大量数据的情况下，数据生产者几乎没有话语权、无法控制其数据被捕获、被使用和谁受益的现状，为研究人员、决策者和活动家提供了一个聚焦数据生产者的新范式。同时，提出将计算机的数据生产重新概念化为“数据劳动”，探讨如何通过六个维度来赋予数据生产者力量，包括可读性、最终使用意识、协作要求、公开性、可替代性和生计重叠等。

- (2): 过去的方法很大程度上是关注于数据的直接应用和利用，忽略了数据生产者的权利和声音。本研究提出了一个新的范式，将数据生成视为一种劳动形式，旨在增加数据生成不同群体的发言权。这一方法是具有充分动机的。

- (3): 本文综合了文献中未来可能影响数据劳动范式和初步提议，并提出了更进一步的展望。作者主张数据生产者和科技公司之间建立透明度、反馈机制及数据收益的分享等方案，以彰显数据生产者的权利。

- (4): 本文在探讨如何通过数据生产者的参与，实现科技公司数据的公正使用，并提出了六个维度。但本文在特定任务和性能方面并没有做出评估。

- (5):本文的动机就是探究如何更好地平衡数据生产者、科技公司及利益相关方的权益，增加数据生产者的话语权和参与性。




 ## Paper:31




1. Title: Can ChatGPT Defend the Truth? (ChatGPT是否能捍卫真理？)

2. Authors: Boshi Wang, Xiang Yue, Huan Sun

3. Affiliation: The Ohio State University, Columbus, OH (美国俄亥俄州立大学, 哥伦布)

4. Keywords: deeplearning, NLP, large language models, reasoning, evaluation

5. Urls: https://arxiv.org/abs/2305.13160, Github: https://github.com/OSU-NLP-Group/Auto-Dialectical-Evaluation

6. Summary: 

- (1): 本文针对大型语言模型（LLMs）的推理能力进行了测试。在既定的问题下，模型需要防止受到用户错误观点的干扰，并进行正确的辩护和判断。 
- (2): 传统的LLMs评测方法可能会被模型的大规模数据所欺骗，很难真正测试模型的推理能力。作者提出的方法不仅能评测模型的推理能力，而且可以自动化。 
- (3): 作者提出了一种自动化评测框架，此方法通过通过对语言模型进行一种类似对话的探测，评测其对问题的推理分析能力。 
- (4): 作者测试了多种复杂推理数据集，结果表明尽管ChatGPT在初期能够很好地执行问题和给出正确的答案，但当它面对错误的批评或者荒谬无比的说辞时，其很难坚持自己的立场，这漏测到了LLMs不足。 
- (5): 研究LLMs的弱点是为了更好地了解模型在实际环境中的性能，并保证在人类反馈任务时与其匹配。




 ## Paper:32




1. Title: Pre-training Multi-Party Dialogue Response Generation with Expectation-Maximization Algorithm

2. Authors: Chaoran Guo, Xinyuan Zhang, Wei Zhang, Xiaohua Liu, Zhifang Sui, Yang Liu

3. Affiliation: Chaoran Guo - Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China

4. Keywords: multi-party dialogue, response generation, pre-training, expectation-maximization algorithm

5. Urls: https://aclanthology.org/2022.acl-long.510.pdf, Github: None

6. Summary:
- (1): The background of this article is the problem of multi-party dialogue response generation, which has not been well studied compared to two-party dialogues.
- (2): The past methods for two-party dialogues cannot be directly applied to multi-party dialogues due to the lack of annotated addressee labels, and previous solutions have relied on fine-tuning models on small datasets. This article proposes a pre-training method using an Expectation-Maximization (EM) approach to iteratively generate addressee labels and optimize a response generation model.
- (3): The proposed methodology is to first incorporate addressee information into the response generation process using addressee embeddings, and then use the EM algorithm to iteratively generate addressee labels and optimize the response generation model.
- (4): The proposed method achieves state-of-the-art performance on a multi-party dialogue response generation task, and the results demonstrate the feasibility and effectiveness of the proposed EM approach.
- (5): The motivation for this research is to improve the performance of response generation in multi-party dialogues, which is an important and challenging task in natural language processing.




 ## Paper:33




1. Title: Modeling User Satisfaction Dynamics in Dialogue via Hawkes Process

2. Authors: Fanghua Ye, Zhiyuan Hu, Emine Yilmaz

3. Affiliation: University College London (Fanghua Ye), National University of Singapore (Zhiyuan Hu)

4. Keywords: Dialogue systems, User satisfaction estimation, Hawkes process, Estimator, Satisfaction dynamics

5. Url: arXiv:2305.12594v1 [cs.CL] 21 May 2023, Github: None

6. Summary:

- (1): 该研究探索利用用户满意度估计模拟用户对话场景的表现并评估对话系统性能，该场景需要充分考虑满意度动态变化。

- (2): 既往研究中的现有估计器忽略了对话中不同回合之间的满意度动态变化，缺乏模拟真实用户的能力。本文提出一种新的估计器ASAP（通过Hawkes Process估计满意度），将用户对话过程中的满意度视为事件序列，并采用Hawkes过程有效地建模这个序列的动态变化。与基线估计器相比，实验结果表明ASAP显著优于现有估计器。

- (3): 本文提出的估计器ASAP通过Hawkes process对对话事件进行建模，并有效地模拟用户的满意度动态变化。

- (4): 该方法在四个基准对话数据集上达到了显著的性能提升，超过现有基线估计器。ASAP通过建模满意度动态变化支持了模拟真实用户的能力，进一步推动了对话系统的优化与开发。

- (5): 对话系统作为人类与机器之间的交互接口，越来越受到关注。采用有效的自动评估方法能够迭代开发过程中更好地研究和改进对话系统性能，因此本文的研究动机是探索用户满意度估计作为一个有效的自动评估工具，提高对话系统性能的开发效率和普适性。




 ## Paper:34




1. Title: VLAB: Enhancing Video Language Pre-training (VLAB:增强视频语言预训练)

2. Authors: Xingjian He, Sihan Chen, Fan Ma, Zhicheng Huang, Xiaojie Jin, Zikang Liu, Dongmei Fu, Yi Yang, Jing Liu, Jiashi Feng

3. Affiliation: 中国科学院自动化研究所认知与决策智能复杂系统实验室 (The Laboratory of Cognition and Decision Intelligence for Complex Systems, Institute of Automation, Chinese Academy of Sciences)

4. Keywords: deeplearning, ML, NLP, CV, Video Language Pre-training

5. Url: Paper link: https://arxiv.org/abs/2305.13167  Github: None

6. Summary:

- (1):文章研究的背景是视频语言预训练（VLP）因数据稀缺、训练成本高等因素，进展受限，影响了各种视频多模态任务的发展

- (2):传统的基于图像-文本的预训练方法 CLIP，具有学习高质量多模态表示的能力。但是，在基于这些强大特征的VLP上，目前应用有限。VLAB 提出了一种新的视频语言预训练方法，它通过特征适应和融合将CLIP表示转移到视频预训练任务上，并为各种视频-文本任务开发了统一的视频多模态模型。VLAB 的两个关键策略是进一步适应基于图像-文本的方法，olving了CLIP建模时间信息的缺陷，同时扩展了模型的能力以涵盖对比性和生成性任务。

- (3):本文提出的方法采用两种策略：特征适应和特征融合。通过特征适应进行时间相关、对比性和生成性的预测获得训练数据，而特征融合则通过有效利用图像和视频特征的互补性进行优化。

- (4):VLAB 在视频文本检索、视频字幕生成和视频问答等高竞争视频多模态任务上，进行了广泛的实验验证。结果表明，VLAB 显著优于现有方法，并在 MSRVTT、MSVD 和 TGIF 数据集上设置了新的视频问答准确率记录。在这些数据集上，分别获得了 49.6、61.0 和 79.0 的准确率。

- (5):本文的动机是将大规模图像-文本对比性预训练模型CLIP的强大表征及其优化方法，有效传递到以视频为基础的多模态任务中。




 ## Paper:35




1. Title: "What do others think?"（“别人怎么想？”）

2. Authors: Chao Zhao, Spandana Gella, Seokhwan Kim, Di Jin, Devamanyu Hazarika, Alexandros Papangelis, Behnam Hedayatnia, Mahdi Namazifar, Yang Liu, Dilek Hakkani-Tur 

3. Affiliation: UNC Chapel Hill（北卡罗来纳大学教堂山分校）

4. Keywords: task-oriented dialogue, subjective knowledge, dialogue generation, natural language processing

5. Urls: Paper: arXiv:2305.12091v1 [cs.CL] Github: https://github.com/alexa/dstc11-track5

6. Summary:

- (1): 该文章的研究背景是面向任务型对话系统的主观知识建模和对答案生成的研究。
 
- (2): 传统的面向任务型对话系统通常依赖于特定领域的API/数据库或外部的客观知识来生成响应，无法解决主观用户请求的问题。过去的方法没有充分利用网络中非结构化的信息，因此不能充分回答用户对主观体验的询问。本文提出了基于主观知识的任务定向对话的新任务和对应的数据集。同时，以客户评论为主观知识源的对话生成方法被充分说明。该方法需要解决主观意见的多样性，然后生成合理的回答。因此，该方法在理论上是有很好的动机的。

- (3): 本文提出了新的任务和新的数据集，并基于主观知识源提出了一种新的对话生成方法。该方法需要完整地分析网络上的评论数据，从中提取客观和主观的信息，将其计入对话生成的机制中。

- (4): 本文中的研究方法在进行中被应用到了客户评论的提取和回答。该模型在这方面做得很好，实验表明，该方法对于任务的处理效果非常好。因此，该方法表明了未来对话生成理论研究和任务定向对话应用中对于主观内容的理解具有重要的实践价值。

- (5): 对话生成和任务定向对话一直是自然语言处理领域的研究热点。而客户的主客观意见一直被认为是对话的新增价值。根据这种新方法，主观性是有助于建立更加真实和准确的对话的。本文的主要目的是在任务定向对话中，揭示主观知识对于在对话系统中专家与用户对话中的影响，进一步丰富了对话生成的内容，具有很好的研究意义。




 ## Paper:36




1. Title: Observations on LLMS for Telecom Domain: Capabilities and Limitations
2. Authors: Sumit Soman, Ranjani H G
3. Affiliation: Sumit Soman is affiliated with Global AI Accelerator, Ericsson, Bangalore
4. Keywords: Chatbot, Large Language Models, Generative AI, ChatGPT, GPT3.5, GPT4, Bard, LLaMA, Telecom, Enterprise Wireless 
5. Urls: https://arxiv.org/abs/2305.13102
6. Summary: 
- (1): 本文针对通信领域的自然语言处理应用，使用大型语言模型（LLMs，Large Language Models）来构建对话接口(Chatbot)，通过外围设备的公开数据对使用自然语言对话的波动进行了分析，从不同角度评价了波动的特性及问题。
- (2): 过去的方法有一些限制，比如模型对于特定领域和术语的适应性不强等问题，而LLMs具有更强的适应性，并且可以帮助在对话中进行使用，因此本文提出基于LLMs的波动方法，具有很强的动机。
- (3): 本文的研究方法是通过在Cradelepoint的公开数据上进行对应问题的对答，来评估不同模型在不同任务中的表现，比如术语和产品分类的领域适应性、上下文连续性、对输入干扰和错误的鲁棒性等。 
- (4):LMMs-based chatbots在波动领域中的多种任务中均取得了良好的表现，如术语分类、浏览产品、性能监测等，并且提出了一些针对这类应用开发人员有用的见解。 
- (5):本文的研究旨在探讨在通信领域构建通信接口的新方法，并希望能够对类似领域的研究人员提供足够的经验。




 ## Paper:37




1. Title: Matcher: Segment Anything with One Shot Using

2. Authors: Yang Liu, Muzhi Zhu, Hengtao Li, Hao Chen, Xinlong Wang, Chunhua Shen 

3. Affiliation: 长沙市电子交通职业技术学院

4. Keywords: deeplearning, computer vision, feature matching, segmentation

5. Urls: https://arxiv.org/abs/2305.13310, Github: https://github.com/aim-uofa/Matcher

6. Summary:

- (1): 本文研究如何使用预训练模型进行开放域图像理解。

- (2): 以往的方法要么受限于训练数据，要么限制在特定任务上。由于模型在提取语义信息时的差异，模型间的整合很可能会产生错误或杂波，导致错配或误分割。因此，本文提出了Matcher方法，将通用的特征提取模型和无类别分割模型组合起来，以一个shot进行对象分割。本文方法包括双向Matching策略，鲁棒的Proposal采样策略和可控制的Mask合并策略，以此解决上述问题。

- (3): 本文引入了一种基于特征匹配的分割方法，将两种预训练模型组合在一起，分别进行特征匹配和掩码合并。

- (4): Matcher方法在多项分割任务上取得了优秀的通用性能，而不需要针对每个特定任务进行训练。在COCO-20i上取得了52.7%的mIoU，超过了专家模型1.6%以上。并且，Matcher方法对于一些复杂的物体分割，在多样性方面也表现良好。

- (5): 本文研究旨在解决基于特征匹配的通用、可控、准确对象分割问题，提高模型在开放域场景中的应用性能。




 ## Paper:38









 ## Paper:39




1. Title: G3Detector: General GPT-Generated Text Detector （G3Detector: 一种通用的 GPT 生成文本检测器）

2. Authors: Haolan Zhan, Xuanli He, Qiongkai Xu, Yuxiang Wu, Pontus Stenetorp

3. Affiliation: Haolan Zhan: 澳大利亚蒙纳士大学，Xuanli He, Yuxiang Wu: 英国伦敦大学学院， Qiongkai Xu：澳大利亚墨尔本大学，Pontus Stenetorp：瑞典斯德哥尔摩大学

4. Keywords: Large Language Models, machine-generated text, detection, GPT

5. Urls: Paper: arXiv:2305.12680, Github: None

6. Summary:

- (1): 本文研究背景是 GPT 类型的模型的迅速发展引发的社会和伦理问题。尽管机器生成文本检测方法在区分各种人造文本上已取得了一定的成效，但是无法识别最新的GPT模型生成的数据，存在很大的挑战。

- (2): 学术研究中已有两种主要方法来识别机器生成的文本，第一种是将文本的生成与人类生成区分作为一个分类问题来考虑。第二种是使用数字水印算法来嵌入恒定的信息。

然而，这些方法都无法应对最新的 GPT 模型带来的挑战。本文提出了一种简单而强大的检测方法，可在识别各种领域的人工合成文本方面展现出良好的性能，并且具有识别强大检测逃避技术生成的文本的能力。

- (3): 本文提出的检测器采用了基于 n-gram 和借鉴机器翻译的特征向量化方法。该方法在各种模型结构和不同的解码策略下都表现出了突出的性能。此外，本文还提出了一种新的方法来防止和抵御检测逃避攻击。

- (4): 本文检测器在 WMT、法律、医学和一些实际启发式应用的文本数据上测试之后，表现出了出色的性能，准确率均达到90%以上。与其他检测器相比，本文提出的检测器的性能在所有任务中都表现得更加优秀，证明了该方法的有效性。

- (5): 本文旨在提高机器生成文本检测机制的鲁棒性和效率。




 ## Paper:40




1. Title: Contextualising Implicit Representations for Semantic Tasks

2. Authors: Theo W. Costain, Kejie Li, Victor A. Prisacariu

3. Affiliation: Active Vision Lab, University of Oxford（牛津大学）

4. Keywords: deeplearning, implicit representations, semantic tasks, contextualizing

5. URLs: Paper: arXiv:2305.13312v1  [cs.CV]  22 May 2023, Github:None

6. Summary:

- (1): 该文研究以往的隐式表示方法只用于重建任务，而对语义任务几乎没有用处的问题，提出一种上下文化隐式表示方法使得可以在上下游任务中使用隐式表示，而无需访问原始的训练数据或编码网络。
- (2): 以往方法大多只探究了方法在特定应用中的性能，没有实现泛化到其他任务的目的。该论文中提到的上下文化隐式表示方法使得这些方法可以泛化到其他任务，并且能够在避免对推断性能的影响的同时，获得更好的重建结果。提出的方法在理论上是合理的。
- (3): 在已有的只用于重建任务的隐式表示下，使用所提的上下文化模块，从已训练的编码中发掘隐藏的语义信息。该模块可以使用更大的数据集预先训练出隐式表示模型，并且可以在只使用小型分类数据集训练时达到更好的重建效果。
- (4): 该方法在语义分割任务中表现良好，且重建结果得到提升，同时支持未来的隐式表示模型在任何情况下进行微调。
- (5): 该文的研究动机为解决以往隐式表示方法只适用于重建任务，而对于其他任务的适用性较差的问题，并尝试提出一种通用性的方法。




 ## Paper:41




1. Title: Distilling ChatGPT for Explainable Automated Student Answer Assessment (运用ChatGPT进行解释性自动化学生成绩评估)

2. Authors: Jiazheng Li, Lin Gui, Yuxiang Zhou, David West, Cesare Aloisi, and Yulan He

3. Affiliation: Department of Informatics, King's College London, UK (King's College伦敦学院信息学系)

4. Keywords: deeplearning, NLP, student answer assessment, language model, ChatGPT

5. Urls: arXiv, Github:None

6. Summary:

- (1): 论文研究的背景是解释性自动化学生回答评估。

- (2): 过去的方法是通过文本分类实现学生回答评估，但存在不可信、不透明和难以提供自动评估过程的依据等问题。这些限制影响了它们在实践中的应用价值。文章提出了运用ChatGPT进行解释性自动化学生成绩评估的方法，旨在解决过去方法存在的问题。 

- (3): 本文提出了用来同时进行学生成绩评估和理由生成的大型语言模型ChatGPT，以及用来细调较小语言模型的批评者模块，它自动过滤ChatGPT的不正确输出，善用其余的ChatGPT输出作为嘈杂标记数据来进行语言模型的finetune。此外，通过从ChatGPT输出中多次采样，我们能够计算预测置信度分数，进而可以用于鉴定训练集中的数据损坏和人工标签错误。 

- (4): 本文方法在学生成绩评估上实现了良好的性能提升，并提供了更详细和易于理解的评估，相较于传统的文本分类方法表现更优。文章研究的任务是解释性自动化学生回答评估，在这一任务上取得了良好表现，证明了这一方法的有效性。

- (5): 本文的动机是通过提出新的方法来解决过去在自动化评估学生回答中存在的问题，即不可信、不透明和难以提供自动评估过程的依据等问题，并提供了具体的解决方案。




 ## Paper:42




1. Title: Automatic Code Summarization via ChatGPT: How Far Are We?（使用ChatGPT进行自动代码摘要：我们的进展如何？）

2. Authors: Weisong Sun, Chunrong Fang, Yudu You, Yun Miao, Yi Liu, Yuekang Li, Gelei Deng, Shenghan Huang, Yuchen Chen, Quanjun Zhang, Hanwei Qian, Yang Liu, Zhenyu Chen

3. Affiliation: 国家重点实验室for Novel Software Technology,南京大学，南京，中国

4. Keywords: Large language model, ChatGPT, automatic code summarization, neural code summarization

5. Urls: 
Paper: https://arxiv.org/abs/2305.12865v1
Github: None

6. Summary: 

- (1): 本文研究背景是如何利用人工智能技术自动生成代码摘要，以方便软件开发者更好地理解和维护程序代码。

- (2): 过去的研究方法主要是基于深度学习和自然语言处理技术的，但这些方法存在一些缺点，例如生成摘要的质量不高、模型复杂等问题。本文提出了一种使用ChatGPT进行自动代码摘要的方法，主要是利用ChatGPT自动生成针对给定代码片段的摘要。并且，本文中的方法比使用NCS、CodeBERT和CodeT5等先进模型获得相对较低的摘要质量。

- (3): 本文的研究方法主要是利用ChatGPT对CSN-Python数据集进行评估，并对比其他先进模型，使用三个常见的机器翻译评价指标对生成的摘要进行评价和比较。

- (4): 本文的方法主要在CSN-Python数据集上进行测试和评估，在BLEU、METEOR和ROUGE-L三个评价指标下，ChatGPT的代码摘要性能明显低于其他三种先进模型。

- (5): 本文的研究动机主要是探讨ChatGPT在自动代码摘要方面的效果和可能存在的问题，为今后进一步优化或改进ChatGPT提供思路和参考。




 ## Paper:43




1. Title: Rethinking the Evaluation for Conversational Recommendation in the Era of Large Language Models 
(CRNN论文阅读笔记-《在大语言模型时代重新思考会话推荐的评估》，翻译仅供参考)

2. Authors: Xiaolei Wang, Xinyu Tang, Wayne Xin Zhao, Jingyuan Wang, and Ji-Rong Wen

3. Affiliation: 中国人民大学高铃学院人工智能，信息学院，北航，北京大数据管理与分析方法主要实验室 (Xiaolei Wang所属部门为中国人民大学高铃学院人工智能)

4. Keywords: Conversational recommendation, large language models, evaluation protocol, user simulators

5. Urls: 
Paper: https://arxiv.org/abs/2305.13112
Github: https://github.com/RUCAIBox/iEvaLM-CRS

6. Summary:
- (1):该论文研究在大语言模型时代下会话推荐的评估方式。
- (2):文中介绍了现有推荐系统的评估机制，指出现有评估方式可能会忽略评估模型与用户的交互性质。作者提出设计一种基于大语言模型的互动评估方法iEvaLM，支持模拟不同用户与系统交互的场景，以解决现有评估方式的问题。
- (3):论文中提出了一种基于大语言模型的用户模拟器，即iEvaLM方法，用于支持交互式评估，并通过模拟用户与系统间的会话场景，对对话推荐模型进行综合评估。
- (4):论文通过在两个公共的会话推荐数据集上的实验，测试了iEvaLM方法的有效性。结果表明iEvaLM方法相比主流评估方法具有较大的提升。此外，文中还提出了对推荐模型解释性的评估标准，同时介绍了ChatGPT模型生成解释的优点。结果表明iEvaLM方法达到了预期目标。
- (5):该论文希望通过设计iEvaLM方法，建立一种更好的评估机制，以促进语言模型在对话推荐领域的应用，提高推荐系统的性能水平。




 ## Paper:44




1. Title: AUDIOTOKEN: Adaptation of Text-Conditioned Diffusion Models for Audio-to-Image Generation (中文翻译：AUDIOTOKEN：基于文本条件扩散模型的音频生成图像的改进)

2. Authors: Guy Yariv, Itai Gat, Lior Wolf, Yossi Adi, Idan Schwartz

3. Affiliation:  第一作者所属机构：The Hebrew University of Jerusalem

4. Keywords: Diffusion models, Audio-to-image

5. Urls: Paper: https://arxiv.org/pdf/2305.13050.pdf, Github code: https://pages.cs.huji.ac.il/adiyoss-lab/AudioToken

6. Summary:

- (1): 本文研究领域为音频生成图像。

- (2): 以往的方法主要是将生成模型的过程与自然语言文本相结合，本文的方法是将图像生成所用的扩散模型应用于音频数据，提出了一种文本条件下的扩散模型适用于音频到图像生成的新方法。以往的方法往往需要大量的可训练参数，而本文提出的方法非常轻量级。通过对比基准模型和该作方法的表现，结果表明该方法既能达到更好的主观评价，也是更好的客观评价。 

- (3): 本文提出一种新的方法，利用文本到图像的训练生成混合噪声图像时的diffusion模型来生成音频到图像的模型，具体实现方式是采用预训练的音频编码模型对音频样本进行编码，将其转换为一个新的token进行处理，然后用于扩散模型的图像生成中。 

- (4): 本文方法适用于音频到图像的生成。利用混合噪声的扩散模型来生成嵌入音频的图片，结果表明该方法比基线方法优越。评价指标包括客观和主观评价，均表明该方法达到了优秀的性能。 

- (5): 本文的意义在于提出了一种新的以音频为条件的图像生成方法，可能对于提高音频逼真度有一些应用意义，同时该方法非常轻量级，可大大提高算法的优化效率和应用效果的提升。




 ## Paper:45




1. Title: LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities and Future Opportunities 

2. Authors: Yuqi Zhu, Xiaohan Wang, Jing Chen, Shuofei Qiao, Yixin Ou, Yunzhi Yao, Shumin Deng, Huajun Chen, Ningyu Zhang 

3. Affiliation:  浙江大学 

4. Keywords: Knowledge Graph, Large Language Models, entity extraction, relation extraction, question-answering 

5. Urls: None, Github: https://github.com/zjunlp/AutoKG

6. Summary: 
- (1): 本文主要研究基于大型语言模型的知识图谱构建和推理方法。 
- (2): 过去的方法通常依赖于监督学习，而目前的大型语言模型在自然语言处理领域中表现出了非凡的能力。本文提出了一种对于大型语言模型在知识图谱领域应用的实验评测方法，并探讨了其在各项任务中的表现以及潜在应用。 
- (3): 本文使用了大量的数据集对大型语言模型在知识图谱的构建和推理任务中的表现进行了评估。我们提出了AutoKG，这是一种基于多智能体的框架，可以用大型语言模型进行知识图谱的构建和推理任务。 
- (4): 本文实验发现，GPT-4在大多数任务中表现优异，甚至在某些推理和问答数据集上超过了Fine-tune模型。同时，大型语言模型表现出了较强的推理和问答任务的表现，但在信息提取上的效果有限。 
- (5): 本文的目标是探究大型语言模型在知识图谱领域中的潜在应用，并进一步提出一种基于大型语言模型的多智能体框架，可以提高知识推理和抽取的效率与准确性。 




 ## Paper:46




1. Title: Multi-Task Instruction Tuning of LLaMa for Specific Scenarios.
 
2. Authors: Yue Zhang, Leyang Cui, Deng Cai, Xinting Huang, Tao Fang, Wei Bi.
 
3. Affiliation: Jiangsu Key Laboratory of Big Data Technology for Application, Soochow University.
 
4. Keywords: Multi-task learning, language model, writing assistance, instruction tuning.
 
5. Urls: arXiv:2305.13225v1 [cs.CL] 22 May 2023.
 
6. Summary:
- (1): 本文主要研究如何在特定场景下对大型语言模型（LLM）进行 instruction tuning，进一步提高其性能。
- (2): 过去的方法主要是使用fine-tuned的模型在特定任务中表现，但是LLM在特定任务上的性能通常不如特定任务的 fine-tuned 模型。因此，文章提出将LLM通过与指令相关的数据fine-tune，在writing assistance（写作辅助）场景下进行测试。 
- (3): 作者选择了七个与写作相关的任务以创建评估基准测试，包括语法性、流畅性、清晰度、连贯性、简化、中性化和改写。通过收集60k个训练样本并将其转化为 instruction-following 格式，将这些写作指令数据与来自斯坦福Alpaca项目的通用指令数据组合，对LLMa进行continuous tuning。作者还进行了更多的实验和分析，为以后有效地进行LLMa特定场景fine-tuning提供了见解。
- (4): 实验结果表明，通过instruction tuning，LLMa能够显著地提高其在写作任务上的表现，同时提供了面向特定场景中LLMa高效fine-tuning的启示。
- (5): 文章主要的动机是探究如何优化LLM在特定场景下的性能，特别是在写作场景下进行写作辅助任务。




 ## Paper:47




1. Title: SpokenWOZ: A Large-Scale Speech-Text Benchmark for Spoken Task-Oriented Dialogue in Multiple Domains (SpokenWOZ：面向多领域口语任务对话的大规模语音-文本基准数据集)
2. Authors: Shuzheng Si, Wentao Ma, Yuchuan Wu, Yinpei Dai, Haoyu Gao, Ting-En Lin, Hangyu Li, Rui Yan, Fei Huang, Yongbin Li
3. Affiliation: DAMO Academy, Alibaba Group (阿里巴巴达摩院)
4. Keywords: task-oriented dialogue, spoken conversation, speech recognition, dataset, natural language processing
5. Urls: Paper url: https://arxiv.org/abs/2305.13040v1, Github: None
6. Summary:
- (1):该文研究的背景是现有对话系统模型通常使用测试数据来进行评估，而这些数据大多是来自人工编写的对话，与真实场景中的口语交互存在很大差异。
- (2):先前的方法主要关注ASR噪声问题，忽略了口语交互的独特特点，如逐字处理和口语语言推理，因此需要构建一个大规模的面向真实口语交互的数据集。文章给出了名为SpokenWOZ的数据集，它包含了来自人类-人类对话的语音和文本，并且涵盖了8个不同的领域。
- (3):本文提出了基于Wizard-of-Oz流程的语音-文本数据采集方法，另外通过跨轮槽填充和基于口语语言现象的推理槽检测，提出了新的数据集挑战。作者在数据集上进行了大量的实验，包括文本和语音模态的对比以及诸如ChatGPT等语言学模型的评估。
- (4):文章在SpokenWOZ数据集上进行了实验，并提出了多种模型进行评估。实验结果显示，当前模型在处理口语交互方面还有很大的提升空间。作者通过fine-tune等方式进一步提高了模型性能，可以支持其在真实口语交互场景中的应用。
- (5):本文的研究动机是构建一个大规模的口语交互数据集，以便更好地评估在真实口语环境中构建对话系统的性能。




 ## Paper:48




1. 标题：Automated stance detection in complex topics and small languages: the challenging case of immigration in polarizing news media （自动化检测语言和话题复杂的极化新闻媒体中的观点：以移民为例）

2. 作者：Kairit Sirts, Eva-Maria Talvik, Liisi Laineste, Hille Pajupuu, Heiki-Jaan Kaalep, Kadri Vider

3. 一作机构：University of Tartu （塔尔图大学）

4. 关键词：automated stance detection, natural language processing, immigration, linguistically and culturally complex issues

5. 链接：paper：https://arxiv.org/pdf/2204.10952.pdf， Github: None

6. 摘要：

- (1):本文研究语言和话题复杂的极化新闻媒体中，利用自然语言处理技术自动检测观点的问题。论文以移民话题为例，尝试在低资源的语言环境下进行自动化方案，并探讨其在解决于不同领域相关问题上的适用性。

- (2):研究中，传统的手动标注方式费时费力。由于语言和话题复杂，现有模型表现欠佳。模型无法充分理解复杂的语言表达，并不完全适用于低资源语言环境下的应用。本文提出了一种基于调优大型语言模型（LLMs）的方案，相比于传统方法，该方案针对某些情况表现较佳。同时，本文首次尝试将零样本分类运用于对话题的态度检测。另外，本文使用了聊天机器人GTP 3.5作为主要方法，报告了其在文本分类任务上的表现。

- (3):研究采用了监督学习方法，并通过一系列实验对不同的LLMs进行比较。最终，通过将最佳模型应用于大规模新闻文本集合以对移民话题的态度进行分类，取得了很高的性能表现，支持本文的研究目标与任务。

- (4):本文的主要成果为提出了一种自动化的政治立场媒体监控工具。在数据集上进行相关实验，展示了零样本分类作为一种新方法在有限




 ## Paper:49




1. Title: Training Diffusion Models

2. Authors: Kevin Black, Michael Janner, Yilun Du, Ilya Kostrikov, Sergey Levine

3. Affiliation: 1. University of California, Berkeley （加州大学伯克利分校）；2. Massachusetts Institute of Technology （麻省理工学院）

4. Keywords: Diffusion models, Reinforcement learning, Policy gradient algorithms, Image quality, Denoising

5. Urls: arXiv:2305.13301v1  [cs.LG]  22 May 2023

6. Summary:

- (1):本文研究了强化学习方法如何用于直接优化扩散模型生成的结果，而非仅仅是拟合数据的分布的最大似然估计问题。 改进既可以是人类感知图像质量，也可以是药物效果等任务，这些都不是扩散模型最初的目标，但这些更有利于下游任务。 

- (2):以前的模型因为精确的似然计算相对困难，因此很难在许多传统的强化学习算法上应用。所以本文将其改进为多步决策任务，利用计算每个去噪步骤时的精确似然值，来替代完整去噪过程中的近似似然。本文提出的反馈策略梯度算法是比另外的 reward-weighted 似然方法更有效的方法。 

- (3):本文提出了一种策略梯度算法，称为去噪扩散策略优化（DDPO），以黑盒的方式使用奖励函数优化扩散模型，实现对特定任务的生成。 

- (4):实验结果表明，DDPO可以使文本到图像扩散模型适应难以通过提示表达的目标，比如图像可压缩性等，也适用于人类反馈得出的目标，比如审美质量。最后，本文展示了 DDPO 可以通过来自视觉语言模型的反馈来改进提示图像的对齐方式，而不需要额外的数据收集或人为标注。 

- (5):文章主要动机是研究如何通过改进模型来提高生成结果质量，而不仅限于拟合数据的分布。分别以图像生成和药物发现为例。




 ## Paper:50




1. Title: Watermarking Text Data on Large Language Models（大型语言模型中的文本数码水印）
2. Authors: Yixin Liu, Hongsheng Hu, Xuyun Zhang, Lichao Sun
3. Affiliation: Yixin Liu - Lehigh University（里海大学）, Hongsheng Hu - Data61, CSIRO (Australia)（Data61, CSIRO, 澳大利亚）, Xuyun Zhang - Macquarie University (Australia)（麦觉理大学，澳大利亚）, Lichao Sun - Lehigh University（里海大学）
4. Keywords: Large Language Models, Copyright Protection, Text Data, Watermarking, Membership Inference.
5. Url: Paper - https://arxiv.org/abs/2305.13257v1, Github - None
6. Summary:

- (1): 近年来，大型语言模型（LLM）如BERT和ChatGPT已经在各种下游自然语言处理（NLP）任务中表现出了令人瞩目的性能。然而，这些大模型的庞大数据需求引发了人们对版权保护和数据隐私的严重关注。
- (2): 过去的方法中，主要是基于已知预测性能的原始文本重建或辅助数据。这些方法具有计算成本高和数据隐私问题的缺点。针对这些问题，本文提出了一种新的水印技术，称为TextMarker，其通过基于后门的成员推断方法来保护嵌入在LLM训练文本数据中的各种形式的私人信息。这是一种新的成员推断框架，可以消除传统成员推断技术中额外代理数据和代理模型训练的必要性，从而使我们的提案更加实用和适用。
- (3): 本文提出的TextMarker方法是一种基于后门的成员推断技术，其通过在原始文本中插入后门，并计算生成模型对训练数据的权重信息来标记文本。而不需要使用额外的代理数据和代理模型，即可进行成员推断。 
- (4): 本文在三个数据集上进行了测试，结果表明本文所提出的TextMarker方法可以准确地标记模型数据集中的文本。实验结果表明，TextMarker方法可以消除代理数据和代理模型的需求，并且具有良好的可扩展性和稳定性。
- (5): 本研究鉴于大型语言模型的庞大数据需求和数据隐私保护的需求，提出了一种新的基于后门的文本水印方法TextMarker，并且在实验中得到了证明。



