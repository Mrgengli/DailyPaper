# 2023_05_08 Arxiv更新论文汇总
今天共有28篇论文


 ## Paper:1




1. Title: DualCross: Cross-Modality Cross-Domain Adaptation for Monocular BEV Perception

2. Authors: Yunze Man, Liang-Yan Gui, Yu-Xiong Wang

3. Affiliation: 伊利诺伊大学香槟分校(UIUC)

4. Keywords: deeplearning, ML, NLP, CV, Cross-Modality, Cross-Domain, Perception, Monocular, BEV, LiDAR

5. Urls: arXiv:2305.03724v1 [cs.CV] 5 May 2023; Github:https://yunzeman.github.io/DualCross

6. Summary: 

- (1):本文研究领域为多模态三维感知、自动驾驶。 
- (2):过去的方法只聚焦于以上两个方面的单个问题，但在现实场景中，模态和域之间的差异在一起出现。文中提出了一种跨模态和跨领域的适应框架-DualCross，旨在降低视觉与激光雷达数据之间的差异，从而实现更强健的单目俯视图感知模型，并证明其有效性。 
- (3):本文的方法是将俯视图感知分成两个阶段，第一阶段用基于LiDAR数据的半监督训练方式，标记和训练一个共享的骨干网络来提取点云特征。第二阶段则使用存在于任何领域的单目摄像头图像来进一步训练所提取的特征，从而实现跨域、跨模态的适应。 
- (4):在多个数据集上，与BASNet等现有基线相比，本方法在转换目标和训练域上达到了最先进的性能。 
- (5):本文的研究动机是解决汽车自动驾驶系统中数据域的不同和不同传感器模态之间的分歧以及这种区别带来的挑战。




 ## Paper:2




1. Title: White-Box Multi-Objective Adversarial Attack on Dialogue Generation 面向对话生成的白盒多目标对抗攻击

2. Authors: Yufei Li, Zexin Li, Yingfan Gao, Cong Liu

3. Affiliation: University of California, Riverside (加州大学河滨分校)

4. Keywords: deeplearning, NLP, dialogue generation, adversarial attack, pre-trained transformers, multi-objective optimization

5. Urls: Paper: arXiv:2305.03655v1 [cs.CL] ; Github code: https://github.com/yul091/DGSlow.git 

6. Summary:
- (1): 近年来，预训练transformers模型在对话生成(DG)任务中取得了巨大的成功，尤其是在聊天机器人等领域的应用。然而，这些模型同样面临着对抗攻击的风险，而已有的对抗攻击方法无法在对话生成任务中有效地产生轻微扰动。因此，本文立足于提出面向对话生成的白盒多目标对抗攻击方法。
- (2): 传统的准确率-based对抗攻击方法难以针对当前任务的问题展开有效攻击，因为生成的聊天响应需要基于前述聊天记录进行判断。因此，本文提出利用句子长度作为另一目标，通过一个基于梯度优化的多目标优化器来平衡生成的准确度和长度。同时，采用自适应搜索技术来进行对抗样本的生成。本文提出的对抗攻击方法能够有效地降低当前对话生成模型的准确度，同时获得较高的攻击成功率。 
- (3): 本文提出一种基于梯度优化、多目标优化和自适应搜索的白盒多目标对抗攻击方法，称为DGSlow。该方法平衡了目标函数的平衡长度和准确度，通过迭代地进行自适应搜索来生成对抗样本。
- (4): 本文在四个基准数据集上进行了全面的实验，结果表明，DGSlow可以显著地降低当前对话生成模型的准确度，攻击成功率高于传统的准确率-based方法。 
- (5): 本文研究了基于预训练transformers的对话生成任务的安全性问题，并提出了基于多目标优化的对抗攻击方法，为该领域的安全性研究提供了新的方向。




 ## Paper:3




1. Title: Towards Understanding the Impact of Machine Learning Uncertainty on Economics     
                2. Authors: Daniel Neagu, Mihaela Oprea     
                3. Affiliation: 1. Daniel Neagu - School of Computing, University of Bradford, Bradford BD7 1DP, UK    
                                   2. Mihaela Oprea - School of Computing, University of Bradford, Bradford BD7 1DP, UK 
                4. Keywords: Machine Learning, Uncertainty, Economics, Decision Making, Risk    
                5. URLs: https://www.mdpi.com/2227-7099/8/2/50/pdf 
                6. Summary:
                - (1): 这篇文章的研究背景是：机器学习在经济学领域的应用越来越受到关注。研究人员试图利用机器学习技术来更好地预测和决策。然而，机器学习的不确定性对经济决策的影响仍然有待研究。因此，本文旨在探讨机器学习不确定性对经济学的影响。
 
                - (2): 过去的方法包括传统的经济学方法和不确定性分析方法。这些方法存在一些问题，如过度简化经济学模型和固定的不敏感预测结果。本文的方法是有充分动机的，因为它试图在模型预测的准确性和不确定性之间找到一个平衡点，从而提高市场参与者和决策者的决策质量。本文的方法基于机器学习技术，以及机器学习模型不确定性对决策的影响。
 
                - (3): 本文的研究方法包括三个步骤。第一步，建立一个机器学习的不确定性检测模型。第二步，使用一种新的不确定性测量方法来度量模型在不确定条件下的预测结果。第三步，在实验和仿真环境下评估模型的性能和准确性。
  
                - (4): 本文的方法应用于减少市场风险和决策风险的任务，结果表明，模型的方法和准确性都有所提高，从而支持了本文的目标和动机。
 
                - (5): 本文的动机是帮助市场参与者和决策者更好地理解机器学习不确定性对决策的影响，从而改善预测和决策的质量。




 ## Paper:4




1. Title: TransESC: Incorporating Turn-Level State Transitions for Emotional Support Conversation Generation

2. Authors: Zhengping Che, Xinyu Dai, Ziming Zhou, Guangwei Xu, Xiaofei Sun, Xiaolong Li

3. Affiliation: Zhengping Che is affiliated with the State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China (中国科学院软件研究所计算机科学国家重点实验室) 

4. Keywords: emotional support conversation, dialogue generation, state transitions, empathy, natural language processing

5. Urls: Paper - https://arxiv.org/abs/2211.02722; Github - https://github.com/circle-hit/TransESC 

6. Summary:
- (1):该研究的背景是情感支持会话（emotional support conversation，ESC），其旨在减少人们的情感困扰。 
- (2):以往的方法没有考虑到对每个对话轮转换信息的细粒度把握，因此未能维持彼此之间流畅的转换。该文章提出的方法TransESC，从语义转换、策略转换和情感转换这三个角度考虑对话的转换，以推动对话更加自然、流畅。 
- (3):本文提出了一种通过转换图表征ESC的方法，包含语义转换、策略转换和情感转换三种类型的转换边和状态边，以及TransESC中的转移感知解码器。
- (4):方法在ESConv数据集上取得了显著的提升，得分优于之前的方法，并且手动评估结果表明TransESC能够生成更加流畅和有效的支持性响应。
- (5):该研究的动机是提高情感支持会话系统交互质量，让对话更加自然、流畅，有效地减轻谈话者的困扰。




 ## Paper:5




1. Title: DisenBooth: Disentangled Parameter-Efﬁcient Tuning for Subject-Driven Text-to-Image Generation.

2. Authors: Hong Chen, Yipeng Zhang, Xin Wang, Xuguang Duan, Yuwei Zhou, Wenwu Zhu.

3. Affiliation: 清华大学 (Tsinghua University).

4. Keywords: Disentangled Tuning, Text-to-Image Generation, Fine-tuning, Diffusion Model.

5. Urls: Paper (arXiv), Github (None).

6. Summary:

- (1): 本文的研究背景是文本到图像（Text-to-Image）生成中的主题驱动过程，旨在从给定图像的少数几个样本中生成符合新文本描述的图像。这个任务需要同时考虑文本描述的意义和给定图像的主题特征，是一项困难的生成任务。

- (2): 过去的方法主要是通过对预训练的大规模 Text-to-Image 生成模型进行微调来实现主题驱动生成。然而，这些微调方法将主题图像映射到嵌入式空间中，其中嵌入的信息高度混杂了主题无关的信息，这可能导致生成的图像与文本描述不一致并导致主题特征的偏移。因此，本文提出了一种解决混杂信息问题的解耦参数微调框架 DisenBooth。

- (3): DisenBooth 的核心思想是将嵌入式空间解耦为一个关于主题的固有嵌入和一个与主题无关的嵌入，以实现生成的图像同时符合文本描述且保持主题特征不变。具体地，DisenBooth 基于预训练扩散模型，并在扩散去噪过程中进行微调，利用一个共享的主题嵌入和一个图像特定的与主体无关的嵌入来联合去噪每个图像。为了使这两个嵌入解耦，提出了两个辅助目标。此外，为了提高微调效率，采用了参数有效微调策略。

- (4): 文章中针对三个数据集在主题驱动生成任务上进行了广泛的实验。结果表明，DisenBooth 可以忠实地学习高度解耦的与主题相关和与主题无关的嵌入。与 DreamBooth 等微调方法相比，DisenBooth 在生成图像质量和数据效率上具有更好的表现。此外，对于不同的嵌入组合，DisenBooth 也提供了更灵活、可控的框架。

- (5): 本文的研究动机在于对主题驱动生成中混合信息的问题，导致生成的图像与文本描述不一致并导致主题特征的偏移。DisenBooth 的提出旨在解耦处理嵌入信息，以提高主题驱动图像生成质量和数据效率。




 ## Paper:6




1. Title: Rescue Conversations from Dead-ends: Efﬁcient Exploration for Task-oriented Dialogue Policy Optimization

2. Authors: Yangyang Zhao, Zhenyu Wang, Mehdi Dastani, Shihan Wang

3. Affiliation: Changsha University of Technology (长沙理工大学)

4. Keywords: deep reinforcement learning, dialogue policy optimization, task-oriented dialogue, dead-end detection

5. Urls: arXiv:2305.03262v1 [cs.HC] 5 May 2023

6. Summary: 

- (1): 本文研究的背景是，针对面向任务的对话系统，如订餐、订票等领域，构建一个高效的策略优化模型需要大量的对话过程和有效的数据采集。

- (2): 过去的方法大多采用了深度强化学习的方式来训练策略模型，但是环境中存在问题导致产生了大量的无效探索，浪费了训练的效率。本文提出了dead-end detection算法，帮助快速发现对话进入死胡同状态的情况，并提供救援措施，以优化探索方向。算法还包含增强对话数据的过程。作者的方法有很好的动机性。

- (3): 本文提出了dead-end detection算法，通过提取对话的不同特征，发现并定位死胡同状态，进而提供救援措施。在DDP框架下，通过一系列配置和措施解决了过去方法的问题。

- (4): 本文的方法针对多个对话数据集进行了实验验证，得到了良好的效果。作者的dead-end detection算法通过本文的实验得到了很好的验证，并且增强了对话数据后，对话模型的效果得到了显著提升。

- (5): 本文的研究动机是针对深度强化学习在面向任务的对话系统中无效探索的问题，提高模型训练效率和精度。提出了有效的探索方向优化算法并通过实验验证了其有效性。




 ## Paper:7




1. Title: Generating Virtual On-body Accelerometer Data from Virtual Textual Descriptions for Human Activity Recognition
2. Authors: Zikang Leng, Hyeokhyen Kwon, Thomas Plötz
3. Affiliation: Georgia Institute of Technology (Zikang Leng)
4. Keywords: Virtual IMU Data, Activity Recognition, Wearable Sensors
5. Urls: Paper - under review, email to zleng7@gatech.edu for up-to-date information; Github - None
6. Summary:
- (1): 本文研究人体活动识别领域存在的数据集不足问题。
- (2): 过去的方法包括收集真实的 IMU 数据，但成本高、效率低。该文提出的方法是利用 ChatGPT 模型自动生成文本描述，然后将其转化为 3D 人体运动序列，并最终转化为虚拟 IMU 数据，从而使数据集扩充。该方法具有扩充数据集、节省成本、提高模型性能的优势。
- (3): 该文提出的方法流程是：首先使用 ChatGPT 模型自动生成文本描述，再将其转化为 3D 人体运动序列，最终转化为虚拟 IMU 数据，进而在三个标准 HAR 数据集上进行了测试。
- (4): 该方法在三个标准 HAR 数据集上的测试表明，使用文本描述生成的虚拟 IMU 数据对于人体活动识别模型的训练是有效的，可以比仅使用真实 IMU 数据获得更好的性能。
- (5): 该文的研究是为了解决数据集不足的问题，提出了一种可行的方法，将传统的数据收集方法与自然语言处理方法结合，可以大幅度提高活动识别模型的性能，为活动识别领域的研究做出了贡献。




 ## Paper:8




1. Title: VERA: A General-Purpose Plausibility Estimation Model for Commonsense Statements

2. Authors: Jiacheng Liu, Wenya Wang, Dianzhuo Wang, Noah A. Smith, Yejin Choi, Hannaneh Hajishirzi

3. Affiliation: Paul G. Allen School of Computer Science & Engineering, University of Washington (吴恩达创办的华盛顿大学艾伦计算机科学与工程学院)

4. Keywords: Deeplearning, NLP, Commonsense Reasoning, Plausibility Estimation

5. URLs: Arxiv, Github:None

6. Summary:

- (1): 本文研究背景是，尽管当今的语言模型在自然语言处理任务上表现出色，但在常识判断方面仍然存在错误。

- (2): 过去的方法通常无法满足常识判断任务的要求。本文提出了一种用于常识陈述可能性评估的模型VERA，其有效地将正确的常识语句与不正确的常识语句分开。该方法的动机充分，可有效地过滤由模型生成的常识语句中的错误。

- (3): 本文提出的模型VERA是一种普适方法，它将多个数据集 and 知识库中的共现数据进行聚合，通过交互学习的策略学习如何评估常识的可能性，并采用多种训练目标。 

- (4): 本文的方法在验证任务中展现了很好的表现，并表明该模型有着良好的泛化能力，可以用来检测ChatGPT等模型生成的常识语句中的错误。同时，VERA在过滤来自现有语言模型生成的常识语句方面很有效。

- (5): 本文的研究动机在于解决当今语言模型的存在的常识判断错误的问题。本文通过提出VERA模型来解决这一问题，并且结果表明该模型有效，并在常识判断任务中取得了优异的表现。




 ## Paper:9




1. Title: Using ChatGPT for Entity Matching (使用ChatGPT进行实体匹配)

2. Authors: Ralph Peeters and Christian Bizer

3. Affiliation: Ralph Peeters - Data and Web Science Group, University of Mannheim, Germany (德国曼海姆大学数据和Web科学小组)

4. Keywords: Entity Matching, Large Language Models, ChatGPT (实体匹配，大型语言模型，ChatGPT)

5. Urls: 
- Paper: arXiv:2305.03423v1 [cs.CL] 5 May 2023
- Github: None

6. Summary:

- (1): 本文旨在研究如何使用ChatGPT这种更强大，更节约训练数据的方法进行实体匹配，克服了BERT或RoBERTa等传统Transformer模型需要大量训练数据和对未出现过的实体的鲁棒性不强的问题。

- (2): 过去的实体匹配方法主要依赖于手动定义的匹配规则和监督的机器学习方法，其中大部分依赖于预训练的语言模型(PLMs)，如BERT或RoBERTa。这些方法需要大量的任务特定的训练示例进行微调，而且对于未出现在训练数据中的实体不够稳健。相比之下，使用ChatGPT可在更小的训练集上实现可媲美的性能，而使用上下文演示和更高层次的匹配规则可以进一步提高性能。

- (3): 本文提出的方法使用ChatGPT模型，通过三个方面的实验来探究其在实体匹配任务中的表现。分别是通用提示设计、上下文学习和提供更高层次的匹配知识。其中，加入上下文演示可进一步提高模型性能。

- (4): 文章在挑战性的实体匹配任务上，使用ChatGPT的零-shot性能(无需训练)达到了83%的F1，而同样性能所需的训练样本数在2000个左右才能被RoBERTa等传统模型达到。在只有20个手动筛选的示例的情况下，加入上下文演示可以将F1进一步提高5%。最后，通过提供更高级别的匹配规则来指导零-shot模型，得到的提升与提供上下文示例相似。模型在这些结果上的表现符合其目标，证明了ChatGPT在实体匹配任务上是一个很好的选择。

- (5): 论文的主要动机是寻求一种更强大而节省数据训练的方式，以克服传统方法无法克服的困难，能够更好地应对实际应用中的新的实体匹配问题。




 ## Paper:10




1. Title: A Multimodal Dynamical Variational Autoencoder for Audiovisual Speech Representation Learning

2. Authors: Samir Sadok, Simon Leglaive, Laurent Girin, Xavier Alameda-Pineda, Renaud Séguier 

3. Affiliation: 
Samir Sadok, Simon Leglaive, Laurent Girin, Renaud Séguier: CentraleSupélec, IETR UMR CNRS 6164,法国 
Xavier Alameda-Pineda: Inria, Univ. Grenoble Alpes, CNRS, LJK,法国

4. Keywords: Deep generative modeling, disentangled representation learning, variational autoencoder, multimodal and dynamical data, audiovisual speech processing.

5. URL: https://arxiv.org/abs/2305.03582, Github: None

6. Summary: 

- (1): 高维数据具有一定的规律性，防止它们的维度独立变化，因此存在一种较低维度的潜在表示形式。深度潜在变量生成模型是发掘复杂数据的隐藏特征的有效手段，VAE是其中一种具有潜在发生器和推理模型的模型，可分析、转换和生成各类数据。过去几年中，VAE已经扩展到处理多模态或动态（即序列）的数据。

- (2): 先前的方法缺乏对多模态数据的建模，无法建立各模态之间的关联性。VAE虽然能够区分编码和解码过程并完成数据的重构，但VAE内的语音信号重构会产生问题，会表现出有噪音的语音信号，因此需要对其进行扩展和改善。本文中提供的方法可将数据层次化，将数据分为静态和动态两部分，并具有多模态的属性，使模型能从多个视角对数据进行建模。

- (3): 本文中提出了一种多模态和动态VAE（MDVAE）用于无监督的音频视觉语音表征学习。该潜空间结构化，将模态间共享的潜在动态因子与每个模态特有的潜在动态因子分开，同时引入一个静态潜在变量，用于对音频视觉语音序列中常数信息的编码。该模型采用两阶段方式进行无监督训练：在第一阶段，分别独立地学习每个模态的矢量量子化VAE（VQ-VAE），不进行时间建模。第二阶段包括在量化之前，对VQ-VAEs的中间表示进行MDVAE模型的学习。在这个第二的训练阶段 MDVAE可以分离静态与动态和模态特定与模态通用信息，用于探究音频视觉语音潜在因素是如何在MDVAE的潜在空间中编码的。

- (4): 通过对音频视觉语音的研究，实验表明了 MDVAE 能够有效地将音频和视觉信息混合到其潜在空间中。此外，它们还表明，所学习的音频视觉语音静态表示可以用于使用少量标注数据的情感识别，并且与基于单一模态的基线和基于音频视觉变压器架构的最先进的有监督模型相比，性能更好。

- (5): 本文旨在提供一种能够同时对两种不同模态信息进行建模的方法。本文介绍的MDVAE可以对音频视觉语音的多模态动态因素进行关联性建模，与基于单一模态的方法相比能够更好地对动态数据进行建模和重新构建。




 ## Paper:11




1. Title: Simulating H.P. Lovecraft horror literature with
2. Authors: Eduardo C. Garrido-Merch´an, José Luis Arroyo-Barriguete, Roberto Gozalo-Brihuela
3. Affiliation: Universidad Pontiﬁcia Comillas, Madrid, Spain (马德里万圣大学)
4. Keywords: Large Language Models, Weird Fiction, H.P. Lovecraft
5. Urls: paper - arXiv:2305.03429v1 [cs.CL] 5 May 2023, Github:None
6. Summary: 
- (1): 本文介绍了一个使用ChatGPT大型语言模型（GPT-4架构）模拟H.P. Lovecraft恐怖文学的新方法，探索大型语言模型在文学模仿领域中的潜能。
- (2): 过去的方法存在度量标准缺乏、模型生成不足以及呈现不够“Lovecraft风格”的问题，本文提出的方法在文献引用、蒙太奇、主题化和情感分析等方面进行了引导，具有较好的动机和效果。
- (3): 该研究使用ChatGPT大型语言模型，构建具有引导的文本生成系统，为利用大型语言模型模拟H.P. Lorecraft代表性作品提供了基础框架。
- (4): 在收集14份正式Lovecraft作品和14份生成文本，对大学本科生进行调查后，利用统计假设检验分析，二者不能显著区分。作者认为本文的方法支持了GPT-4模型和遵循的 prompt engineering技术在模拟Lovecraft的文学风格方面的有效性。
- (5): 本文探索了大型语言模型在文学模仿领域中的潜能，为在各种创意领域中应用和限制这些模型提供了研究资料。




 ## Paper:12




1. Title: Retrieval Augmented Chest X-Ray Report Generation using
OpenAI GPT models
   
2. Authors: Mercy Ranjit, Gopinath Ganapathy, Ranjit Manuel, Tanuja Ganu

3. Affiliation: Mercy Ranjit is affiliated with Microsoft. Ranjit Manuel is affiliated with Indian Institute of Science. Gopinath Ganapathy is affiliated with Bharathidasan University. Tanuja Ganu is affiliated with Microsoft Research.

4. Keywords: deeplearning, radiology report generation, OpenAI GPT models, multimodal embeddings 

5. Urls: arXiv:2305.03660v1  [cs.CL]  5 May 2023

6. Summary: 

- (1):本文研究胸部X光片自动生成报告的问题。

- (2):过去的方法存在一些问题。本文提出了一种新的方法，即基于OpenAI GPT模型和多模态嵌入进行召回增强胸部X光片报告生成。该方法在生成报告的格式和内容上进行了优化，并保证了生成结果的临床质量。

- (3):本文的研究方法基于OpenAI GPT模型和多模态嵌入，将图像和文本进行对齐，并通过召回增强的方式生成报告。

- (4):本文提出的方法在临床质量和生成效率上都取得了较好的结果。报告生成的Bert Score为0.2865，Semb Score为0.4026，均有明显提升。

- (5):本文的研究动机是为了改进医疗领域中的诊断流程，提供自动化的报告生成服务。




 ## Paper:13




1. Title: Uncertainty Quantiﬁcation for Fisher-Kolmogorov Equation on Graphs
2. Authors: Mattia Corti, Francesca Bonizzoni, Paola F. Antonietti, and Alﬁo M. Quarteroni
3. Affiliation: MOX-Dipartimento di Matematica, Politecnico di Milano, Piazza Leonardo da Vinci 32, Milan, 20133, Italy
4. Keywords: Fisher-Kolmogorov equation, uncertainty quantification, Monte Carlo Markov Chain, Alzheimer's disease, patient-specific model
5. Urls: arXiv:2305.03619v1 [math.NA] 5 May 2023, Github: None
6. Summary:

- (1): 该文的研究背景是神经变性疾病的模拟，重点在于探讨蛋白质在全脑中的积累以及对阿尔茨海默病发展的预测。
- (2): 以往的方法仅关注诊断而不是防治，PET 扫描金贵而不便利，部分微分方程模型的复杂度比较高。这篇文章提出的方法应用预测性模型，利用 Monte Carlo Markov Chain 等方法精确定位患者的疾病发展，来提高防治工作的质量和保障病人的健康。
- (3): 该文的研究方法是基于图形脑连接模型构建的缩减模型。随机反应系数模型采用随机随机场模型，并利用临床数据来推断其概率分布。同时，利用 Monte Carlo 和稀疏网格随机配点的方法来分析反应系数的不确定性对蛋白质积累进度的影响。
- (4): 该文提出的方法可以对阿尔茨海默病的进一步发展进行有效的定量预测和控制，提高病人的生命质量。
- (5): 该文是基于现实问题提出的，旨在通过设立有效的解决方案来弥补既有的研究不足，实现神经变性疾病的防治。




 ## Paper:14




1. Title: Generative Steganography Diffusion (生成式隐写扩散)

2. Authors: Ping Wei, Qing Zhou, Zichi Wang, Zhenxing Qian, Xinpeng Zhang, Sheng Li.

3. Affiliation: Fudan University (复旦大学)

4. Keywords: Steganography, Generative steganography, Diffusion model (隐写术, 生成式隐写术, 扩散模型)

5. Urls: None, Github: None

6. Summary:

- (1): 本文的研究背景是隐写术。

- (2): 过去的方法包括基于GAN或flow的生成式隐写方法。GAN方法由于缺乏网络的可逆性不能完全恢复隐藏的秘密数据，而Flow方法由于每个模块的严格可逆性限制会产生较差的图像质量。为了解决这个问题，本文提出了一种新颖的生成式隐写方案—— Generative Steganography Diffusion (GSD)，通过设计一个可逆扩散模型StegoDiffusion, 不仅生成逼真的藏文图像, 还实现了100%隐藏秘密数据。StegoDiffusion模型使用了快速采样技术，利用纯随机Walk非Markov连通，构造一个基于扩散生成过程的 transition-probability的ODE，使秘密数据和藏文图像通过ODE的近似求解器—— Euler iteration formula 相互转化，在不可逆但更表达能力强的网络结构下实现了模型可逆性。该方法在所有指标上显著优于现有的生成式隐写方法。

- (3): 本文提出了一种基于可逆扩散模型的生成式隐写方案—— GSD，通过设计一个可逆扩散模型StegoDiffusion来实现。

- (4): 本文的方法应用于生成式隐写任务中，通过图像质量、隐藏数据提取精度、载荷等维度对比，证明该方法在所有指标上显著优于现有的生成式隐写方法。

- (5): 本文的主要研究动机是为了提高生成式隐写技术的可逆性和性能，以优化传递秘密信息的安全性。




 ## Paper:15




1. Title: ChatGraph: Interpretable Text Classification by Converting ChatGPT Knowledge to Graphs
2. Authors: Yucheng Shi, Hehuan Ma, Wenliang Zhong, Gengchen Mai, Xiang Li, Tianming Liu and Junzhou Huang 
3. Affiliation: Yucheng Shi, Tianming Liu: School of Computing, University of Georgia, Athens, GA 
4. Keywords: ChatGPT, interpretable text classification, knowledge graph extraction, linear classifier
5. URLs: Paper: arXiv:2305.03513v1 [cs.CL]3 May 2023, Github: None
6. Summary:

- (1): 本文围绕 ChatGPT 的应用开展可解释性（interpretability）研究，目标是提高文本分类的性能和解释性。
- (2): 本文结合 ChatGPT 知识图谱的特点，提出一种转换 ChatGPT 知识图谱为图形，再使用可解释的线性分类器进行分类的方法。文章指出 ChatGPT 的拟合在一些 NLP 任务中效果不佳且难以解释，所以需要提高解释性。
- (3): 本文提出的 ChatGraph 方法首先使用 ChatGPT 进行知识图谱提取，再将得到的知识图谱转换为图形，最后训练一个可解释的线性分类器进行分类。
- (4): 本文在四个数据集上进行了实验，比较了 ChatGraph 方法与传统方法的效果，并进行了分析。结果表明，ChatGraph 可显著提高文本分类性能，并提高解释性。 
- (5): 本文的动机是提高 ChatGPT 在文本分类方面的解释性和性能，为 ChatGPT 在更多的 NLP 任务中提供了参考。




 ## Paper:16




1. Title: Guided Image Synthesis via Initial Image Editing in Diffusion (通过扩散中的初始图像编辑指导图像合成)

2. Authors: Jiafeng Mao, Xueting Wang, Kiyoharu Aizawa

3. Affiliation: The first author's affiliation is The University of Tokyo (东京大学).

4. Keywords: text-to-image, diffusion model, fine-grained control, layout-to-image (文本到图像，扩散模型，细粒度控制，布局到图像)

5. Urls: Paper link: https://arxiv.org/abs/2305.03382 GitHub code: None

6. Summary:

- (1): 该篇文章的研究背景是图像生成，它是计算机视觉领域的一个重要研究方向。

- (2): 过去的方法主要集中在使用提示方式（prompt）指导生成图像，但这种方式通常会产生不确定性和失败。本文首先研究了生成过程失败的原因，并进一步将结论应用于控制生成结果的新方向。在研究中，作者发现通过扩散模型生成图像时，初始噪声图像会影响生成出的图像内容，而其对应的像素块位置的变化不会对生成结果产生影响。进一步实验表明，将初始噪声图像中具有生成用户需求内容趋势的像素块移动到用户指定的区域，可以实现对布局到图像（layout-to-image）任务的最佳生成效果。

- (3): 研究方法是在扩散模型的基础上，探索更灵活和细粒度的初始噪声图像编辑控制方法，通过操作图像的随机噪声初始化方式来实现对生成结果的控制。

- (4): 本文以生成图像重新涂色和布局到图像合成两个应用实例验证了所提出的方法。实验结果表明，新方法可以取得良好的生成效果，达到了与先进技术相近或更好的成果。

- (5): 研究动机是为了探讨生成图像过程中影响生成结果的因素，以及如何通过对初始噪声图像的操作来指导生成过程，得到更为理想的生成结果。




 ## Paper:17




1. Title: A Suite of Generative Tasks for Multi-Level Multimodal Webpage Understanding

2. Authors: Andrea Burns, Krishna Srinivasan, Joshua Ainslie, Geoff Brown, Bryan A. Plummer, Kate Saenko, Jianmo Ni, Mandy Guo

3. Affiliation: Andrea Burns is affiliated with Boston University.

4. Keywords: Deeplearning, ML, NLP, CV, Webpage Understanding, Generative Tasks, Attention Mechanism

5. Urls: https://arxiv.org/abs/2305.03668v1, Github: None

6. Summary:
- (1):本文研究多层多模态网页理解中的生成任务。
- (2):以往的方法只使用了网页的部分信息而没有汇总整合，没能完全利用结构化的图像-文本数据，本文提出一系列生成任务并引入了相关数据集，并设计了一个新的注意力机制 Preﬁx Global，它选取最相关的图像和文本内容作为全局令牌，指定了Context，同时比完全关注使用更低的计算复杂度，改善了任务性能，为该方法提供了动力。
- (3):本文提出了新的数据集WikiWeb2M，包括了网页的所有结构化信息，设计了一系列生成任务，引入了Preﬁx Global 注意力机制。
- (4):实验结果表明，与以往数据相比，来自WikiWeb2M的新的注释提高了任务性能，特别是当使用Preﬁx Global时，性能得到了明显改善。 
- (5):该研究具有实际意义，可以为Web文本理解任务提供更多的数据，同时可以采用新的类别和生成任务，以帮助机器模拟人类的网页浏览行为。




 ## Paper:18




1. Title: VicunaNER: A Zero/Few-Shot Named Entity Recognition Framework Based on the Vicuna Model
    (VicunaNER：基于Vicuna模型的零/少样本命名实体识别框架)

2. Authors: Jianru Xue, Yu Wu, Yuanyuan Zhao, Enhong Chen, Tong Xu, Qi Liu

3. Affiliation: 合肥工业大学 Hefei University of Technology

4. Keywords: Deep Learning, Named Entity Recognition, Few-Shot Learning, Large Language Models

5. Urls: Paper: https://www.aclweb.org/anthology/2022.findings-acl.136.pdf, Github: None

6. Summary:

- (1): 本文研究大型语言模型在零/少样本命名实体识别（Named Entity Recognition, NER）任务中的应用。

- (2): 过去的 NER 方法在大型语料库和复杂语言结构下存在明显的性能退化问题。本文提出的 VicunaNER 框架基于 Vicuna 模型，利用多轮对话的方式，分别进行 Recognition 和 Re-Recognition 两个阶段的 NER 任务，避免了遗漏命名实体的情况，并进行实体校验、去重和合并，提高了准确性。该模型解决了传统方法中精度和可扩展性的问题，具备应用前景。

- (3): 本文提出的 VicunaNER 框架分为 Recognition 和 Re-Recognition 两个阶段，两个阶段都采用多轮对话的方式对识别任务进行优化。同时增加了实体校验、去重和合并等环节，保证了识别的准确性。

- (4): 本文在 10 个跨 5 个领域的数据集上测试了 VicunaNER 在零/少样本 NER 任务中的准确率。实验结果表明 VicunaNER 在准确率上具有优势。

- (5): 本文动机在于提高 NER 任务的准确率和可扩展性，结合大型语言模型使用的特点提出了 VicunaNER 框架。




 ## Paper:19




1. Title: Velocity field and cavity dynamics in drop impact（液滴撞击中的速度场和空穴动力学）

2. Authors: V. Lherm and R. Deguen

3. Affiliation: 1号作者隶属于美国罗切斯特大学Earth and Environmental Sciences学院，2号作者隶属于法国各大学和科研机构。

4. Keywords: drop impact, velocity field, cavity dynamics, experiment, particle image velocimetry

5. Urls: arXiv:2305.03709v1 [physics.flu-dyn] 5 May 2023. Github: None.

6. Summary:

- (1): 本研究的背景是对于撞击发生时产生的速度场和空穴动力学进行探索，因为这涉及了天体撞击等自然事件的建模问题。

- (2): 过去的方法存在的问题是无法准确描述并预测液滴撞击过程中的速度场和空穴动力学，而本研究的方法提出了一个半理论模型，利用了不同阶的Legendre多项式对速度场进行分解，从而进一步拓展了我们对该问题的认识。

- (3): 本文提出的研究方法是利用粒子图像测速技术，通过分解速度场，建立了一个基于不稳定Bernoulli方程和动能学边界条件耦合的半解析模型。

- (4): 本文的研究重点是对液滴撞击时产生的速度场和空穴动力学进行探究，研究结果显示我们的方法可以更准确地描述此类现象的过程和特征，从而对于撞击过程的建模和预测有着较好的支持效果。

- (5): 本文的研究动机是探究液滴撞击现象中速度场和空穴动力学的特点，旨在为天体撞击等自然现象的重建和模拟提供基础和支持。




 ## Paper:20




1. Title: Can LLM Already Serve as A Database Interface? (LLM是否已经可以作为数据库接口？)

2. Authors: Jinyang Li, Binyuan Hui, Ge Qu, Binhua Li, Jiaxi Yang, Bowen Li, Bailin Wang, Bowen Qin, Rongyu Cao, Ruiying Geng, Nan Huo, Chenhao Ma, Kevin C.C. Chang, Fei Huang, Reynold Cheng, Yongbin Li.

3. Affiliation: 首位作者：The University of Hong Kong（香港大学）

4. Keywords: Text-to-SQL parsing, big benchmark, database grounded, dirty database contents, SQL efficiency.

5. Urls: Paper: arXiv:2305.03111v1 [cs.CL] 4 May 2023, Github: https://bird-bench.github.io/

6. Summary:
- (1): 本文研究如何将自然语言转化为可执行的SQL语句，以促进非专业数据分析人士从关系型数据库中自动提取所需信息的能力。
- (2): 文章介绍了既往方法的局限性，特别是现有基准数据集Spider和WikiSQL等仅聚焦于数据库表结构而忽视数据库内容的情况下，提出了基于大规模数据库Grounded文本到SQL任务的大型基准Bird，强调数据库内容的价值理解具有重要意义，并为相关研究中“脏”数据库内容、外部知识问题等新挑战提供了理论基础。 
- (3): 依据Bird基准，介绍了文中提出的方法来解决如数据库内容理解、语法解析、SQL效率等问题，可以帮助得到更准确、高效的SQL语句结果。
- (4): 文章实验结果表明，Bird基准可以很好地促进现有自然语言到SQL语句转化技术在大规模数据库中的应用，目前得到的最高准确率ChatGPT只有40.08％，与人类92.96％的结果相距遥远。因此，现有技术仍面临着挑战。
- (5): 该文研究的动机在于促进自然语言技术在数据库分析中的应用，同时为该领域的研究提供新的数据集及方法。




 ## Paper:21




1. Title: Iterative 𝛼-(de)Blending: a Minimalist Deterministic Diffusion Model

2. Authors: Eric Heitz, Laurent Belcour, Thomas Chambon

3. Affiliation: Eric Heitz and Thomas Chambon are from Unity Technologies France, and Laurent Belcour is from Intel Corporation France.

4. Keywords: diffusion models, sampling, mapping

5. Url: https://doi.org/10.1145/3588432.3591540 , Github: None

6. Summary:

- (1): 本文研究了决策性扩散模型，其是一种简约但强大的确定性去噪扩散模型，主要应用于生成建模领域。

- (2): 传统的扩散模型基于随机解决方案，比如Langevin动力学或分值匹配，但这些都是深奥级别的概念，难以为普通用户所掌握。本文中提出了另一种方法，只需要本科水平的微积分和概率知识。通过混合两个不同密度的随机样本，选取神经网络的网络来处理混合后的结果，模型可以不断地仿真混合和分离两种密度，形成随机路径并逐渐收敛为一个确定性映射。相比于传统的方法，本文的方法更容易推导和实施，计算更加稳定，实验效果更好，并且和计算机图形学领域有着有趣的联系。

- (3): 本文提出的方法主要包括两个密度相互混合并以此做为输入，以神经网络的结果为输出。同时，作者借助Gaussian噪声和Langevin动力学的关系，采用了类似随机扰动信号的方法，迭代的理论上收敛两个密度。

- (4): 本文的方法在图像生成领域中比其他传统方法表现更加优异。实验结果表明，本文提出的方法在生成MNIST数字图片上比DDPMs提高了4.89个”bits/dim”，在CIFAR-10和ImageNet数据集上的test-time sampling误差分别减少了30%和45%。

- (5): 目前的扩散模型主要基于随机解决方案，这种方法相对更难理解和实现，因此需要一种简单的扩散模型。同时，本文提出的方法还可应用于图像生成和相关领域。




 ## Paper:22




1. Title: Governance of the AI, by the AI, and for the AI

2. Authors: Dr. Andrew W. Torrance, Ph.D., and Dr. Bill Tomlinson, Ph.D.

3. Affiliation: Andrew W. Torrance is the Paul E. Wilson Distinguished Professor of Law at the University of Kansas, while Bill Tomlinson is a Professor of Informatics at the University of California, Irvine and Adjunct Professor at Te Herenga Waka - Victoria University of Wellington.

4. Keywords: artificial intelligence, governance, technology, society, humanity

5. Url: None. Github: None.

6. Summary:

- (1): This article analyzes the governance of artificial intelligence (AI) by humanity and the governance of humanity by AI, with the aim of making decisions that maximize benefits and minimize costs. 

- (2): In the past, there have been several false dawns during which the arrival of world-changing AI has been heralded. However, the current state of AI is already ushering in profound changes to many different sectors of society. Every new technology challenges the ability of humanity to govern it wisely. The approach in this article is well-motivated, as governance is usually viewed as both possible and necessary due to the disruption new technology often poses to social structures, industries, the environment, and other important human concerns.

- (3): The proposed research methodology in this paper is an analysis of a range of interactions between AI and governance. 

- (4): This paper does not report specific performance on a task, as it is not a technical research paper. 

- (5): The motivation for the research in this article is to ensure that wise decisions may be made that maximize benefits and minimize costs regarding the governance of AI.




 ## Paper:23




1. Title: Out-of-Domain Intent Detection Considering Multi-turn Dialogue (基于多轮对话的领域外意图检测)

2. Authors: Hao Lang, Yinhe Zheng, Binyuan Hui, Fei Huang, Yongbin Li

3. Affiliation: Alibaba Group (阿里巴巴集团)

4. Keywords: Out-of-Domain Intent Detection, Multi-turn Dialogue, Context-aware, Information Bottleneck

5. Urls: Paper - https://arxiv.org/abs/2305.03237, Github - None

6. Summary:

- (1): 本文的研究背景是检测在多轮对话中领域外的意图。

- (2): 之前的研究多数只在单个对话轮中进行领域外的意图检测，而忽略了多轮对话中的上下文信息。文章提出一个基于多轮对话的上下文感知的领域外的意图检测框架(Caro)，利用信息瓶颈法原则来从多轮对话中提取可靠的表示。文章还探索了在Caro中使用未标记数据来进行领域外样本的挖掘，使用自举法进行模型训练的方法。针对在领域外的意图检测中没有领域外样本的问题，文章从未标记数据中挖掘这些领域外样本。实验结果表明Caro在多轮领域外意图检测任务中性能具有的突出表现，相比之前的最佳方法，F1-OOD分数提高了超过29%。

- (3): 文章提出一个基于多轮对话的上下文感知的领域外意图检测框架(Caro)，利用信息瓶颈法原则来从多轮对话中提取可靠的表示。同时，采用两个不同的视角为每个输入样本构造视图，使用多视图信息瓶颈损失去除与意图检测无关的超出信息。文章也探究如何利用未标记数据在训练中挖掘未被检测到的领域外样本。

- (4): 本文所提出的Caro框架在多轮领域外意图检测任务中，F1-OOD分数相比之前的最佳方法提高了超过29%。这表明Caro具有更好的性能，能够更准确地检测领域外的意图，同时拥有更强的鲁棒性和泛化能力。

- (5): 本文的主要动机是针对目前领域外意图检测研究在多轮对话场景下存在的问题，提出一种更准确、更鲁棒、更具泛化性能的领域外意图检测框架。该框架可以动态地处理多轮对话上下文信息，并且可以利用未标记数据来挖掘未知的领域外样本。




 ## Paper:24




1. Title: Large Language Models in Ambulatory Devices (用于监测镰状细胞贫血患者的便携式设备中的大型语言模型)

2. Authors: Oluwatosin Ogundare, Subuola Sofolahan

3. Affiliation: 第一作者：Siemens Technology (西门子技术)，第二作者：California State University, San Bernardino (加州州立大学圣伯纳迪诺分校)，第三作者：Oklahoma State University, Stillwater (俄克拉荷马州立大学)

4. Keywords: Large Language Model, ambulatory device, sickle cell anemia, real-time monitoring, sensor data

5. Urls: arXiv:None

6. Summary: 

- (1):该论文研究了在便携设备中集成大型语言模型(Large Language Model, LLM）和其他专门的机器学习模型，以实时评估镰状细胞贫血病人的严重程度的潜力。 

- (2):传统的监控方法需要病人经常前往医院，并由专业医生进行管理，不仅费用高昂而且繁琐。而该文所提出的方法，结合大型语言模型和传感器数据，可以通过便携装置对患者在生活中进行实时监测，并给予患者和医生关于病情的及时信息，从而降低疾病的发生几率。 

- (3):该论文提出了一种针对镰状细胞贫血病人的实时监测的模型，并综合考虑了血管生成物质水平、生物物理模型和大型语言模型的方法。 

- (4):该方法的性能在镰状细胞贫血病人严重程度的监测上取得了很好的结果。该设计可以在实时评估中提供更可靠的结果，同时减少了患者前往医院的需要，使患者更加舒适化。 

- (5):该文的动机在于解决传统的监控方法在费用、准确度和使用方便性方面存在的问题。




 ## Paper:25




1. Title: Data Curation for Image Captioning with Text-to-Image Generative
Models

2. Authors: Wenyan Li, Jonas F. Lotz, Chen Qiu, Desmond Elliott

3. Affiliation: 1.Department of Computer Science, University of Copenhagen

4. Keywords: Image captioning, data curation, text-to-image generation, pretraining, multimodal learning

5. Url: arXiv:2305.03610v1 [cs.CV] 5 May 2023, Github: None

6. Summary:

- (1): 本文关注图像字幕生成领域中数据采集的问题。最近的研究主要依赖于基于大规模视觉-语言预先训练的方法。然而在构建训练数据集之前，如何发现并移除数据中的不一致或者误导性内容十分困难，本文从数据整理的角度出发，提出了一种新的方法，通过数据的精选，来提高图像字幕生成的效果。

- (2): 过去的方法大多是基于大规模预训练模型的语言生成模型，对大量的图像、语言训练数据进行预训练，存储预训练好的模型，然后利用这些模型完成图像字幕生成任务。但是这些方法容易产生一些不一致、误导性或者过于详细的样本，而现有的大量数据集中也存在大量噪音样本，影响了模型的性能。本文从数据精选的角度进行了研究，尝试通过两种方法来慢慢剔除不合适的数据，并提出了一种新的图像替换方法，来更好的匹配字幕和图像的内容。

- (3): 本文提出了一种数据整理的方法，通过基准模型BLIP在MS COCO和Flickr30K上的性能测试，进一步证明我们的方法可以提高基础模型的性能。在数据处理的过程中，本文首先通过移除或替换样本中不匹配的字幕，来排除不一致和误导性的数据。随后，通过使用现有的文本-图像生成模型来生成具备一定语义信息的图片，替换那些难以匹配的图像，以便更好的与语言模型生成的字幕相匹配。最终，本文通过实验发现，这两种方法都可以有效提高图像字幕生成性能。

- (4): 本文的方法通过数据整理的方式，提高了在MS COCO 和Flickr30K两种数据集上的BLIP模型的效果。

- (5): 本文的出发点是为了提高基于图像字幕生成的各种任务的效果，在现有数据的基础上找到一种有效的方法对数据进行关键性的处理，从而提高最终的模型性能。




 ## Paper:26




1. Title: A Large Cross-Modal Video Retrieval Dataset with Reading (带阅读理解的大规模跨模态视频检索数据集)

2. Authors: Weijia Wu, Yuzhong Zhao, Zhuang Li, Jiahong Li, Hong Zhou, Mike Zheng Shou, and Xiang Bai

3. Affiliation: 浙江大学 (Zhejiang University)

4. Keywords: Cross-Modal; Retrieval; Text Reading; Contrastive Learning (跨模态；检索；文本阅读；对比学习)

5. Urls: Paper link: [暂无] Github link: [暂无]

6. Summary:

- (1):该论文研究背景是跨模态视频检索。

- (2):过去的研究方法主要关注单模输入（视觉表示），而在人类环境中，文本无处不在，对于理解视频来说也是非常关键的。本文提出了一种跨模态视频检索数据集（TextVR），要求使用视觉和文本语义表示来检索视频，而不仅是视觉表示，并设计了一个基于文本的视频检索任务的新型多模态基准线。此外，文章还进行了详细的数据集分析，比较了TextVR与现有数据集的差异。文章认为，比起以往的研究方法，该基准线提供了许多新的技术挑战和洞见。

- (3):文章提出了一种使用对比学习的跨模态语言-视频检索模型，该模型旨在扩展对文本阅读的理解与利用，有效地将文本语义信息应用于视频检索任务。

- (4):文章提出的基准线在跨模态检索任务中表现不错，比现有的方法取得了更高的表现，说明所提出的方法和基准线能够比较好地解决现有方法存在的问题。

- (5):文章的目的是解决现有跨模态视频检索方法忽视文本信息的问题，提出一个新的基准线解决这个问题。同时，该数据集也为进一步研究跨模态视频检索提供了有价值的资源。




 ## Paper:27




1. Title: Multi-modal Instruction Tuning with In-context Examples

2. Authors: Zhenpeng Chen, Yuchi Zhang, Zhiwu Lu, Xiaodan Liang, Zhenguo Li

3. Affiliation: Zhenpeng Chen - AI Lab, Tencent; Yuchi Zhang, Xiaodan Liang, Zhenguo Li - Chinese Academy of Sciences; Zhiwu Lu - LingoChamp Inc.

4. Keywords: Multi-modal models, Instruction Tuning, In-context Examples, Language models, Fine-tuning

5. Url: https://arxiv.org/abs/2305.03726, Github: None

6. Summary:

- (1): 近年来，大型语言模型已经展示出在各种任务中作为零/少样本学习器的重要能力，其预训练模型通过大量的文本数据训练后，可以如 GPT-3 一样，对自然语言指令进行成功的获取和实现任务的实现。然而这些模型的实现仍然存在一些问题，本文旨在构建一个多模型模型，将指令调整引入其中，提高其执行任务的能力。 

- (2): 过去的方法通常使用来自 Caption 或 VQA 任务的图像-文本数据对，将视觉信息嵌入到语言模型中。然而，这种方法往往是任务依赖的，需要根据不同的任务进行训练。通过反思，该研究发现 DeepMind Flamingo 的上游预训练数据集 M3W，以更自然的方式对齐视觉和语言信息具有重要价值。通过对该数据集进行训练，Flamingo 获得了零和少样本泛化能力以及 in-context learning 能力，使其成为多模块领域的 GPT-3 时刻。在 OpenFlamingo 项目的帮助下，本文构建了一个 MIMIC-IT 数据集，以及Otter多模型模型，与 OpenFlamingo相比， MIMIC-IT 数据集的 Otter 模型表现出了更好的指令遵循能力。同时，Otter能够通过提供 in-context examples，学习执行指令。 

- (3): 本文提出了 MultI-Modal In-Context Instruction Tuning (MIMIC-IT) 数据集，其中的每个数据样本都包括指令-图像-答案三元组及其 in-context 示例。我们引入 Otter，一种基于 OpenFlamingo 的多模型模型，通过对 MIMIC-IT 数据集的训练，我们证明了 Otter 模型能够有效提高指令遵循能力并实现 in-context learning。同时，我们优化了 OpenFlamingo 项目的实现，包括将其与 Huggingface Transformers 进行集成，以简化训练和推断操作。

- (4): 本文构建了多模型模型 Otter，并使用 MIMIC-IT 数据集进行训练，结果表明其能有效提高指令遵循能力和 in-context learning 能力。同时，我们对 OpenFlamingo 的实现进行了优化，从至少需要 1 张 A100 GPU 的训练资源优化到只需要 4 张 RTX3090 GPU，让更多的研究者可以使用该模型。

- (5): 针对目前多模型的指令遵循能力较差的现象，本研究提出了一种针对性更强的指令调整方法，以提高多模型的性能。




 ## Paper:28




1. Title: DAMO-NLP at SemEval-2023 Task 2: A Unified Retrieval-augmented System for Multilingual Named Entity Recognition (DAMO-NLP在SemEval-2023任务2中：一种面向多语言命名实体识别的统一检索增强系统)


2. Authors: Zeqi Tan, Shen Huang, Zixia Jia, Jiong Cai, Yinghui Li, Weiming Lu, Yueting Zhuang, Kewei Tu, Pengjun Xie, Fei Huang, Yong Jiang


3. Affiliation: DAMO Academy, Alibaba Group (阿里巴巴集团-达摩院)


4. Keywords: multilingual named entity recognition, fine-grained, retrieval knowledge, Wikidata, infusion approach


5. URLs: 
- Paper: https://arxiv.org/abs/2305.03688v1 
- GitHub: https://github.com/modelscope/AdaSeq/tree/master/examples/U-RaNER 


6. Summary: 

- (1): 本文研究多语言命名实体识别中的语境有限和语义歧义问题，且其基于MultiCoNER II shared task进行研究。 

- (2): 过去的方法利用预训练语言模型中的知识库或词典进行实体识别，但仍存在知识不足、上下文长度有限、单一检索策略的问题。本文提出了一种采用检索增强和融合学习的检索增强系统（U-RaNER），解决了过去方法存在的问题，并提供了实现方法。 

- (3): 本文的检索增强系统利用实体中心化的Wikidata知识库，采用注入方法拓展模型的上下文范围，并探索各种搜索策略，提高检索知识质量。 

- (4): 本文的方法在MultiCoNER II shared task中的13个任务中有9个获得了胜利，并且与ChatGPT进行了比较，结果表明ChatGPT在实体抽取任务上仍有提高的空间。 

- (5): 本文的研究意义在于提供了一种可借鉴的新方法来解决多语言命名实体识别中的特定问题，即语义歧义和语境有限的挑战。



