# 2023_05_15 Arxiv更新论文汇总
今天共有12篇论文


 ## Paper:1









 ## Paper:2




1. Title: The ASNR-MICCAI Brain Tumor Segmentation (BraTS)

2. Authors: Dominic LaBella, Maruf Adewole, Michelle Alonso-Basanta, Talissa Altes, Syed Muhammad Anwar, Ujjwal Baid, Timothy Bergquist, Radhika Bhalerao, Sully Chen, Verena Chung, Gian-Marco Conte, Farouk Dako, James Eddy, Ivan Ezhov, Devon Godfrey, Fathi Hilal, Ariana Familiar, Keyvan Farahani, Juan Eugenio Iglesias, Zhifan Jiang, Elaine Johanson, Anahita Fathi Kazerooni, Collin Kent, John Kirkpatrick, Florian Koﬂer, Koen Van Leemput, Hongwei Bran Li, Xinyang Liu, Aria Mahtabfar, Shan McBurney-Lin, Ryan McLean, Zeke Meier, Ahmed W Moawad, John Mongan, Pierre Nedelec, Maxence Pajot, Marie Piraud, Arif Rashid, Zachary Reitman, Russell Takeshi Shinohara, Yury Velichko, Chunhao Wang, Pranav Warman, Walter Wiggins, Mariam Aboian, Jake Albrecht, Udunna Anazodo, Spyridon Bakas, Adam Flanders, Anastasia Janas, Goldey Khanna, Marius George Linguraru, Bjoern Menze, Ayman Nada, Andreas M Rauschecker, Jeﬀ Rudie, Nourel Hoda Tahon, Javier Villanueva-Meyer, Benedikt Wiestler, and Evan Calabrese.

3. Affiliation: Department of Radiation Oncology, Duke University Medical Center, Durham, NC, USA

4. Keywords: Brain Tumor, Segmentation, Multilabel, mpMRI, Challenge

5. Urls: arXiv:2305.07642v1 [cs.CV] 12 May 2023

6. Summary:

- (1): 本文研究的是脑肿瘤分割任务。

- (2): 该领域过去的方法缺乏非侵入性的多参数核磁共振成像的自动化分割工具，这导致对于分割的精准度和定量化评估的准确性存在着不足。因此，研究对于单标签和多标签脑肿瘤自动分割工具以及案例的评价进行了探索研究，并设计相应的分割算法模型，充分考虑到脑肿瘤的复杂性和实际操作问题。

- (3): 本文提出了一种基于最大专家标注标签的自动化脑膜瘤分割模型，并设计了脑肿瘤分割挑战赛任务，以此为基础提供社区标准和基准，提升领域内的最先进水平。

- (4): 本文在最大的专家标注多标签脑肿瘤的多参数核磁共振图像数据集上，采用提出的自动化分割算法模型进行了实验，取得了优秀的分割结果和性能表现，并在分割实验中设计了相应的算法评价措施。

- (5): 本研究的动机在于提供一种基于大规模数据集的自动化脑肿瘤分割技术和评价方法，以此进一步提升临床医学诊断的效率和准确程度。




 ## Paper:3




1. Title: BEWARE OF DIFFUSION MODELS FOR SYNTHESIZING MEDICAL IMAGES - Muhammad Usman Akbar

                2. Authors: Muhammad Usman Akbar, Wuhao Wang, Anders Eklund

                3. Affiliation: 链兴大学医学信息学部，计算机与信息科学系的统计和机器学习部门，医学影像科学与可视化中心（CMIV）

                4. Keywords: Diffusion Models, GANs, Medical Imaging, Brain Tumor, Memorization

                5. Url: https://arxiv.org/abs/2107.04746

                6. Summary:

                - (1):本文主要探讨扩散模型在合成医学图像方面的局限性，尤其是在脑肿瘤图像方面的表现，并将其与GANs进行对比，目的是提醒医学影像研究者在使用扩散模型时要注意它们可能存在的记忆问题。

                - (2):GANs一直是生成图片的重要方法，在合成高质量和高分辨率图片方面有着出色的表现，然而，扩散模型在文本到图像转换方面的表现一度受到瞩目，近年来还被用于生成更高质量的图片。文章指出，常用的评估指标，如FID和IS，无法判断扩散模型是否只是复制了训练图像。扩散模型和GANs的目标都是从复杂的高维分布中采样出现实的样本，但扩散模型的效果更好，这是本文中探讨的一个问题。

                - (3):文章分别使用BRATS20和BRATS21数据集对StyleGAN和扩散模型进行训练，合成脑肿瘤图像，并衡量合成图像与所有训练图像之间的相关性。通过实验比较，发现当数据集较小时，扩散模型更容易记忆训练图像。

                - (4):扩散模型在生成脑肿瘤图像方面存在过度记忆的问题，特别是在数据集较小时，这为使用扩散模型生成医学图像的研究提供了提示和警醒。

                - (5):本文的研究动机是在探索医学影像研究中使用合成图像，其中涉及的扩散模型技术的局限性与限制。




 ## Paper:4




1. Title: ArtGPT-4: 艺术视觉-语言理解 with Adapter-enhanced MiniGPT-4 
2. Authors: Zhengqing Yuan, Huiwen Xue, Xinyi Wang, Yongming Liu, Zhuanzhe Zhao, Kun Wang
3. Affiliation: 郑清元: 安徽工业大学, 人工智能学院；薛惠文: 苏州大学, 光电科学与工程学院；王新毅: 安徽工业大学, 人工智能学院；刘永明: 安徽工业大学, 人工智能学院；赵专哲: 安徽工业大学, 人工智能学院；王鲲: 安徽工业大学, 计算机与信息技术学院
4. Keywords: ArtGPT-4, multimodal model, vision-language understanding, NLP, GPT-4
5. URLs: Paper: arXiv:2305.07490v1 [cs.CL] 12 May 2023, Code: https://huggingface.co/Tyrannosaurus/ArtGPT-4 
6. Summary:
- (1): 近年来，大型语言模型(LLMs)在自然语言处理(NLP)方面取得了显著进展，像ChatGPT和GPT4这样的模型在各种语言任务中取得了令人瞩目的能力。然而，在这样的大规模训练模型方面仍然面临挑战，而找到与模型规模相匹配的数据集通常是困难的。
- (2): Fine-tuning和使用新的训练方法训练具有较少参数的模型是克服这些挑战的有希望的方法之一。这些方法中，MiniGPT-4是这样一款模型，它通过利用新的预训练模型和创新的训练策略，在视觉-语言理解方面取得了与GPT-4同等水平。然而，该模型在艺术图片方面仍然面临一些挑战。由此，提出了一款名为ArtGPT-4的新型多模态模型来解决这些限制。ArtGPT-4是使用Tesla A100设备在仅2小时内，使用约200 GB的数据，对图像-文本对进行训练的。该模型可描绘具有艺术感的图片，并生成视觉代码，包括美观的HTML / CSS网页。此外，本文还提出了用于评估视觉-语言模型表现的新基准。在随后的评估方法中，ArtGPT-4的得分比当前最先进模型高1分，只比艺术家低0.25分。代码和预训练模型可在https://huggingface.co/Tyrannosaurus/ArtGPT-4获得。
- (3): 本研究提出了ArtGPT-4，一款用于视觉-语言理解的多模态模型。该模型使用了MiniGPT-4的模型架构，同时也使用了Adapter-enhanced技术来保持模型的精度，用于图片的视觉输入使用了ResNet101进行编码，而视频的输入则使用了一个基于ResNet101/RNN结构的编码器。ArtGPT-4还将Unicoder模型应用于文本处理，以实现对图像和文本之间的融合。
- (4): 本文提出的ArtGPT-4模型在图像理解方面取得了很好的表现，得分比当前最先进模型高1分。其生成的网页也具有较好的艺术美感。同时，ArtGPT-4也表现出对文本理解的良好能力，其性能可支持论文目标。
- (5): 该论文主要针对大规模训练模型的挑战，提出了一种具有较少参数的训练方法以克服这些挑战，并针对艺术图片的特殊需求提出了一种新型多模态视觉-语言模型，为图像理解提供了一种新的解决方案。




 ## Paper:5




1. Title: Unlocking the Potential of Medical Imaging with ChatGPT’s Intelligent Diagnostics

2. Authors: Ayyub Alzahem, Shahid Latif, Wadii Boulila, Anis Koubaa

3. Affiliation: 王子塔大学 (Prince Sultan University)

4. Keywords: ChatGPT, Medical Imaging, Healthcare diagnosis, Deep Learning, Convolutional Neural Network

5. Urls: https://arxiv.org/abs/2305.07429

6. Summary:

- (1):本文针对医学图像诊断是复杂耗时的任务，需要专业知识和经验的问题，旨在为医疗保健提供决策支持系统，辅助医护提供诊断、治疗和管理健康问题的决策。
 
- (2):该文提出利用深度学习模型对医学图像数据集进行训练，并通过聊天式生成预测的自动诊断结果，模型具有增强决策能力、降低成本的潜力。相较于传统方法，该文的方法拥有更加智能化和高效的分析能力。

- (3):该文提出的医学图像智能诊断系统主要包括三个阶段：数据收集和标记；深度学习模型训练；诊断报告生成。首先利用医学图像数据集，训练深度学习模型以提取四类信息：图像扫描类型、身体部位、测试图像和结果。然后将这些信息输入到ChatGPT中，生成自动的诊断结果。 

- (4):该文的方法在大规模医学图像数据集上展开了广泛的实验，实验结果表明模型具有可行性和可靠性。自动诊断方法通过准确地分析各种图像细节，实现了高准确度的诊断准确性。

- (5):该文的动机是解决医学图像诊断的繁琐、复杂和耗时的问题，提高决策的准确性、速度和效率，以及降低医疗保健成本。




 ## Paper:6




1. Title: MedGPTEval: A Dataset and Benchmark to Evaluate the Responses of Large Language Models in Medicine (医学领域大型语言模型响应评价数据集与基准)

2. Authors: Jie Xu, Lu Lu, Sen Yang, Bilin Liang, Xinwei Peng, Jiali Pang, Jinru Ding, Xiaoming Shi, Lingrui Yang, Huan Song, Kang Li, Xin Sun, Shaoting Zhang*

3. Affiliation: 上海人工智能实验室 (Shanghai Artificial Intelligence Laboratory, Shanghai, China)

4. Keywords: Large language models, medical domain, evaluation system, medical datasets, chatbots

5. Urls: Paper: https://arxiv.org/abs/2305.07340v1  Github: None

6. Summary: 

- (1): 本论文旨在解决大型语言模型在医学领域应用中生成的“幻觉”（不完全可靠回答）所带来的安全风险问题，建立全面的评价系统。

- (2): 过往工作的缺陷在于缺乏鲁棒性，对LLMs缺乏全面的评价，而本文提出了一个可以评价LLMs在医学领域能力的独特方法，包括一套评价标准、基于中文的医学数据集以及基准。其方法具有很高的动机性。

- (3): 本文提出了一种全面的评价体系，由医学能力、社交综合能力、情境能力和计算鲁棒性组成，总共16个指标。五名医学和工程专家使用Delphi方法对现有标准进行了优化，获得了一套满足标准的医学数据集。针对这些数据集，他们评估了三个聊天机器人：OpenAI的ChatGPT、百度公司的ERNIE Bot和上海人工智能实验室的Doctor PuJiang(Dr.PJ)。最终，他们盲目评估了这三个聊天机器人通过LLMs提供的反应情况。 

- (4): 本文的方法在医学对话和病例报告等场景中，Dr.PJ聊天机器人的表现明显优于ChatGPT和ERNIE Bot，但在多次对话场景下，Dr.PJ在医学专业能力方面略低于ChatGPT。 

- (5): 对于LLMs在医学领域的应用，由于其幻觉和缺乏鲁棒性而存在显著的安全风险，因此建立全面的评价体系可以有效地预防风险并提高LLMs的可靠性。




 ## Paper:7




1. Title: Prompt Learning to Mitigate Catastrophic Forgetting in Cross-lingual Transfer for Open-domain Dialogue Generation （措辞严谨可采用：《针对面向开放域对话生成的跨语言迁移中缓解灾难性遗忘的提示学习方法》）
                
                2. Authors: Lei Liu, Jimmy Xiangji Huang （措辞严谨可采用：作者：刘磊，黄香季）
                
                3. Affiliation: Department of Electrical Engineering & Computer Science, York University （措辞严谨可采用：机构：约克大学电气和计算机科学系）
                
                4. Keywords: dialogue generation, few-shot cross-lingual transfer, multitask learning, prompt learning, catastrophic forgetting （措辞严谨可采用：关键词：对话生成，较少样本跨语言转移，多任务学习，提示学习，灾难性遗忘）
                
                5. Urls: paper: https://dl.acm.org/doi/abs/10.1145/3539618.3592043 ; Github: https://github.com/JeremyLeiLiu/XLinguDial (GitHub链接没有提供，标注为None即可)
                
                6. Summary: 
                
                - (1):本文研究了多语言开放域对话生成领域中，较少样本跨语言转移（FS-XLT）和多任务学习（MTL）两种跨语言迁移中的灾难性遗忘问题。
                
                - (2):目前，建立其他语言的对话系统的方式有很多，但存在一些问题。本文针对PMT（预训练语言模型）迁移问题进行改进，解决了跨语言生成中的线上崩溃、以及mPLM-ZS-XLT中典型的病态分布问题，通过手动生成提示来缓解灾难性遗忘问题，保留mPLM的多语言性。这种方法在多语言开放域对话生成任务中取得了很好的表现，通过确认方法有效性的实验结果，表明本方法可以解决FS-XLT和MTL中的灾难性遗忘问题，从而改善了生成的质量。
                
                - (3):具体的研究方法是通过手动生成一些提示，将跨语言对话生成问题转化为mPLM的预训练任务，以缓解mPLM-ZS-XLT中的灾难性遗忘问题，并且保留mPLM的多语言性。
                
                - (4):研究表明改进后的方法在多语言开放域对话生成任务上有效，通过实验，改进后方法的表现较基准方法有显著提升，并且方法表现支持研究目标。
                
                - (5):本文的动机在于解决多语言开放域对话生成任务中样本不足导致的瓶颈问题，改进现有方法，获得更好的实验表现，为多语言领域的对话生成任务研究提供有益参考。




 ## Paper:8




1. Title: MMG-Ego4D (Multimodal Generalization in Egocentric Action Recognition)

2. Authors: Xinyu Gong, Sreyas Mohan, Naina Dhingra, Jean-Charles Bazin, Yilei Li, Zhangyang Wang, Rakesh Ranjan

3. Affiliation: Meta Reality Labs

4. Keywords: multimodal, egocentric action recognition, few-shot learning, generalization

5. Urls: Paper (https://arxiv.org/abs/2305.07214v1), Github (https://github.com/facebookresearch/MMG-Ego4D)

6. Summary: 

- (1): This article focuses on the problem of "Multimodal Generalization" (MMG) in egocentric action recognition, which studies how systems can generalize when data from certain modalities is limited or missing.
 
- (2): The past methods for egocentric action recognition are typically based on third-person or spectator perspective, which are different from egocentric perspective and less challenging. The approach proposed in this paper is well motivated, as recognition from egocentric videos is critical in areas such as robotics and augmented reality, but more challenging due to low-level corruptions and the need for interpretation from the wearer's perspective.

- (3): The proposed research methodology involves constructing a new dataset called MMG-Ego4D, derived from the Ego4D dataset but re-annotated by human experts for MMG problem research. Two scenarios of MMG are designed to study the limited or missing modalities - missing modality generalization (some modalities are missing during the inference time) and cross-modal zero-shot generalization (modalities are disjoint between inference time and training time). A diverse array of models are evaluated on MMG-Ego4D, and new methods with improved generalization ability are proposed, including a fusion module with modality dropout training, contrastive-based alignment training, and a novel cross-modal prototypical loss for better few-shot performance.

- (4): The methods proposed in this paper achieve state-of-the-art performance on the MMG-Ego4D dataset, demonstrating the effectiveness of the approach in multimodal generalization in egocentric action recognition. The performance achieved supports the goals of the research in studying how systems can generalize when data from certain modalities is limited or missing.

- (5): The motivation for the research in this article is to study the problem of multimodal generalization in egocentric action recognition, which is critical in areas such as robotics and augmented reality but more challenging due to the limited or missing modalities. The proposed approach and methodology can guide future research in multimodal generalization problems.




 ## Paper:9




1. Title: Is ChatGPT a Good Causal Reasoner? A Comprehensive Evaluation. (ChatGPT是一个好的因果推断器吗? 一项全面的评估)

2. Authors: Jinglong Gao, Xiao Ding, Bing Qin, Ting Liu

3. Affiliation: 哈尔滨工业大学社交计算与信息检索研究中心

4. Keywords: causal reasoning, NLP, ChatGPT, hallucination, event causality identification

5. Urls: arXiv, Github: None

6. Summary:

- (1): 本文研究了ChatGPT（一种基于语言模型预训练的文本生成算法）在因果推断任务中的性能表现。

- (2): 过去的方法主要是基于BERT和RoBERTa等语言模型，需要使用大量标注数据进行监督训练。ChatGPT最新版本可以在NLP各种任务中表现出色，但目前尚没有对其在因果推断方面的能力进行综合评估。本文旨在对ChatGPT的因果推理能力进行全面评估，并发现其并不是一个好的因果推断器，但是是一个很好的因果解释器，并深入探究了这种“幻觉”现象的原因。

- (3): 本文提出了基于事件因果识别（ECI）任务的综合评测方法，并利用四个最先进的ChatGPT版本进行了实验。同时使用了包括In-Context Learning（ICL）和Chain-of-Thought（COT）技术等方法与模型结构进行比较实验。

- (4): 实验结果表明，ChatGPT在低事件密度和较小语义距离等情况下表现较好。对于句子中的事件，ChatGPT善于捕捉显式的因果关系，在处理隐式因果关系时表现不佳。此外，闭合式提示比开放式提示的效果更好。总体来说，ChatGPT并不是一个好的因果推断器，但在因果解释方面有广泛应用前景。

- (5): 本文的研究旨在深入探究ChatGPT这一先进算法在因果推断任务中的表现，为自然语言处理技术的发展提供新思路和解决方案。




 ## Paper:10




1. Title: Improving Deep Learning for Semantic Image Segmentation with Receptive Field Block
2. Authors: Chunxia Xiao, Chao Wang, Yu Qiao
3. Affiliation: 中国科学院自动化研究所
4. Keywords: Deep learning, Convolutional neural network, Semantic image segmentation, Receptive field
5. Urls: Paper: https://www.mdpi.com/2076-3417/11/15/7278; Github: None
6. Summary:
- (1): 本文的研究背景是语义图像分割的深度学习方法，旨在提高现有方法的精度。
- (2): 过去的方法因为缺乏对图像全局信息的捕捉，存在无法准确识别目标的问题。本文提出了一种基于可接受域块的深度学习方法，通过扩大感受野来捕获图像的全局信息。
- (3): 本文提出的方法解决了现有方法无法全面获取感受野信息的问题，通过引入可接受域块的结构，对输入图像进行了多层次的特征提取，从而改善了语义图像分割的精度。
- (4): 作者在多个数据集上进行了实验，并且与现有的语义图像分割方法进行了比较。结果表明，通过引入可接受域块的结构，本文提出的方法在语义图像分割上具有更好的性能。
- (5): 本文的研究动机是现有的语义图像分割方法因为不全面获取感受野信息而存在精度问题，作者希望能通过引入新的结构来解决这一问题。




 ## Paper:11




1. Title: The Ethics of AI in Games (游戏中的人工智能伦理)
2. Authors: David Melhart, Julian Togelius, Benedikte Mikkelsen, Christoffer Holmg˚ard, Georgios N. Yannakakis
3. Affiliation: David Melhart, Julian Togelius, Benedikte Mikkelsen, Christoffer Holmg˚ard, Georgios N. Yannakakis 为共同第一作者，隶属于丹麦哥本哈根的 modl.ai。
4. Keywords: artiﬁcial intelligence, ethics, video games, affective computing
5. Url: Paper: arXiv:2305.07392v1  [cs.HC]  12 May 2023; Github: None
6. Summary:
- (1): 本文的研究背景是随着人工智能工具逐渐被游戏产业采用，伦理问题逐渐浮出水面。随着艺术ifical Intelligence的快速发展，人工智能在游戏设计、开发，甚至是游戏环境中的应用正在日趋成熟，而游戏行业的道德问题正在同步出现。
- (2): 本文讨论游戏中AI工具和方法的伦理考虑，主要通过情感计算的视角来研究，即以情感游戏循环为框架展开讨论。其中，引入了elicit、sensing、detection和adaptation四个元素应用到游戏中，考虑人工智能在这四个方面的伦理问题。过去的方法普遍存在游戏设计中的“黑暗模式”和有害掉钱策略、游戏的黑盒子特性，都有着同样的道德问题，但是本文以情感计算作为切入点并未出现过。因此，在此背景下，本研究有启发性地提出了情感计算框架来分析这些伦理问题。
- (3): 本文采用问卷调查法、实验法、文献研究法等方法，综述了游戏AI工具和方法、情感游戏循环和游戏伦理等方面的研究。
- (4): 本文以情感计算作为切入点，通过情感游戏循环展开思考游戏中AI工具和方法的伦理问题，重点讨论了人工智能在 elicitation（如何人为诱发情感的伦理边界）、sensing（如何平衡隐私与安全）、detection（透明度和所有权的挑战）等方面的伦理问题。最终总结了游戏中AI算法带来的数据模型所有权等各种道德难题，目的是保证用户和开发人员在游戏开发中的道德标准和主观要求一致，以达到更加安全和良好的游戏经历。
- (5): 随着人工智能技术的日益成熟，游戏行业对于使用这类技术面临的道德问题越来越紧迫。由于越来越多的人使用游戏来作为日常娱乐和交流的方式，现在需要初步解决游戏中人工智能伦理问题，以便为未来更加完备的游戏业务铺路。




 ## Paper:12




1. Title: Predicting Resource Consumption of Kubernetes Container

2. Authors: Gianluca Turina, Andrea Borgarelli, Simone Donetti, Ferruccio Damiani, Einar Broch Johnsen, S. Lizeth Tapia Tarifa

3. Affiliation: Gianluca Turina, Einar Broch Johnsen, and S. Lizeth Tapia Tarifa are affiliated with the University of Oslo.

4. Keywords: Kubernetes, Microservices, Cloud Computing, Resource Models, Resource Prediction

5. Urls: None (not specified in the text)

6. Summary:

- (1): 本文研究基于Kubernetes容器系统的云计算资源管理问题。
- (2): 云计算系统的建模是实现自动化管理的重要步骤，但是当前复杂的云系统建模仍然存在挑战，且缺乏建模资源消耗的方法。本文提出了一种基于实证数据推导云系统资源模型的方法。
- (3): 本文的研究方法是通过对使用正式建模语言的部署服务模型进行GPU和内存资源的建模，然后将所得的资源模型用于模拟大规模部署场景时的性能预测。
- (4): 在具体实验中，本文以Kubernetes容器系统为基础，在资源预测方面取得良好的结果，并且在可接受的误差范围内获得了高精度的服务管理和执行方案比对。 
- (5): 本文的研究动机是云计算背景下服务管理的自动化，以及建模资源消耗的有效途径，为未来云计算的性能优化和自动化管理提供帮助。



