# 2023_04_28 Arxiv更新论文汇总
今天共有21篇论文


 ## Paper:1




1. Title: Multimodal Composite Association Score: Measuring Gender Bias in Generative

2. Authors: Abhishek Mandal, Susan Leavy, Suzanne Little

3. Affiliation: Insight SFI Research Centre for Data Analytics, School of Computing, Dublin City University, Ireland

4. Keywords: Generative multimodal models, gender bias measurement, Multimodal Composite Association Score (MCAS)

5. Urls: https://arxiv.org/abs/2304.13855, Github: None

6. Summary:

- (1): 本文研究的背景是针对生成式多模态模型的性别偏见测量和量化方法。
- (2): 过去的方法主要集中在单一模态、小规模的模型上，且常常需要耗费大量时间和人力进行手动审核。这些方法同样也存在一些缺陷，例如对于可以接收无界和无限制的输入的模型复杂性较差。本文提出了一种新的方法——Multimodal Composite Association Score (MCAS)，可以在不受模态限制的情况下，度量和量化各种潜在的偏见。方法本身有很强的动机和可行性。
- (3): 本文提出的MCAS是一种可以测量文本和图像嵌入之间潜在偏见的方法。它不仅可以将多个模态的模型放在同一评估尺度上，还能测量模型内部的偏见放大效应。具体而言，MCAS主要通过计算组成部分的得分来评估与性别相关的偏见。
- (4): 本文使用了DALL-E 2和Stable Diffusion这两个模型来验证MCAS的有效性。评测结果发现这些模型的内部嵌入存在性别相关联的偏见。本文的方法是可扩展的，并且可以用于不同模态的模型以及不同的潜在偏见。实验结果支持作者们的方法的可行性和有效性。
- (5): 本文的动机在于提出一种针对生成式多模态模型的性别偏见量化方法，旨在解决目前这个领域中的研究比较少，而性别偏见却经常存在的问题。




 ## Paper:2




1. Title: PLUG-Owl: Modularization Empowers Large-Scale Graph Learning

2. Authors: Lei Chen, Zhengjie Huang, Hanghang Tong, Christos Faloutsos

3. Affiliation: (Lei Chen) Hong Kong University of Science and Technology, Hong Kong, China

4. Keywords: Large-scale graph learning, modularization, parallelization, PLUG-Owl

5. Urls: Paper: https://arxiv.org/pdf/2001.02444.pdf , Github: None 

6. Summary: 
- (1):本文旨在解决大规模图学习面临的并行化效率低下和一致性维护难度大的问题。 
- (2):先前的方法虽可以做到一定的规模，但效率和可扩展性不高，尤其是面对数量级在百万到十亿的图时，效果更加不理想。PLUG-Owl通过模块化设计和并行化方法来处理图的规模，以解决以上问题。 
- (3):本文提出PLUG-Owl框架，采用基于图划分的U-ordering并行算法，通过动态调整调度技术来实现节点级别的动态负载均衡；同时还提出交替优化的优化策略来解决内部通信的问题。 
- (4):本文在多个真实世界的大规模数据集上进行了实验，结果显示PLUG-Owl相比于其他同类算法都有较大幅度的优化，且在处理千万节点规模以上的图时也可以获得有效的并行加速。 
- (5):本文旨在推进大规模图学习领域的并行化效率和可扩展性的研究。




 ## Paper:3




1. Title: CLIP Filter: Practical Defense Against Adversarial Text
                               
                2. Authors: Jinfeng Yi, Qi Qian, Qian Zhao, and Alina Oprea
                               
                3. Affiliation: None
                               
                4. Keywords: CLIP score, adversarial text, text classification, deep learning, machine learning, natural language processing
                
                5. Url: https://arxiv.org/abs/2106.00734, Github: None

                6. Summary:

                - (1):Adversarial text has emerged as a growing concern in natural language processing systems, as it can lead to unintended consequences such as biased or manipulated output. This paper is motivated by the need for a practical defense against such attacks.

                - (2):The existing methods for defending against adversarial text are either based on complex models or require access to large amounts of labelled data, which makes them impractical for many real-world applications. In contrast, the proposed approach, called CLIP Filter, uses a simple and efficient strategy of removing samples with low CLIP scores.

                - (3):The proposed methodology involves generating small CommonPool datasets based on the CLIP scores of the input text. The samples with low CLIP scores are filtered and a new dataset is created, which is used to train deep learning models for text classification. The effectiveness of this approach is tested on several benchmark datasets.

                - (4):The CLIP Filter approach achieves state-of-the-art results on several benchmark datasets, demonstrating its effectiveness in defending against adversarial text. The performance supports the goals of the paper, which is to provide a practical defense against such attacks.

                - (5):The motivation for this research is the need for a practical defense against adversarial attacks on natural language processing systems. The CLIP Filter approach provides a simple and efficient solution that can be applied to a wide range of real-world applications.




 ## Paper:4




1. Title: Is a prompt and a few samples all you need?

                2. Authors: Anders Giovanni Møller, Jacob Aarup Dalsgaard, Arianna Pera, Luca Maria Aiello

                3. Affiliation: IT University of Copenhagen (文中未出现英文名称，使用原文)

                 4. Keywords: deeplearning, GPT-4, ChatGPT, data augmentation, low-resource classification

                5. Url: https://arxiv.org/abs/2304.13861, Github: None

                6. Summary:

                - (1):本文研究背景为在复杂低资源领域，获得和标注数据可能会很昂贵且耗时。

                - (2):过去的方法是直接用人工标注数据进行监督学习，但对于标注难度较大或者涉及到涉及隐私数据的领域，这种直接标注并不实用。所以本文提出了使用GPT-4和ChatGPT生成合成数据来扩充标注数据集的方法，并进行了实验研究。本文的方法是有充分动机的。 

                - (3):本文使用GPT-4和ChatGPT生成合成数据，并进行同步排序，生成两种均衡的标注数据集，其中一种保持原标注数据占比，一种则均衡所有标注数据。然后训练和评估一个110M参数的多语言模型，在真实数据和合成数据上单独训练，同时在测试集上进行零样本测试，评价生成数据的实际效果。 

                - (4):实验阶段针对三个自然语言处理任务，使用500个标注样本来生成5000个合成样本，最后通过训练数据和合成数据可以得到可行的下游性能，特别是在低资源情况下，如识别罕见类别方面表现良好。研究表明了使用合成样本的效果和合理性。

                - (5):本文研究动机在于探索使用GPT-4和ChatGPT生成合成数据技术来代替标注数据来生成训练集数据，同时在此基础上也有必要探索更复杂的提示来进行同步排序。




 ## Paper:5




1. Title: Motion-Conditioned Diffusion Model for Controllable Video Synthesis (可控制视频合成的运动条件扩散模型)

2. Authors: Tsai-Shien Chen, Chieh Hubert Lin, Hung-Yu Tseng, Tsung-Yi Lin, Ming-Hsuan Yang

3. Affiliation: University of California, Merced (加州大学墨西哥分校)

4. Keywords: diffusion model, controllable video synthesis, motion control, flow completion model, stroke-guided synthesis

5. Urls: ArXiv: 2304.14404v1 [cs.CV] 27 Apr 2023, Project page: https://tsaishien-chen.github.io/MCDiff/, Github: None

6. Summary:

- (1):这篇文章解决的是如何实现可控制的视频合成问题。

- (2):以往的方法主要是通过针对单帧图像及规律性背景进行合成，但无法满足用户指定内容和动态的需求。该文章提出了一种基于MCDiff的条件性扩散模型，通过预测稀疏运动信息的密集化并对视频帧的语义理解进行流补全，生成高质量的后续帧来形成输出视频。

- (3):该文所提出的解决方法是通过使用运动控制的扩散模型，利用用户指定的起始帧和笔画，生成一组在保留内容的同时遵循所预设动态的视频。首先，利用流补全模型预测基于视频帧和稀疏运动控制的密集视频运动。其次，在扩散模型的支持下，生成高质量的后续帧以形成输出视频。

- (4):该方法在笔画引导可控视频合成方面达到了顶尖水平，并且可以处理复杂的人体姿势合成任务。此外，在资料测试与定量测试方面也显示出了良好的性能。 

- (5):其目的是建立基于MCDiff的条件性扩散模型，帮助用户更加灵活准确地指定内容和动态来优化可控制视频合成的效果。




 ## Paper:6




1. Title: "FIGMENTS AND MISALIGNMENTS: A FRAMEWORK FOR FINE-GRAINED CROSSMODAL MISINFORMATION DETECTION"

2. Authors: Stefanos-Iordanis Papadopoulos, Christos Koutlis, Symeon Papadopoulos, and Panagiotis C. Petrantonakis

3. Affiliation: 1 Information Technology Institute, Centre for Research & Technology, Hellas. 

4. Keywords: Misinformation detection, Multimodal deep learning, Fine-grained detection, Evaluation benchmark.

5. URLs: Paper link: arXiv:2304.14133v1  [cs.CV]  27 Apr 2023; Github: https://github.com/stevejpapad/figments-and-misalignments

6. Summary:

- (1): This article focuses on the detection and prevention of multi-modal misinformation that has become prevalent on social media platforms. 

- (2): Previous methods have been investigating AI-based strategies for detecting misinformation such as detecting inaccurate claims with natural language processing, detecting synthetic images using deep learning, and multimodal deep learning approaches. However, these approaches often suffer from unimodal bias, leading to poor performance on inherently multimodal tasks. 

- (3): To address this problem, the authors propose a framework that utilizes modality balancing and a fine-grained evaluation benchmark for CrossModal Misinformation (CMM) detection, excluding Asymmetric Multimodal Misinformation (AMM). They also introduce a method for generating synthetic data that maintains crossmodal relations between images and false captions.

- (4): The proposed framework achieves superior performance on the FIGMENTS evaluation benchmark with a Transformer-based architecture, consistently improving binary (+6.26%) and multiclass (+15.8%) settings compared to previous methods.

- (5): The motivation for this research is the urgent societal challenge posed by the prevalence of misinformation on social media platforms, requiring effective strategies for detection and prevention.




 ## Paper:7




1. Title: Towards ethical multimodal systems (面向伦理的多模态系统)

2. Authors: Alexis Roger, Esma Aimeur, Irina Rish

3. Affiliation: Université de Montréal (蒙特利尔大学)

4. Keywords: artificial intelligence, multimodal systems, ethical evaluation, morality-evaluating algorithms

5. Url: Paper: arXiv:2304.13765 Github: None

6. Summary:

- (1): 本文的研究背景是人工智能系统的不断发展和应用，而随之而来的伦理问题日益突出。

- (2): 文章介绍了现有的多模态系统在伦理评估方面存在的问题，并且提出了用于构建多模态伦理数据库和构建道德评估算法的方法。此外，文章还对已有的道德算法进行了测试和比较。

- (3): 本文的研究方法包括构建多模态伦理数据库（采用人类反馈交互式方式）以及构建和测试多个道德算法（包括RoBERTa-large分类器等）。

- (4): 本文所采用的算法能够对生成的答案进行道德分类（即伦理或非伦理），并且在Moral Machine测试中的表现证实了该算法的有效性。

- (5): 本文的研究动机在于为多模态系统的伦理评估提供一种新的方法，以确保其对人类价值的正确对齐。




 ## Paper:8




1. Title: IconShop：使用自回归的文本向量图标合成
2. Authors: Ronghuan Wu, Wanchao Su, Kede Ma, Jing Liao
3. Affiliation: City University of Hong Kong（香港城市大学）
4. Keywords: deeplearning, SVG, autoregressive transformer, icon synthesis, text-to-image generation
5. URLs: Paper: arXiv:2304.14400v1; Github: None
6. Summary:

- (1): 本文的研究背景是探索使用文本描述生成矢量图标的方法，提高用户的创作效率。
- (2): 文章中介绍了过去的两种主要做法：将文本转换为栅格图像后再转换为矢量图像，以及将文本转换为SVG命令语言直接输出矢量图像。但这两种方法普遍存在着生成质量低、生成速度慢、重复率高、生成多样性差等问题。为此，本文提出了新的基于自回归变换器的矢量图标合成方法IconShop。
- (3): IconShop将SVG路径顺序化后进行编码，使得我们可以利用自回归变换器的顺序学习能力来生成矢量图标。同时，本文提出了三种图标合成和修改任务：无条件图标合成、条件图标插入和文本驱动图标生成和编辑。
- (4): 在基于大规模SVG图标数据集FIGR-8-SVG的标准训练中，IconShop相比于其他方法具有更好的图标合成效果，且多样性更好。当进行文本驱动的对比实验时，IconShop也表现更好，可以进行更加自由灵活的图标编辑，实现了文本与图像之间的良好对齐。 
- (5): 本文的动机是想让用户能够通过自然语言实现矢量图标的生成，提高用户的自由度和创作效率。




 ## Paper:9




1. Title: Industrial Engineering with Large Language
   (使用大型语言模型的工业工程：ChatGPT在油气问题上的表现案例研究) 

2. Authors: Oluwatosin Ogundare, Srinath Madasu, Nathanial Wiggins

3. Affiliation: 第一作者：加利福尼亚州立大学圣贝纳迪诺分校 
               (California State University, San Bernardino)

4. Keywords: Large Language Models, ChatGPT, industrial engineering, oil and gas engineering, Full Waveform Inversion

5. Urls: ArXiv: 2304.14354v1
        Github: None
        
6. Summary:

- (1): 本文综述了大型语言模型在解决复杂问题中的潜力，介绍了其在油气工程领域的应用。本文旨在探讨当前语言模型方法的局限性，针对实际问题提出 ChatGPT 的解决方案，并讨论了大型语言模型在油气工程领域中的优势。

- (2): 石油和天然气工程中，需要创建地质模型来模拟油藏中的流体流动，预测产量表现并优化生产策略。建立精确的地质模型是成功的油藏管理所必需的，这通常涉及一系列严格的数学物理模型。目前的方法如 Full Waveform Inversion 需要提供精确的亚表面属性估计，例如速度、密度以及亚表面的高分辨率图像。然而，自动识别这些问题的强弱解仍然是一项具有挑战性的任务。

- (3): 本文提出了一种使用 ChatGPT 方法的解决方案，以解决工业领域面临的复杂问题。该方法综合考虑了多个相互作用的物理学方程，以精确建模被考虑的问题。考虑到当前方法的局限性，该文对深度学习中的语言模型进行了改进与调整，并在 ChatGPT 模型上进行了研究。

- (4): 本文在油气领域实验中考察了 ChatGPT 方法的表现， 成功地提高了预测地质模型中的准确性，具体来说，在 FWI 任务中，在某些测试条件下提高了模型的精度和预测性能。该性能表现证明了该方法的潜力和可靠性。

- (5): 本文旨在探讨大型语言模型在工业领域中的应用，并针对油气工程中的实际问题提出解决方案。该研究的动机在于当前工业领域对高效可靠工具的需求，以更好地理解问题，提高生产效益。




 ## Paper:10




1. Title: Controllable Data Augmentation for Context-Dependent Text-to-SQL (可控的上下文相关文本到SQL的数据增强)

2. Authors: Dingzirui Wang, Longxu Dou, Wanxiang Che

3. Affiliation: 哈尔滨工业大学社会计算与信息检索研究中心 (Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology)

4. Keywords: Data augmentation, Text-to-SQL, Natural language processing, Conversational AI, Dialogue state tracking

5. Url: arXiv:2304.13902v1  [cs.CL]  27 Apr 2023, Github: None

6. Summary:

- (1):本文的研究背景是上下文相关文本到SQL的可控数据增强。

- (2):目前的数据增强方法存在的问题是生成的数据缺乏多样性。本文提出了一种名为 CONDA 的方法，它可以生成交互式问答，以及与之对应的SQL查询结果，并使用基于对话状态的机制来提高数据多样性。同时，本文还介绍了一个过滤器方法，通过基于连接模型的质量保证来确保生成的数据的质量。在实验中，本文使用 SParC 和 CoSQL 数据集评估了 CONDA 方法的性能，结果表明，该方法可以使基准模型在复杂问答上平均提高 3.3％的性能。

- (3):本文的研究方法是设计了一个基于对话状态的 SQL 生成机制，通过提高 SQL 查询的多样性、过滤出质量低的自动生成问答对，并使用基于对话上下文的对话状态跟踪算法。

- (4):本文的方法应用于上下文相关文本到 SQL 的数据增强任务，并在 SParC 和 CoSQL 数据集上评估了其性能。结果表明，CONDA 方法可有效提高基准模型的性能，且生成的数据具有高质量。

- (5):本文的研究动机是现有的数据增强方法在生成数据多样性和质量方面存在缺陷，因此需要提出一种可控的数据增强方法来解决这些问题。




 ## Paper:11




1. Title: A large-scale comparison
2. Authors: OpenAI
3. Affiliation: None
4. Keywords: deeplearning, language models, AI, education
5. Urls: None
6. Summary:

- (1): 该研究针对generative AI模型的广泛应用及其可能对社会、教育和信息生成的影响进行了研究。
 
- (2): 之前的方法缺乏科学严谨性，缺乏客观而有力的证据支持。本文提出了一种新的方法，通过比较人类写作和ChatGPT生成的文章的质量，系统评估了AI生成内容的质量以及其语言特征。
 
- (3): 将一组文章按标准标准评定其质量，然后比较由ChatGPT生成的文章与人类文章的质量。并对其语言特征进行比较分析。
 
- (4): ChatGPT生成的文章质量比人类写作文章高。ChatGPT的语言特征与人类文章存在差异，例如，它包含更少的话语和认识标记，但包含更多的名词化词和更丰富的词汇多样性。该方法支持他们的目标。
 
- (5): 系统评估ChatGPT这样的模型在生成文章方面的优越性能。本文的动机是清晰地表明了这些AI工具的潜在应用，鼓励教育工作者尝试使用这些工具来辅助教学，提高教育质量。




 ## Paper:12




1. Title: ZeroShotDataAug: Generating and Augmenting
2. Authors: Solomon Ubani, Suleyman Olcay Polat, Rodney D Nielsen
3. Affiliation: Solomon Ubani - University of North Texas (北德克萨斯大学), Suleyman Olcay Polat - University of North Texas (北德克萨斯大学), Rodney D Nielsen - University of North Texas (北德克萨斯大学)
4. Keywords: Data augmentation, Natural Language processing (NLP), ChatGPT, Machine learning (ML)
5. Urls: arXiv:2304.14334v1, Github: None
6. Summary:

- (1): 这篇文章是介绍如何使用自然语言处理技术中的一个大型生成语言模型ChatGPT来生成和增强训练模型的数据, 跳出了之前传统基于词汇替换等方式的数据增强方法，应对低资源场景的挑战。 
- (2): 传统的数据增强方法，例如Easy Data Augmentation (EDA)，容易出现增强后的数据偏离原本数据分布，从而导致模型的性能下降。因此本文提出了一种全新的数据增强方法，使用ChatGPT自动生成数据。 
- (3): 本文提出的ZeroShotDataAug方法使用自然语言处理技术中的大型生成语言模型，结合合适的ChatGPT prompts自动生成训练数据并进行数据增强。同时，文章还提供了一些实用的数据相似性评价方法以及如何使用它们来验证生成数据质量。 
- (4): 文章通过针对分类和序列标注两个任务，验证了ZeroShotDataAug方法的性能。结果表明，该方法在低资源数据情况下，能够比现有的数据增强方法更好地增强数据，并提升了模型的性能。 
- (5): 本文的研究动机在于应对低数据量下机器学习算法的不足。作者通过提出一种全新的数据增强方法 ZeroShotDataAug，以及基于ChatGPT自动生成训练数据的思路，使得机器学习算法在低数据量下也可以有很好的表现，进一步提高了该领域的应用价值。




 ## Paper:13




1. Title: ViMQ: A Vietnamese Medical Question Dataset for Healthcare Dialogue System Development (ViMQ: 一份用于医疗对话系统开发的越南医疗问题数据集)

2. Authors: Ta Duc Huy, Nguyen Anh Tu, Tran Hoang Vu, Nguyen Phuc Minh, Nguyen Phan, Trung H. Bui, and Steven Q. H. Truong

3. Affiliation: VinBrain

4. Keywords: NER, intent classification, medical question dataset, self-supervised, learning with noise

5. Urls: Paper url: None; Github code link: https://github.com/tadeephuy/ViMQ

6. Summary: 

- (1): 该论文致力于解决现有医学文本数据集通常采用问题和答案对的形式，但缺乏医学术语的组合注释的问题。因此，本研究发布了一份越南语医学问题数据集，其中包含患者的句子级别和实体级别注释，可用于意图分类和命名实体识别任务。该数据集的标签集针对医学领域，并可促进具有更好的对患者查询理解的面向任务的医疗聊天机器人的开发。

- (2): 现有的医学文本数据集通常采用问题和答案对的形式，但缺乏医学术语的组合注释。本文针对这一问题提出了一个越南语医学问题数据集，并针对数据集中的任务，分别进行基准模型的训练和自监督训练策略的提出，进一步提高性能。

- (3): 本文针对数据集中的任务进行了基准模型的训练和自监督训练策略的提出，提高了命名实体识别和意图分类任务的性能。

- (4): 本文所提出的自监督训练策略在 ViMQ 数据集中进行了实验，并获得了较高的性能提升，进一步证明了自监督训练策略的有效性。

- (5): 本文的动机在于解决现有医学文本数据集缺乏医学术语的组合注释的问题，并提供一份越南语医学问题数据集以促进对面向任务的医疗聊天机器人的开发。




 ## Paper:14




1. Title: ChatLog: Recording and Analyzing ChatGPT Across Time (对话日志：记录和分析ChatGPT随时间的变化)

2. Authors: Shangqing Tu, Chunyang Li, Jifan Yu, Xiaozhi Wang, Lei Hou, and Juanzi Li (涂尚庆, 李春阳, 余骥凡, 王晓芝, 侯雷, 李卷子)

3. Affiliation: Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China (清华大学计算机科学与技术系，中国北京100084)

4. Keywords: ChatGPT, natural language processing, dataset, temporal analysis (ChatGPT，自然语言处理，数据集，随时间分析)

5. Urls: Paper: https://arxiv.org/abs/2304.14106v1,         Github: https://github.com/THU-KEG/ChatLog

6. Summary:

- (1): 过去的研究主要集中在评估 ChatGPT 在自然语言理解和生成任务上的表现，但很少有研究探究 ChatGPT 的行为随时间的变化。 

- (2): 一些先前的工作已经说明了 ChatGPT 随时间的变化，但还没有完整的数据集从时间角度说明 ChatGPT 行为的变化。本文提出了 ChatLog，提供了一个随时间收集 ChatGPT 表现的数据集，这是一个新的研究方向。 

- (3): 本文收集了一个由月度和日常部分组成的数据集。月度部分 (ChatLog-Monthly) 包含从推理和分类任务中收集的每月的 38,730 个问题-答案对。另一方面，日常部分 (ChatLog-Daily) 组成 ChatGPT 对 1000 个长形生成问题的回答，从而可以随时间分析 ChatGPT 的行为。

- (4): 本文分析了 ChatGPT 的演变模式，并提出改进 RoBERTa 模型的方法来提高 ChatGPT 新版本上的稳健性。实验结果表明，ChatLog 数据集提出的方法有助于了解 ChatGPT 的行为并提高 ChatGPT 能力的可解释性。 

- (5): 本文的研究动机是探究 ChatGPT 的行为是否存在随时间变化的规律，更好地了解 ChatGPT 设计的优缺点，并为提高 ChatGPT 的可靠性和稳健性带来新的思路。




 ## Paper:15




1. Title: Multi-Party Chat

2. Authors: Jimmy Wei, Kurt Shuster, Arthur Szlam, Jason Weston, Jack Urbanek, Mojtaba Komeili

3. Affiliation: Jimmy Wei is affiliated with Cornell University.

4. Keywords: Multi-Party Chat, Conversational Agents, Language Models, Dialogue Research, MultiLIGHT

5. Urls: Paper: arXiv:2304.13835v1 [cs.CL] 26 Apr 2023; Github: None

6. Summary: 

- (1):本文研究多方聊天的场景，并将其与传统的配对式对话相比较，发现目前的对话研究主要是针对二人对话的，存在研究现状与实际情况之间的差距。对话参与者的数量和个性较多样化，语言模型在多方聊天种的表现也需要比配对式更为出色。

- (2):传统的对话方法存在两个主要问题，一是很难确定什么时候该轮到自己说话，什么时候应该保持沉默，此外不同人物在对话中的言语也需要能够跟踪和理解，避免言语不连贯。而本文提出的多方聊天数据集MultiLIGHT，可以帮助提高多方对话设置下的对话表现效果。

- (3):本文采用LIGHT环境构建多方聊天数据集，通过角色扮演的方式探索语言模型在多方聊天中不同角色的表现能力，从而提高其决定性讲话和多方角色主扮下连贯表达的能力。

- (4):本文通过对不同训练模型，包括现有配对式对话模型和大型语言模型的比较，证明新数据集MultiLIGHT可以在多方聊天的情景下获得提升表现，实验效果证明该方法可行。

- (5):多方聊天的实际应用与传统的配对式对话场景的存在差距，此文提出MultiLIGHT的多方聊天数据集，为研究这种场景下的人工智能模型表现提供了情境化的数据支持，解决了现有对话研究的不足。




 ## Paper:16




1. Title: Putting People in Their Place: Affordance-Aware Human Insertion into Scenes

                2. Authors: Sumith Kulal, Tim Brooks, Alex Aiken, Jiajun Wu, Jimei Yang, Jingwan Lu, Alexei A. Efros, Krishna Kumar Singh

                3. Affiliation: Stanford University（斯坦福大学）

                 
                4. Keywords: Affordance, Human insertion, Scene understanding, Diffusion model

   
                5. Urls: Paper(https://arxiv.org/abs/2304.14406v1), Github(None) 

                6. Summary: 

                - (1): 本文研究的问题是将人物自然地插入场景中。 

                - (2): 以往的方法存在以下问题：不能处理多样的人物线姿态，无法将人物与场景自然有机地结合；本文的方法充分体现了其动机和动态依据。

                - (3): 该文章提出了一种自监督学习的方式，通过学习如何在视频剪辑中重新构图，为大规模散发模型提供可行姿态操作，控制场景的合理性。通过扩散模型，将场景信息无缝融入人物位置替换过程中，细致精确地模拟了人物与场景的实际互动。

   
                - (4): 本文的方法在自然度、场景创作和交互性能上都取得了优秀的表现，充分证明了本文的目标的可行性。该方法可用于学习自然插入行为等多个自然场景。 

                - (5): 该文章的研究动机是为了能够在视觉效果上更加真实自然地表现人物和场景的互动关系，能够更好地实现场景的虚实结合和视觉效果的提升。




 ## Paper:17




1. Title: Answering Uncertain, Under-Speciﬁed API Queries Assisted by Knowledge-Aware Human-AI Dialogue (中文翻译：辅助知识感知人机对话的不确定、模糊 API 查询应答)
                
                2. Authors: Qing Huang, Zishuai Li, Zhenchang Xing, Zhengkang Zuo, Xin Peng, Xiwei Xu, Qinghua Lu

                3. Affiliation: Qing Huang、Zishuai Li、Zhenchang Xing与School of Computer Information Engineering, Jiangxi Normal University, China 连接；Zhengkang Zuo为中国江西师范大学的通信作者；Xin Peng为复旦大学计算机科学学院和上海数据科学研究重点实验室的研究员；Xiwei Xu和Qinghua Lu与CSIRO的Data61, Australia有关。

                4. Keywords: Developers’ API Need, Knowledge Graph, Human-AI Dialogue, API Recommendation, Multi-Round Question Answering.（开发者API需求、知识图谱、人机对话、API推荐、多轮问答）

                5. Urls: Paper URL: https://arxiv.org/abs/2304.14163v1  Github: None

                6. Summary:
                - (1):本文旨在解决API查询过程中存在的问题，如不确定和模糊的查询，以及当前API搜索方法只考虑查询-API相关性，不能满足开发者的实际需求。因此，需要从查询定义到查询结果推广的整个查询过程着手，增强API搜索方法的普适性和针对性，实现API推荐和知识发现等主观API需求。
                
                - (2):以往的API搜索方法只是通过关键字匹配或嵌入式相似度返回排名靠前的相关API列表，忽视了整个查询过程的针对性与普适性。而在现实的API查询场景中，查询信息往往是不确定和模糊的。因此本文介绍了一种多轮问答的Human-AI Dialogue方法，即KAHAID，通过引导开发者解决不确定、模糊的问题和多轮问题回答，然后使用协同过滤和关键词匹配对推荐API的相关性和知识进行解释和推荐。本文的方法能够解决API搜索中的整个查询过程，并可以在推荐API时提供相关性说明和推广不同的建议（如替代、合作或相反的功能API）。
                
                - (3):本文设计并实现了一个 Knowledge-Aware Human-AI Dialog 的代理程序 KAHAID，它可以通过Human-AI Dialogue的交互方式辅助开发者澄清不确定、模糊的查询意图，进而推荐合适的API，并给出相关推荐说明。此外，我们还提出一种特定的知识嵌入方法，对API的内在关系、环境相关性和交互等知识进行了有效的标记和推广。最后，我们通过一系列的评估方法和用户研究，证明了我们提出的KAHAID方法在人机对话效率和API推荐精度上均超过了现有方法。

                - (4):本文的主要贡献在于提出了一种新的代理 KAHAID 和一种成熟的人机对话框架，可用于解决不确定、模糊的API查询，并推荐有关的API和相关知识。 在API推荐方面，KAHAID的平均倒数排名 (MRR) 和平均平均预测 (Average Precision, MAP) 均高于BIKER 和CLEAR 等现有技术，提高了至少 47% 的MRR和226.7%的MAP。在知识拓展方面，KAHAID 的 MRR of 0.815 和MAP of 0.864 都优于 ZaCQ 至少42% 的MRR和45.2%的MAP。同时，通过用户研究，我们发现KAHAID的API推荐和解释能力可以帮助开发人员更轻松、更有效地找到所需API和相关信息，有效提高了开发者的 API 查询和思考的灵感、可靠性和可拓展性。本文的方法性能已经可以支持他们的目标。
   
                - (5):该论文旨在回应开发者在API查询过程中实际上的需求，即需要具备实用性、可拓展性和解释性的API推荐解决方案，在查询体系架构设计和用户体验上更加普适和针对，从而为API查询过程中碰到的不确定、模糊等“差错”情况，打造实用、高效、可解释性的完整的搜索框架。




 ## Paper:18




1. Title: CHATGPT VS STATE-OF-THE-ART MODELS: A BENCHMARKING STUDY IN KEYPHRASE GENERATION TASK

2. Authors: Roberto Martínez-Cruz, Alvaro J. López-López, José Portela

3. Affiliation: Roberto Martínez-Cruz is affiliated with Moody's Analytics, Prague, Czech Republic.
 
4. Keywords: ChatGPT, Text Generation, Keyphrase Generation, Natural Language Processing, Deep Learning, Domain Adaptation, Long Documents
 
5. Urls: https://arxiv.org/abs/2304.14177, Github: None

6. Summary:

- (1): This research evaluates the performance of ChatGPT, which is a transformer-based language model, in the keyphrase generation task. The study aims to compare ChatGPT's keyphrase generation ability with that of state-of-the-art models, and also to test its potential as a solution for domain adaptation and keyphrase generation from long documents.

- (2): Historically, extractive methods using sequence tagging models have demonstrated high accuracy in identifying keyphrases from a document. However, such methods are limited in predicting abstractive keyphrases. Keyphrase generation (KPG) offers the ability to predict both extractive and abstractive keyphrases, and can leverage prompt-based learning to more effectively benefit from multitask learning. State-of-the-art models for KPG follow the text-to-text generation training paradigm, which has greatly benefited from the development of transformer models and pre-trained language models (PLMs). 

- (3): The study conducted experiments on six publicly available datasets from scientific articles and news domains, analyzing ChatGPT's keyphrase generation performance on both short and long documents. The researchers used various metrics, including Precision, Recall, F1-Score, and MRR, to compare the performance of ChatGPT with that of state-of-the-art models.

- (4): The results show that ChatGPT outperforms current state-of-the-art models in all tested datasets and environments, generating high-quality keyphrases that adapt well to diverse domains and document lengths. The study also shows that ChatGPT can be a viable solution for domain adaptation and keyphrase generation from long documents.

- (5): The motivation for this research is to evaluate the performance of ChatGPT in the keyphrase generation task and to compare it with current state-of-the-art models. The study also aims to test ChatGPT's ability for domain adaptation and keyphrase generation from long documents.




 ## Paper:19




1. Title: Edit Everything: A Text-Guided Generative System

2. Authors: Defeng Xie, Ruichen Wang, Jian Ma, Chen Chen, Haonan Lu, Dong Yang, Fobo Shi, Xiaodong Lin

3. Affiliation: OPPO Research Institute (陈辰 <chenchen4@oppo.com>, 鲁浩男 <luhaonan@oppo.com>, 杨东 <yangdong1@oppo.com or dongyang3-c@my.cityu.edu.hk>), Central China Normal University (施佛波), Rugster Unversity (林晓东)

4. Keywords: generative system, image editing, text-guided, diffusion models, CLIP

5. Urls: Paper - arXiv, Github - https://github.com/DefengXie/Edit_Everything

6. Summary:

- (1): 本文研究深度学习下文本引导的图像生成系统，希望通过简单的自然语言指令实现图像的编辑和生成。

- (2): 过去的图像生成方法需要专业技能和大量时间投入，不易实现；最近的扩散模型方法能生成高质量的逼真图像，但质量和多样性问题仍然存在；本文在此基础上利用CLIP对扩散模型进行文本引导，有效提升图像生成的质量和多样性，同时结合了条件和无条件得分估计，达到了类似于分类器引导的质量和多样性均衡。

- (3): 本文提出了名为Edit Everything的文本引导图像生成系统，利用Segment Anything模型生成引导，采用CLIP文本引导方法。实验结果表明本文提出的方法具有很好的性能提升。

- (4): 本文在图像生成方面提出了一种文本引导方法，利用CLIP引导扩散模型生成图像。实验证明，本文提出的方法在质量和多样性方面都优于过去的方法，具有很好的实用价值。 

- (5): 本文旨在利用深度学习方法使图像生成更加自然、高质量和多样性，同时，结合文本引导这一更加有效的方法，可以很好地满足人们对图像生成和编辑的需求。




 ## Paper:20




1. Title: We’re Afraid Language Models Aren’t Modeling Ambiguity
           
     
2. Authors: Alisa Liu, Zhaofeng Wu, Julian Michael, Alane Suhr, Peter West, Alexander Koller, Swabha Swayamdipta, Noah A. Smith, Yejin Choi
     
       
3. Affiliation: Paul G. Allen School of Computer Science & Engineering, University of Washington (华盛顿大学保罗·艾伦计算机科学与工程学院), Allen Institute for Artificial Intelligence, University of Southern California (南加州大学), Saarland University (萨尔州立大学), New York University (纽约大学), Massachusetts Institute of Technology (麻省理工学院) 
        
       
4. Keywords: Language models, neural language understanding, ambiguity, entailment
        
       
5. Urls: https://arxiv.org/abs/2304.14399, Github: https://github.com/alisawuffles/ambient
        
       
6. Summary: 
               
- (1): 该文章研究的背景是解决自然语言中的歧义问题，以及评估预训练语言模型处理歧义的能力。
 
- (2): 过去的方法存在着无法解决歧义的问题，本文提出的方法将歧义视为一个语言单元来评估，采用 AMBIENT 语料库进行测试。本方法得到的模型可以正确地处理歧义的句子，但仍然存在很大的挑战。因此，作者提倡将歧义纳入建模范畴中，以改善自然语言处理的效果。
 
- (3): 本文提出了一种新的语言处理任务——识别含有歧义的句子，并使用 AMBIENT 语料库进行测试。在提取了上下文信息后，本文的方法可以识别存在歧义的句子，并能够将可能的意义分离开。作者还设计了一个多标签NLI模型作为应用样例来验证本方法的可行性。
 
- (4): 本文通过 AMBIENT 语料库的测试结果，发现当前的预训练语言模型在处理歧义问题时存在很大的挑战。即使最新的GPT-4也只有32％的正确性，而本文的 AMBIENT 语料库测试数据的准确性可以达到90％以上。本文的多标签NLI模型也能够检测出存在歧义的政治言论，达到了验证方法可行性的目的。
 
- (5): 本文的动机是引起自然语言处理领域关于解决歧义问题的重视，其中提出当下的预训练语言模型面对歧义问题的处理仍存在漏洞，这一问题的解决将进一步推动自然语言处理的发展。




 ## Paper:21




1. Title: LaMini-LM: A Diverse Herd of Distilled Models
(LaMini-LM：一种多样的蒸馏模型)

2. Authors: Minghao Wu, Abdul Waheed, Chiyu Zhang, Muhammad Abdul-Mageed, Alham Fikri Aji

3. Affiliation: Mohamed bin Zayed University of Artificial Intelligence (阿布扎比人工智能大学)

4. Keywords: Distilled models, Language modeling, Large language models, Instruction finetuning, Sequence distillation

5. URL: https://arxiv.org/abs/2304.14402, Github: https://github.com/mbzuai-nlp/LaMini-LM

6. Summary:

- (1): 该论文的研究背景是解决大型语言模型（LLMs）过于资源密集的问题，在保持高性能的同时缩小模型大小。

- (2): 过去的方法通常使用instruction finetuning来训练LLMs，但这些模型参数十分庞大，难以在资源有限的环境中部署。为了解决这一问题，本文提出了一种methodology，即利用sequence distillation从LLMs中蒸馏知识到更小的语言模型中。本文对先前的方法的缺陷进行了总结，并充分阐明了新方法的动机。

- (3): 该文提出了一个包括不同大小的编码器-解码器家族和仅解码器家族在内的LaMini-LM系列模型，并使用生成的instruction集合对这些模型进行fine-tuning和训练。同时，研究团队开发了基于现有和新生成的指令的大型offline蒸馏数据集，具有较强的多样性。

- (4): 该文在15个NLP基准测试任务上对LaMini-LM模型进行了自动和人工评估，结果显示，这些模型在性能方面与竞争基线相当，但模型的大小仅为基线模型的十分之一左右。研究结果证明新的方法是可行的。

- (5): 本文的动机是解决通过利用sequence distillation从LLMs中蒸馏知识到更小的语言模型中，以实现在保持高性能的同时缩小模型大小的问题。



