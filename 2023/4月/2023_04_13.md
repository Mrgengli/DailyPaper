# 2023_04_13 Arxiv更新论文汇总
今天共有28篇论文


 ## Paper:1




1. Title: Evaluating AIGC Detectors on Code Content（评估AIGC检测器在代码内容上的表现）

2. Authors: Jian Wang, Shangqing Liu, Xiaofei Xie, Yi Li

3. Affiliation: Nanyang Technological University（南洋理工大学）

4. Keywords: Artificial Intelligence Generated Content, ChatGPT, AIGC Detectors, Software development, Empirical study（人工智能生成内容， ChatGPT， AIGC检测器，软件开发，实证研究）

5. URLs: Paper: arXiv:2304.05193v1 [cs.SE] 11 Apr 2023 ; Github: None

6. Summary: 

- (1): 本文研究背景为AIGC及其相关应用的快速发展，尤其是ChatGPT在软件开发领域的广泛应用及其潜在滥用所引起的问题。

- (2): 已有相关研究提出了同类应用的检测器，但这些检测器在代码相关内容上的表现还未得以研究。该研究提出了一项在软件开发领域评估已有AIGC检测器的实证研究，发现这些检测器在自然语言数据上表现良好，但在代码相关数据上表现不及预期。为此，研究者提出了一种利用领域特征的Fine-tuning方法，使得检测器在特定领域的数据上表现显著提升。同时，通过人类实验，也发现人类对于这类虚假内容的检测同样存在困难。

- (3): 本文采用实证研究方法，构建了包含49.25万个ChatGPT生成的代码相关数据样本的数据集。并评估了六个AIGC检测器在该数据集上的表现，其中包括三个商业化和三个开源解决方案。此外，为更好对比人类与自动化检测器的性能，研究者还设计了人类实验，并针对性地与自动化检测器做了比较。 

- (4): 本文的研究主要针对现有AIGC检测器在代码相关内容上的表现与优化。实验结果表明，Fine-tuning方法确实可以显著提升检测器在特定领域的表现，但仍存在普适性较差的问题。与此同时，由于检测内容的特殊性，该领域的人类检测同样存在挑战，因此建议针对该领域研发更为专业的检测器。

- (5): 本文的研究目的在于填补已有研究的空白，即评估现有AIGC检测器在代码相关内容上的表现。此外，也旨在唤起人们对于AIGC在特定领域中可能带来的潜在风险的认识，并为之后研究这一特定领域的检测器提供思路。




 ## Paper:2




1. Title: Does Informativeness Matter? Active Learning (in Chinese: 信息量对主动学习有影响吗？)
 
2. Authors: Wei Tan, Jionghao Lin, David Lang, Guanliang Chen, Dragan Gasevic, Lan Du, and Wray Buntine
 
3. Affiliation:  第一作者： Wei Tan (澳大利亚莫纳什大学); 
 
4. Keywords: Informativeness, Active Learning, Dialogue Act Classification, Large Language Models, Intelligent Tutoring Systems (关键词：信息量，主动学习，对话行为分类，大型语言模型，智能辅导系统)
 
5. Urls: Paper: https://arxiv.org/pdf/2304.05578.pdf 
 
Github: None
 
6. Summary: 

- (1): 本文研究了在对话行为分类任务中样本的信息量是否会影响到主动学习的效果。该研究领域主要落在自然语言处理、机器学习和人工智能交互等相关领域。 

- (2): 过去的研究中，往往采用随机抽样的方法获取用于手动标注的数据，但忽略了样本信息量的差异和分类器学习的可能性。由于过分强调了样本数量，而淡化了样本信息量的作用，可能导致在分类器训练中使用了大量的低信息量的样本，因而出现了资源浪费和训练效果不佳的问题。因此，文章提出了一种可行的解决方案：利用主动学习算法来对样本进行选择，以达到尽可能选择高信息量样本的目的。 

- (3): 本文提出了一种新的方法，旨在通过主动学习的采样方法来训练对话行为分类器。具体而言，该方法利用了大型语言模型，提高了分类器的预测准确性，并通过对话行为分类器的训练过程，演示了如何利用主动学习算法来减少人工标注成本。 

- (4): 经过实验验证，本文提出的主动学习算法在对话行为分类任务方面表现出色，在人工标注成本减少的情况下，分类器性能得到了提高。空间复杂度也有显著的提高，从而得出选择高信息量样本对于训练DAs分类器有效的结论。 

- (5): 研究意义在于: 在进一步提高高性能智能辅导系统或语神经科学研究方面有较为广泛的应用价值。




 ## Paper:3




1. Title: Chinese Legal Document Segmentation via Key Information Extraction and Multi-task Learning

2. Authors: Xiaoyan Zhang, Yidong Chen, Chunfu Wang, Xiaojie Yuan, Zhibo Wang, Xiaofei Lu, Qin Lu 

3. Affiliation: 中国科学院自动化研究所 (Chinese Academy of Sciences)

4. Keywords: Legal document segmentation, Multi-task learning, Key information extraction

5. URLs: https://www.aclweb.org/anthology/D19-7311.pdf, Github: None

6. Summary:

- (1):本文研究中文法律文书分割问题，并提出了基于关键信息提取和多任务学习的方法。

- (2):过去的方法主要基于规则或固定模板，无法应对文书间的结构差异和变化。本文提出了一种利用关键信息提取和多任务学习相结合的方法。该方法首先提取文书中的关键信息，然后以此为基础，应用多任务学习方法进行文本段落切分和标题识别。与之前的方法相比，该方法能够提供更好的精度。

- (3):本文提出的方法包括两个主要部分。第一个部分是关键信息提取，该部分基于条件随机场模型提取文书中关键信息所在的位置。第二个部分是多任务学习，该部分通过共享神经网络实现对文本段落切分和标题识别两个任务的同时学习。

- (4):该方法在两个不同的数据集上进行了测试，实验结果表明该方法能够在文档段落切分和标题识别方面取得更好的结果。

- (5):本文旨在解决中文法律文书分割的难题，提出了一种新的分割方法。该方法的关键在于将关键信息提取和多任务学习相结合，可以更准确和高效地进行文书分割。




 ## Paper:4




1. Title: Using Multiple RDF Knowledge Graphs for Enriching ChatGPT Responses

2. Authors: Michalis Mountantonakis and Yannis Tzitzikas

3. Affiliation: Institute of Computer Science - FORTH-ICS, 希腊 and Computer Science Department - University of Crete, 希腊

4. Keywords: Artificial Intelligence, ChatGPT, RDF Knowledge Graphs, fact checking, response enrichment

5. Urls: Paper: arXiv:2304.05774v1 [cs.DB] 12 Apr 2023, Demo Video: https://youtu.be/H30bSv9NfUw, Demo URL: https://demos.isl.ics.forth.gr/GPToLODS, Github: None

6. Summary:

- (1): 本文关注人工智能技术 ChatGPT 的应用，ChatGPT 能够对各种领域的问题给出详细和有条理的回答；然而，许多情况下，其回答虽然听起来似是而非，但实际上是不准确的，也没有提供证据，因此任何用户都需要进一步搜索和查证答案的准确性或寻找有关响应实体的更多信息。同时，RDF 知识图谱的数量急剧增加，这些图谱提供了高质量结构化数据。
- (2): 过去的方法无法运用RDF知识图谱来丰富ChatGPT的回答，无法快速验证响应的事实。本文介绍了一个名为GPT•LODS（Linked Open Data Syndesis）的研究原型，该原型能够从数百个RDF知识图谱中获取更多信息，将每个响应实体标识和注释，并提供指向LODsyndesis KG（其中包含400个RDF知识图谱和超过412百万的实体的集成数据）的统计和超链接。因此，在实现实时响应的同时，有可能丰富实体的内容并执行事实检查和验证。
- (3): 本文提出了GPT•LODS的研究原型，该原型包含三个主要模块：ChatGPT模块，RDF结构信息模块和RML映射模块。ChatGPT模块以结束时间的形式返回响应，可以使用GPT-3.5系列和GPT-4系列的大型语言模型。RDF结构信息模块使用其他工具来解析RDF KG的架构信息。RML映射模块将ChatGPT的响应和RDF图谱的数据进行融合。
- (4): 本文的贡献在于提供了一种新的方法，通过结合RDF知识图谱和ChatGPT来丰富响应并自动执行事实检查和验证。作者在使用GPT•LODS原型的各种场景下进行了评估，结果显示该方法优于仅使用ChatGPT的方法。此外，作者还提供了一个可用于在线演示的Demo链接和Github代码，对于感兴趣的读者可以自行探索并使用该原型。
- (5): 本文的动机在于，尽管已经有了许多在RDF KG上的工作，但本文可以看作是第一篇将ChatGPT与RDF KG结合的研究文章。它能够自动丰富响应并自动执行事实检查和验证。本文提供了一个可用于在线演示的原型，对于自然语言处理和知识图谱领域的研究和实践具有实际意义。




 ## Paper:5




1. Title: An Improved Heart Disease Prediction Using Stacked Ensemble Method (基于层叠集成方法的心脏疾病预测改进)

2. Authors: Md. Maidul Islam, Tanzina Nasrin Tania, Sharmin Akter, Kazi Hassan Shakib

3. Affiliation: City University, Dhaka, Bangladesh (孟加拉达卡市立大学)

4. Keywords: Prediction, Heart Disease, CART, GBM, Multilayer Perception

5. Urls: Paper - None, Github - None

6. Summary:

- (1):本研究的研究背景是心脏疾病已成为全球最大的死亡原因之一，因此，基于机器学习的心脏疾病预测成为了重要的课题。

- (2):过去的方法主要涉及单一分类器，这在一定程度上缺乏精度和可靠性。提出的方法采用了九种分类算法和一组技术来预测心脏疾病，并使用了层叠集成方法以提高预测性能和准确性，以避免传统方法的问题。

- (3):本文的研究方法包括数据预处理技术(异常检测和去除、检查和删除缺失条目、特征归一化、交叉验证等)、使用九种分类算法(如随机森林、多层感知器、k临近、极限随机树、XGBoost、支持向量机、自适应增强、决策树和GBM)、使用八个分类器性能评估指标(如分枝精度、精度、F1得分、特异度、ROC曲线、灵敏度、对数损失和Matthews相关系数)、使用八个分类器性能评估指标，并使用了层叠集成方法来集成这九种算法的技能以提高性能和准确性。

- (4):本文所提出的方法可提高对心脏疾病的预测准确性，通过对已建立的心脏疾病数据集的处理，本文的方法可以轻松区分患有心脏疾病和正常人群。进行了多次实验发现，提出的方案具有良好的应用能力，并达到了高准确度的分类效果。

- (5):本文的研究动机是希望能够使用机器学习技术提高心脏疾病的预测细度和有效性，从而提高心脏疾病的治疗效果。




 ## Paper:6




1. Title: Boosting Cross-task Transferability of Adversarial Patches with Visual Relations

                2. Authors: Tony Ma, Songze Li, Yisong Xiao, Shunchang Liu

                3. Affiliation: Tony Ma - Shen Yuan Honors College, Beihang University

                4. Keywords: deeplearning, ML, NLP, CV, adversarial examples, transferability, cross-task, visual relations 

                5. Urls: https://arxiv.org/abs/2304.05402

                6. Summary: 

                - (1):本文研究的背景是如何提高对抗补丁的跨任务可迁移性。

                - (2):过去的方法主要集中在提高模型间的可迁移性，没有考虑把对抗样本用于不同任务的迁移性。而近年来兴起的基础多任务 AI 系统，如Visual ChatGPT，使得由单一任务生成的对抗样本的效用相对有限。此外，这些系统常常涉及超出简单识别任务的推理功能。本文通过Scene graphs结合基于对象识别的deception和基于谓词的关系消除提出了一种新的跨任务对抗补丁生成方法，名为VRAP，旨在评估各种不同视觉任务的鲁棒性，特别是那些涉及视觉推理的任务。VRAP破坏了推理任务之间共享的视觉推理信息，从而提高了跨任务的可迁移性。 

                - (3):本文提出的方法是基于Scene graphs的VRAP，通过将对象识别-based deception和predicate-based relations elimination相结合，破坏不同inferential tasks之间共享的视觉推理信息。

                - (4):本文在不同的视觉推理任务上验证了VRAP方法，它的性能显著优于先前的方法。

                - (5):本文的激励是那些多任务 AI 系统的出现，这些系统不再依赖单个机器学习模型解决特定任务，而是可以解决不同情况下的问题，从而降低了单一任务的有效性。因此，必须开发具有强大跨任务可迁移性的方法，尤其是在跨推理任务可迁移性领域。




 ## Paper:7




1. Title: Learning Transferable Pedestrian Representation from Multimodal Data for Person Re-Identification and Beyond

2. Authors: Yifan Sun, Xiaofei Zhang, Rongrong Ji, Xiaoshuai Zhang, Yanwei Fu, Yongjian Wu, Feiyue Huang

3. Affiliation: 中国科学技术大学

4. Keywords: Unsupervised Learning, Multi-modal Data, Pedestrian Analysis, Contrastive Learning, Pedestrian Re-Identification

5. Urls: Paper link: https://arxiv.org/pdf/2105.13914.pdf, Github: None

6. Summary:
- (1): 本文是关于运用多模态数据学习可转移的行人矢量表征，进而提升人物重识别以及其他行人分析任务中的性能。
- (2): 以往的无监督人物重识别方法算法专为此任务而设计，难以适应其他行人分析任务。本文提出VAL-PAT框架通过三种学习目标：自监督对比学习、图文对比学习以及多属性分类，学习可转移的行人表征。这三种方法分别提升了模型对行人特征、行人外观信息、以及细节属性的理解。 
- (3): 本文首先在LUPerson-TA数据集上进行预训练，然后将训练好的模型应用到各项行人分析任务中。其中，自监督对比学习和图文对比学习用于训练行人表征，多属性分类用于训练属性识别模型。通过预先训练，模型能够更好地理解行人的内在特征和外在属性信息。
- (4): 本文在不同行人分析任务中对VAL-PAT框架进行了评估，包括人物重识别、人物属性识别和基于文本的人物搜索。评估结果表明，与其他现有算法相比，VAL-PAT框架能够学习到更好的行人表征，具有更好的性能表现。
- (5): 本文的研究动机在于解决现有无监督人物重识别算法不能很好地适应其他行人分析任务的问题，并提出了一个新的框架来学习可转移的行人表征。可转移的行人表征不仅能够提高人物重识别的性能，还适用于其他行人分析任务，拓宽了应用范围。




 ## Paper:8




1. Title: The Wall Street Neophyte: A Zero-Shot Analysis of ChatGPT Over
Multimodal Stock Movement Prediction Challenges

2. Authors: Qianqian Xie, Weiguang Han, Yanzhao Lai, Min Peng, Jimin Huang

3. Affiliation: 武汉大学计算机学院

4. Keywords: large language models, ChatGPT, stock market prediction, multimodal, zero-shot analysis

5. URLs: paper - arXiv:2304.05351v1; Github - None

6. Summary:

- (1): 本文旨在探究大语言模型(ChatGPT)在股市预测方面的应用，尤其是在多模态的情况下，加入文本特征的影响。

- (2): 过去的方法可以归为三类，分别是基于历史数据和技术指标、基于新闻文章以捕捉外在影响、以及利用社交媒体平台提供的实时投资者情感和市场事件。然而，这些方法对于股市预测的准确性有一定的局限。

- (3): 本文提出了一种全新的零样本方法，即使用自然语言生成模型(ChatGPT)，结合历史股票价格数据和训练文本，在多模态的情况下进行股市预测。

- (4): 本文的实验结果表明，ChatGPT表现不如现有的最先进的方法，甚至不如使用价格特征的传统线性回归方法。虽然在一定程度上，Chain-of-Thought提示策略以及加入文本特征有一定的潜力，但ChatGPT的性能仍然不够优秀。此外，研究人员还发现ChatGPT在解释性和稳定性方面存在一些局限性，需要更专业的训练或微调。本文为未来的研究提供了探究ChatGPT在股市预测以及利用社交媒体情感和历史数据改进金融市场分析和预测的基础。

- (5): 本文的研究动机是探讨大语言模型ChatGPT在股市预测方面的应用，特别是在多模态情况下将文本等非数字信息与股票价格数据结合的研究新模型。




 ## Paper:9




1. Title: Interpretable analysis scheme for quantum phase detection based on fluctuations

                2. Authors: Annabelle Bohrdt, Cole Miles, Ruihan Wu, Christie Chiu, Muqing Xu, Geoffrey Ji, Markus Greiner, Kilian Q. Weinberger, Eugene Demler, Eun-Ah Kim

                3. Affiliation: None (all authors are affiliated with various institutions)

                4. Keywords: Quantum physics, neural networks, interpretability, phase detection, Heisenberg model

                5. Urls: https://www.nature.com/articles/s41467-021-24403-1, Github: None

                6. Summary:

                - (1): This paper focuses on the problem of detecting different phases of matter in strongly-correlated quantum physics.

                - (2): The past methods have mostly been conventional neural networks that lack interpretability on a physical level. By combining confusion learning with correlation convolutional neural networks, this paper proposes a method that yields fully interpretable phase detection in terms of correlation functions. The approach is well-motivated since it allows for more physically meaningful interpretation of the results.

                - (3): The research methodology involves using confusion learning and correlation convolutional neural networks to detect changes in snapshots of the 2D Heisenberg model above and below a characteristic temperature where magnetic correlations become significantly long-range. The neural network is trained to pick up qualitative changes in the snapshots, identifying the full counting statistics of nearest neighbor spin correlations as the most important quantity for the decision process.

                - (4): The method achieves good performance in detecting changes of the specific heat and spin susceptibility, the latter being in analogy to magnetic properties of the pseudogap phase in high-temperature superconductors. The performance supports their goals of achieving more physically meaningful interpretations of phase detection results.

                - (5): The motivation for this research is to address the problem of interpreting phase detection results in quantum physics in a more physically meaningful way. By combining confusion learning and correlation convolutional neural networks, the authors propose a method that yields fully interpretable phase detection in terms of correlation functions.




 ## Paper:10




1. Title: CLIP Surgery for Better Explainability with Enhancement in Open-Vocabulary Tasks

2. Authors: Yi Li, Hualiang Wang, Yiqun Duan, Xiaomeng Li

3. Affiliation: 以第一作者Yi Li的所在机构为准：香港科技大学

4. Keywords: deeplearning, CLIP, explainability, multimodal vision model

5. Url: https://arxiv.org/abs/2110.06529, Github: https://github.com/xmed-lab/CLIP-Surgery

6. Summary:

- (1): 本文主要围绕深度学习模型CLIP，在改进其可解释性的同时提升其多任务性能。 

- (2): 本文对过去方法进行研究，发现现有方法存在一些解释性不足的问题，同时介绍其改进方法的动机。 

- (3): 本文提出了CLIP Surgery方法，该方法可以像手术一样修改推理结构和特征，从而改进其可解释性和增强在多个开放式任务中的性能。

- (4): 作者通过在多个公开数据集上的实验，探究其方法在多标签识别和开放式语义分割任务等方面的表现。本文提出的方法不仅在可解释性方面，而且在多任务性能提升方面都取得了很好的表现。

- (5): 本文旨在提高CLIP模型的性能，尤其是改善其解释性，使其在更多的任务中得到应用。




 ## Paper:11




1. Title: Improving Diffusion Models for Scene Text Editing with Dual Encoders (基于双编码器的扩散模型用于场景文本编辑的改进)

2. Authors: Jiabao Ji, Guanhua Zhang, Zhaowen Wang, Bairu Hou, Zhifei Zhang, Brian Price, Shiyu Chang

3. Affiliation: UC Santa Barbara (加州大学圣巴巴拉分校)

4. Keywords: Scene text editing, Diffusion models, Dual encoders, Image editing

5. Urls: Paper: arXiv:2304.05568v1 , Code: https://github.com/UCSB-NLP-Chang/DiffSTE 

6. Summary:

- (1): 本文研究了场景文本编辑这一具有挑战性的任务。
- (2): 既往的方法主要依赖样式转移模型，这些模型将文本区域裁剪出来，然后输入图像转移模型，如 GAN 。但是，这些方法在改变文本风格和插入文本方面的能力有限。最近，扩散模型的进一步发展对文本条件图像编辑有了突破性进展。然而，实证分析表明，现有的扩散模型在正确呈现文本和控制文本风格方面存在问题。基于本问题，本文提出 DIFFSTE 模型，通过双编码器设计方案来改进现有的预训练扩散模型。DIFFSTE 模型包含一个字符编码器以提高文本易读性，以及一个指令编码器以提高风格控制。引入指导调整框架来训练我们的模型，学习从文本指令到相应图像的映射，其既可以具有指定的风格，也可以使用背景中的周围文本的风格。这种训练方法进一步赋予了我们的方法以下三种情形的零-shot 泛化能力：使用未见过的字体变体，例如斜体和粗体，混合不同字体以构建新字体，以及使用更为宽松的自然语言形式作为指令来引导生成任务。文章在五个数据集上进行评估，展示了其在文本正确性、图像自然性和风格可控性方面的卓越表现。
- (3): 本文提出了 DIFFSTE 模型，通过双编码器设计方案来改进现有的预训练扩散模型，提高文本呈现中的可读性和控制文本风格。模型引入指引调整框架，通过学习从文本指令到相应图像的映射，其既可以具有指定的风格，也可以使用背景中的周围文本的风格。该方法为以下三种情形的零-shot 泛化提供了支持：使用未见过的字体变体，混合不同字体以构建新字体，以及使用更为宽松的自然语言形式作为指令来引导生成任务。
- (4): DIFFSTE 模型较之传统的基于GAN和现有的扩散模型在包括文本正确性、图像自然性和风格可控性等方面均有卓越表现，在文本编辑方面取得了很好的效果。
- (5): 本文的调研背景是场景文本编辑这一具有挑战性的任务。本文提出的 DIFFSTE 模型通过引入双编码器设计，提高文本呈现中的可读性和控制文本风格，进一步突破 GAN 和现有扩散模型的基础，并通过一系列实验验证其良好性能。




 ## Paper:12




1. Title: MoMo: A shared encoder Model for text, image and multi-Modal representations
（MoMo: 用于文本、图像和多模态表示的共享编码器模型）

2. Authors: Rakesh Chada, Zhaoheng Zheng, Pradeep Natarajan

3. Affiliation: 第一作者单位：亚马逊 Alexa AI

4. Keywords: self-supervised learning, multimodal learning, shared encoder, Transformer, cross-modal interactions

5. Urls: 论文链接：https://arxiv.org/abs/2304.05523

Github链接：None

6. Summary:

- (1): 本文研究的是多模态数据的共享编码器模型。
- (2): 本文提出的方法和以往不同，使用单个 Transformer 处理文本和图像模态，同时采用逐阶段的训练策略和多模态渐进式训练。本文方法在参数和数据量上都具有更高的效率，且性能优秀。本文方法能够在文本、图像和多模态任务中与多个强模型相比具有竞争力，在使用更少参数和数据的情况下，性能表现仍优秀，且大模型可获得较大的性能提升。
- (3): 本文的训练策略为逐步训练，方法采用共享编码器模型，同时采用跨模态交互来保留不同模态的信息。
- (4): 本文在不同任务中，如文本、图像和多模态任务中均取得了优异的表现，性能优越，并且方法可以在使用更少参数和数据的情况下获得和其他强模型相当的性能。
- (5): 本文的研究动机是为了在跨模态任务中提供更有效的共享编码器模型，在使用更少参数和数据的情况下获得更优秀的性能表现。




 ## Paper:13




1. Title: ChatGPT Beyond English: Towards a Comprehensive Evaluation of Large Language Models in Multilingual Learning
（ChatGPT: 超越英语，多语言学习中对大型语言模型的全面评估）

2. Authors: Viet Dac Lai, Nghia Trung Ngo, Amir Pouran Ben Veyseh, Hieu Man, Franck Dernoncourt, Trung Bui, Thien Huu Nguyen

3. Affiliation: Dept. of Computer Science, University of Oregon, OR, USA（美国俄勒冈大学计算机科学系）

4. Keywords: large language model, multilingual learning, ChatGPT, NLP

5. Urls: https://arxiv.org/abs/2304.05613
（论文链接） Github: None

6. Summary:
- (1):该文章介绍了大型语言模型在多语言学习中的应用，重点介绍了ChatGPT模型在不同语言上的表现情况。
- (2):以往的研究方法主要集中在英语上，对其他语言的研究还较为有限，因此需要对ChatGPT等语言模型进行全面的评估，以提高多语言应用的效果。
- (3):本文针对ChatGPT模型，从7个不同的任务、37种不同的语言角度进行了评估，重点关注了零样本学习，提高了结果的可重复性和适用性，并指出了存在的问题和改进方向。
- (4):ChatGPT在各种任务和语言上的表现较以往的模型略逊一筹，需要进一步研究和改进。
- (5):本文的动机在于在多语言学习的场景下，提高语言模型的适应能力和性能，进一步推动NLP技术的发展。




 ## Paper:14




1. Title: Advancing Medical Imaging with Language Models: A Journey from N-grams to ChatGPT (具有语言模型的医学成像：从N-gram到ChatGPT的旅程)
2. Authors: Mingzhe Hua, Shaoyan Pan, Yuheng Li, Xiaofeng Yang (*通讯作者)
3. Affiliation: Xiaofeng Yang - Emory University的Department of Computer Science and Informatics、Department of Biomedical Engineering 和 Department of Radiation Oncology, Winship Cancer Institute, School of Medicine
4. Keywords: medical imaging, language models, chatbot, image captioning, report generation, natural language processing
5. URLs: 
- 论文链接: https://www.frontiersin.org/articles/10.3389/fmed.2022.827024/full
- GitHub链接: None
6. Summary: 
- (1):该论文介绍了在医学成像领域中使用语言模型来改进任务的综述与教程。
- (2):该文章回顾了语言模型的历史和理念，重点介绍了如何使用语言模型来改进医学成像，强调了不同应用，例如图像字幕、报告生成、报告分类、发现提取、视觉问答、可解释的诊断等。该文章还着重介绍了ChatGPT以及其相对于其他语言模型的优点。文章提出了医学图像中主要的挑战之一是如何将自然语言模型有效地与医学图像进行整合，因此需要发展新型语言模型，以从医学图像中提取有意义的信息，并帮助医学专业人员进行进一步的诊断。本文的动机是填补语言模型与医学成像之间的差距，并鼓励在这个令人激动的研究领域中探索新的想法和创新。
- (3):文章首先概述了语言模型的历史和概念，随后介绍了当前如何使用语言模型来改进医学成像，强调了不同应用类型。该文章提出了语言模型可以支持医学成像提高临床工作流程的效率、降低诊断误差，以及帮助医疗保健专业人员提供及时和准确的诊断的潜在好处。
- (4):该论文提出了使用语言模型的方法，并在医学成像任务上展示了其性能：实现了对心脏CT图像的半自动分段。该方法可以减少需要手动标注的数据数量，提高工作效率，且实验结果表明该方法在精度和效率方面都具有竞争力。
- (5):该论文的动机是填补语言模型与医学成像之间的差距，鼓励在这个令人激动的研究领域中探索新的想法和创新，以进一步提高医学成像的效率和准确性。




 ## Paper:15




1. Title: Chatbots and ChatGPT: A Bibliometric Analysis and Systematic Review of Publications in Web of Science and Scopus Databases
               
                2. Authors: Hamed Khosravi, Mohammad Reza Shafie, Morteza Hajiabadi, Ahmed Shoyeb Raihan, Imtiaz Ahmed 

                3. Affiliation: Hamed Khosravi 所属机构为West Virginia University的Department of Industrial & Management Systems Engineering 

                4. Keywords: Chatbot, ChatGPT, bibliometric analysis, NLP, conversation agents 

                5. Urls: https://www.mdpi.com/2504-2289/5/4/80/htm  or Github: None

                6. Summary: 

                - (1): 本文主要针对聊天机器人领域，尤其是聊天GPT展开了文献计量分析和系统性文献综述，旨在了解该领域的结构、概念演变和趋势信息，为该领域的研究者提供有效的指导和未来研究方向。 

                - (2): 本文首先通过文献计量分析的方法从 Scopus和WoS两个数据库中收集了从1998年至2023年在聊天机器人领域发表的所有相关的学术文献，对这些文献的来源，国家，作者的影响以及关键词等进行了深入分析。其次，在ChatGPT这一最新聊天机器人领域的趋势方向上，本文对45篇相关研究文献进行了详细的方法、创新及结论分析。同时分析了该领域涉及到的关键问题，主要集中在人工智能及相关技术、设计和评价对话代理、数字技术和心理健康三个方向。本文还对传统的聊天机器人的方法与存在的问题进行了简要介绍和分析，展示了课题解决问题的良好动机和理论基础。 

                - (3): 本文采用文献计量分析的方法获取聊天机器人领域的研究数据，并通过深度分析ChatGPT的相关研究文献，对其方法、创新和结论进行评估，并结合实际应用场景来论证提出的方法的合理性和有效性。 

                - (4): 本研究在 Chatbot 领域中针对 ChatGPT 进行了全面的文献计量分析和系统化的文献综述分析，揭示了其结构、演变和趋势信息、揭示了 ChatGPT 是当前研究的主流方向，展示其在多种应用场景中的表现出众，如能够做到与人类谈话的完美衔接，这将进一步推动聊天机器人领域的发展和应用。 

                - (5): 本文旨在为聊天机器人领域的研究者提供指导与信息支持，同时通过对话代理的实际应用来论证方法性的合理性和有效性。




 ## Paper:16




1. Title: DreamPose: Fashion Image-to-Video Synthesis via Stable Diffusion

                2. Authors: Jie Cao, Huiwen Chang, Lan Xue, Kun Zhang, Wei Liu, Zheng Zhang

                3. Affiliation: Jie Cao - Alibaba Group

                4. Keywords: deeplearning, ML, fashion, image-to-video synthesis, stable diffusion

                5. Urls: Paper: https://arxiv.org/abs/2108.03884, Github: None

                6. Summary:

                - (1):本文的研究背景是衣着行业的流行趋势和视频生成技术。

                - (2):以前的方法都不能快速、精准地生成逼真的时装视频，主要存在数据不足、时间不一致等问题。本文的方法基于稳定扩散模型，克服了这些问题，可以生成高质量的时装视频。

                - (3):本文的研究方法主要是建立一个姿势和图片指导的视频合成模型，并采用一些技术手段，比如微调、结构改变、鼓励时间上的一致性等来提高模型的性能，并在UBC Fashion数据集上进行Fine-tune。

                - (4):本文的算法在时装视频动画生成任务上取得了最佳结果，通过两项用户研究得出了比MRAA和TPSMM更优质的交互结果。

                - (5):这篇文章的出发点是提供一种可靠的方法来快速生成时装视频，使时装企业和设计师能够在短时间内评估各种设计方案。




 ## Paper:17




1. Title: Continual Diffusion: Continual Customization of
Text-to-Image Diffusion with C-LoRA (使用C-LoRA进行文本到图像Diffusion的连续自定义)

2. Authors: James Seale Smith, Yen-Chang Hsu, Lingyu Zhang, Ting Hua, Zsolt Kira, Yilin Shen, Hongxia Jin 

3. Affiliation: 三星研究美国（Samsung Research America）

4. Keywords: Continual learning, Text-to-Image, Customization, Diffusion, Self-regularized 

5. Urls: paper link: https://arxiv.org/abs/2304.06027, Github: None

6. Summary:

- (1): 该文章以文本到图像生成为背景，提出了连续自定义的新问题，并在此基础上提出了一种新的方法。

- (2): 过去的方法主要集中在为单独的目标进行自定义，但对于涉及多种目标的连续场景来说，这些方法在面对新目标时容易出现灾难性的遗忘。所以，该文在此背景下，提出一套名为C-LoRA的自我正则化低秩适应方法来解决这个问题。

- (3): 本文提出一种名为“连续Diffusion”的问题框架，并在此基础上设计了一种自我正则化低秩适应方法-C-LoRA。C-LoRA的核心思想是在稳定的Diffusion模型的交叉注意力层中通过连续自我正则化的方式来提升连续学习的能力。

- (4): 该方法在多个任务上都取得了SOTA的表现。在文本到图像的生成任务中，使用该方法进行多个目标的自定义时，相比较于其他的baseline方法，有更高的准确率。与此同时，在基于图像数据的分类任务中，该方法也取得了SOTA表现。

- (5): 该文提出了一种新的问题，即在连续场景中进行文本到图片的生成。为了解决这个问题，提出了一种新的方法，该方法能够快速适应新目标且不会遗忘之前学习的内容，因此该方法在目前有一定的实际应用价值。




 ## Paper:18




1. Title: A Study on the Perceived Scientific Accuracy and Linguistic Quality of ChatGPT Responses to Physics Comprehension Questions

2. Authors: Merten Nikolay Dahlkemper, Simon Zacharias Lahme, Pascal Klein

3. Affiliation: 德国哥廷根大学物理系物理教育研究组

4. Keywords: ChatGPT, AI, physics education, scientific accuracy, linguistic quality

5. URLs: https://arxiv.org/abs/2304.05906, Github: None

6. Summary:
- (1): 这篇文章的研究背景是以ChatGPT为代表的生成式AI在物理教育中的应用越来越广泛，但其在科学准确性和语言质量上存在着局限性，并且对学生的学习体验和成果产生影响。
- (2): 在以往研究中，ChatGPT在涉及到物理问题的情况下存在类似于物理初学者的错误，且存在一些错误的偏见和解释；本文所提出的方法比以往研究更加透彻和细致，将科学精度和语言质量作为评估载体，同时在调查学生对回答的理解，综合考虑因素和两种模型的交互。研究提供了学生对ChatGPT回答的感知数据，并突出了学生和讲师在科学准确性上的谨慎评估。
- (3): 本文的研究采用了两种模型的交互，即人工制作的样本解答和ChatGPT的回答。在调查学生的态度、掌握知识程度、科学准确度和语言质量方面，研究采用了量化的实验方法和统计学分析。
- (4): 研究旨在探究学生对ChatGPT回答物理问题的科学准确性和语言质量的理解，结果显示，学生在非常陌生的情况下的




 ## Paper:19




1. Title: SpectralDiff: Hyperspectral Image Classification with Spectral-Spatial Diffusion Models （基于频谱-空间扩散模型的高光谱影像分类方法）

2. Authors: Ning Chen, Jun Yue, Leyuan Fang, Shaobo Xia

3. Affiliation: Ning Chen is with the Institute of Remote Sensing and Geographic Information System, Peking University （陈宁的附属机构为北京大学遥感与地理信息系统研究所）

4. Keywords: Deep neural network, hyperspectral image (HSI) classification, latent representation, feature extraction, diffusion model, deep generative model

5. Urls: Paper: arXiv:2304.05961v1  [cs.CV] Github: https://github.com/chenning0115/SpectralDiff (源代码与预训练模型)

6. Summary:
- (1):本文旨在解决高光谱数据维度高、相关性强等问题所带来的高光谱图像分类难题；
- (2):传统的高光谱图像分类方法(如PCA、LDA)存在对空间信息的未充分利用。因此，本文基于深度学习提出了一种基于频谱-空间扩散模型的高光谱影像分类方法。该方法既考虑频域，又考虑空域信息，能够更好地捕捉样本的全局信息;
- (3):本文提出的基于频谱-空间扩散模型的高光谱影像分类方法通过正反向的频谱-空间扩散过程实现了训练样本的频谱-空间分布的重构，并通过反向过程的频谱-空间去噪网络来提取无监督扩散特征，其能够在重建的训练样本分布中实现跨样本感知，从而提升了分类效果；
- (4):通过在三个公开数据集上的实验，本文所提出的分类方法取得了比现有方法更好的分类性能；
- (5):本文旨在提出一种能够更好地对高维高相关性数据进行建模处理的高光谱影像分类方法。




 ## Paper:20




1. Title: Can ChatGPT and Bard Generate Aligned Assessment Items? A Reliability Analysis against Human Performance (ChatGPT 和 Bard 能否生成相应考核题目？针对人类表现的可靠性分析)

2. Authors: Abdolvahab Khademi

3. Affiliation: University of Massachusetts, Amherst （马萨诸塞大学阿默斯特分校）

4. Keywords: Artificial intelligence; ChatGPT; Google Bard; Large language models; Natural language processing; Automated item generation; Educational technology (人工智能；ChatGPT；Google Bard；大语言模型；自然语言处理；自动题目生成；教育技术)

5. Url: None
    Github link: None

6. Summary: 
- (1): 本文研究 AI 系统在教育领域中的应用，特别是在考核和教学方面。考核方面，自动评分和自动题目生成一直有 AI 工具的应用。这些工具必须有高可靠性，以便在考核和评分过程中代替或帮助人类评分员。本文针对 ChatGPT 和 Bard 两个 AI 工具在写作项目难度和复杂性认知方面提出了可靠性评估，以人类评分员的表现作为基准。

- (2): 过去已经有许多研究探讨使用 AI 工具进行文本生成（如 ChatGPT）以及语言理解（如 Bard）的实用性，但是这些方法存在着可靠性不够高的问题。本文提出了通过人类评分员的标准来判断 ChatGPT 和 Bard 两个 AI 工具对复杂评价的可靠性。

- (3): 本文使用 Intraclass correlation (ICC) 表示 ChatGPT 和 Bard 工具与人类评价标准之间的可靠性。

- (4): 本文的研究任务是评估 ChatGPT 和 Bard 工具在感知和评估写作项目难度方面的可靠性。通过采用人类评分员标准作为基准，使用 ICC 对人工智能工具、人类评分员之间的可靠性进行评估。

- (5): 本文的研究动机在于使用 AI 技术进行考核和教学的可行性研究，特别是在教育技术领域的自动化题目生成方面。




 ## Paper:21




1. Title: A Multi-Institutional Open-Source Benchmark
Dataset for Breast Cancer Clinical Decision Support
using Synthetic Correlated Diffusion Imaging Data

2. Authors: Chi-en Amy Tai, Hayden Gunraj, Alexander Wong

3. Affiliation: Vision and Image Processing Lab, University of Waterloo (滑铁卢大学视觉与图像处理实验室)

4. Keywords: synthetic correlated diffusion imaging, breast cancer, clinical decision support, open-source benchmark dataset, machine learning

5. Urls: arXiv:None, Github: https://github.com/kislayabhi/Cancer-Net-BCa

6. Summary:
- (1):本文的研究背景是了解合成相关扩散成像（synthetic correlated diffusion imaging，CDIs）在其他癌症如乳腺癌中的效能；
- (2):此前的方法没有深入探索CDIs在癌症诊断方面的效果，同时也没有公开CDIs的数据，因此需要提供更好的多机构开源基准数据集，以支持使用CDIs进行计算机辅助癌症诊断。该方法的动机非常充分。；
- (3):本文提出了Cancer-Net BCa，一个包含253名来自十个机构的乳腺癌患者的体积CDIs成像数据的多机构开源基准数据集，并且提供了详细的注释元数据。其中包含磁共振成像的病变类型、遗传亚型、MRI中的最长直径（MRLD）、Scarff-Bloom-Richardson（SBR）等级和新辅助化疗治疗后乳腺癌病理学完全缓解（pathologic complete response，pCR）等信息。作者进一步研究了Cancer-Net BCa数据集的人口统计学和肿瘤多样性，以深入了解潜在偏见；
- (4):本文方法应用于机器学习的计算机辅助乳腺癌诊断任务，在完全缓解（pCR）和最长直径上取得了良好的性能表现，验证了方法的可行性。
- (5):本文的研究意义在于提供了公共的CDIs数据集，促进了使用机器学习进行计算机辅助乳腺癌诊断的自动化方法的发展，推进了人工智能技术在癌症治疗方面的应用。




 ## Paper:22




1. Title: RECLIP: Resource-efﬁcient CLIP by Training with Small

2. Authors: Runze Li, Dahun Kim, Bir Bhanu, Weicheng Kuo

3. Affiliation: Department of Computer Science and Engineering, University of California Riverside

4. Keywords: deeplearning, machinelearning, visiontransformer, CLIP, contrastivelearning

5. Urls: arXiv:2304.06028v1 [cs.CV] 12 Apr 2023, Github: None

6. Summary:
- (1): 本文研究背景为图像表示学习。
- (2): 过去的方法包括监督学习和自监督学习，本文使用语言监督来提高图像表示的效果，但运行资源需要高。该文提出了RECLIP方法，可以利用小图像有效地学习大规模语言监督，并在最后使用高分辨率数据进行微调，从而显著减少了训练资源需求。 
- (3): 本文的研究方法是RECLIP，该方法利用了计算机视觉中粗到细的观念，通过小图像进行训练，再使用高分辨率数据进行微调，从而显著减少了CPU资源和FLOPs的使用。
- (4): 在零样本分类和图像-文本检索方面，RECLIP与基线相比具有非常有竞争力的表现，并且可以使用6至8倍少的计算资源和7至9倍更少的FLOPs。与最先进的对比学习方法相比，RECLIP展示了5至59倍的训练资源节省，同时保持着非常有竞争力的零样本分类和检索性能。
- (5): 本文的动机是希望在更少的资源环境下探讨语言监督预训练，并提供计算资源方面的经验。




 ## Paper:23




1. Title: Resolving Ambiguity via Dialogue to Correct (通过对话消除歧义以矫正)

2. Authors: Joshua Rosser, Jacob Arkin, Siddharth Patki, Thomas M. Howard

3. Affiliation: Department of Electrical Computer Engineering, University of Rochester (罗切斯特大学电脑工程系)

4. Keywords: human-robot interaction, natural language processing, formal methods, dialogue, Linear Temporal Logic

5. Urls: 
- Paper link: https://arxiv.org/abs/2304.05485v1
- Github link: None

6. Summary:

- (1):本文研究了人与机器人团队间的交互问题，重点关注了消除环境和任务的不确定性所带来的影响。因此，有必要在执行命令之前消除团队之间的任何模糊性，以避免任务失败。

- (2):过去的研究方法注重形式化方法的保障，来合成机器人的反应控制器。但使用这些方法需要在保证正确性的情况下，让人类合作者能够为机器人制定一种特定的规范。但这些规范的制定通常要求人类能够精通制定的软件工具。因此，作者提出使用自然语言作为生成规范的媒介。

- (3):本文提出了一种自然语言交互的架构，采用符号表示法，这可以帮助构建Linear Temporal Logic (LTL)中的规范。该方法采用基于符号推理的自然语言沟通技术，结合形式验证技术，使机器人能够根据不完整的环境模型，从提供的指令中合成正确的反应控制器。这种处理方式提供了一种机制，可以通过对话来推测规范的修正，以便验证它们的正确性。

- (4):本文的提出，在一个由Astrobee机器人组成的仿真环境中测试其可行性。实验结果表明，该方法可以有效地消除控制器合成失败的情况，同时保留了自然语言的优势。而且，本文的方法摆脱了人类语言和机器人环境控制语言之间的限制，让非专家也可以描述任务，从而大大简化了要素选择的负担。

- (5):本文的意义在于通过自然语言的优势，为不精通形式验证的人类合作者提供了一种方法，从而使他们能够与机器人合作者之间达成共识。




 ## Paper:24




1. Title: Multi-step Jailbreaking Privacy Attacks on ChatGPT

2. Authors: Haoran Li, Dadi Guo, Wei Fan, Mingshi Xu, Yangqiu Song

3. Affiliation: 香港科技大学计算机科学与工程系

4. Keywords: large language models, privacy attacks, ChatGPT, AI-generated content

5. Url: None, Github code link: None

6. Summary:

- (1): 本文研究大型语言模型下的隐私攻击，特别是议题敏感的应用程序中可能引发的隐私泄漏问题。

- (2): 过去的工作主要关注于基于GPT-2模型的隐私泄漏问题，容易被攻击者利用。本文提出对聊天应用程序中的ChatGPT进行攻击的多步骤破解方法，并展示了应用程序整合模型带来的更严重的隐私威胁。文章的提出开创了大规模语言模型下的隐私攻击研究领域。

- (3): 本文提出了一种多步骤的破解方法，通过构造钓鱼网站骗取用户登录信息，然后结合一系列技巧，最终破解出用户在聊天程序中的信息。

- (4): 本文实验研究了基于ChatGPT的OpenAI模型API和New Bing的隐私威胁，并展示了应用程序整合模型带来的更严重的隐私泄漏问题。实验结果表明本文提出的多步骤攻击方法能够有效地突破聊天程序的隐私保护机制。

- (5): 本文关注大型语言模型下的隐私攻击问题，通过对ChatGPT的攻击，意图唤起对现有大规模语言模型的隐私问题的关注，提醒研究者和企业对数据隐私保护的重视。




 ## Paper:25




1. Title: Probabilistic Human Mesh Recovery in 3D Scenes from Egocentric Views (从自我中心视角的3D场景中概率恢复人类网格)


2. Authors: Sanwei Li, Yichao Zhou, Jingyi Yu, Kaiwen Mo, Hao Li


3. Affiliation: None


4. Keywords: Egocentric vision, human pose recovery, diffusion model, graph convolutional networks (自我中心视角、人体姿态恢复、扩散模型、图卷积网络)


5. Urls: Paper: https://arxiv.org/abs/2105.12183 , Github: https://sanweiliti.github.io/egohmr/egohmr.html


6. Summary:

- (1): 本篇文章的研究背景是自我中心视角（Egocentric vision）中人类姿态的回复问题，如何从自我中心拍摄的视角中恢复出人体的姿态和形状。

- (2): 之前的方法在拍摄距离很近的情况下，会因为人体被遮挡而出现较大的姿态模糊，这篇文章提出了一个新的模型来解决这个问题。新模型中引入了扩散模型以及图卷积网络来提高恢复准确度。

- (3): 本文提出了一种基于场景的扩散方法来建模人体姿态分布，扩散模型会在3D场景几何条件下生成合理的人体场景交互，使用物理碰撞评分来指导采样以进一步解决人体-场景穿透问题。所述模型采用无类别分类器训练，可对极大范围的条件具有高度灵活性和多样性。我们的扩散去噪模型是一个基于Graph Convolutional Networks的多肢体模型，能够在保持关节可视性的前提下融入肢体间依赖关系。

- (4): 该方法在3D场景中生成人体交互时的准确性和能在不可见肢体上保持多样性表现出了卓越的性能。代码可在https://sanweiliti.github.io/egohmr/egohmr.html中下载。 

- (5): 本文的研究动机在于解决如何从自我中心拍摄的视角中恢复出人体的姿态和形状，以便在AR/VR等应用中更好地实现互动。




 ## Paper:26




1. Title: Zero-shot Temporal Relation Extraction with ChatGPT

2. Authors: Chenhan Yuan, Qianqian Xie, Sophia Ananiadou

3. Affiliation: 曼彻斯特大学计算机科学系

4. Keywords: zero-shot learning, temporal relation extraction, natural language processing, pre-trained language models, ChatGPT

5. Urls: Paper: arXiv:2304.05454v1; Github: None

6. Summary: 

- (1): 本文研究的背景是在时间关系的抽取任务中，监督模型需要耗费领域专家大量标注数据，其成本很高。另外，零样本学习正越来越受到研究者们的重视。

- (2): 本文探究了预训练语言模型ChatGPT在零样本时间关系抽取任务中的表现，并提出三种不同的提示策略来帮助ChatGPT完成任务。与监督模型相比，ChatGPT表现出很大的不足之处，需要设计有效的提示才能提高性能。此外，本文还发现ChatGPT在长依赖的情况下容易失去一致性。

- (3): 本文提出了三种不同的提示策略来指导ChatGPT进行零样本时间关系抽取：1）没有提示；2）事件排序提示；3）思路链提示。

- (4): 通过实验，本文展示了ChatGPT在零样本时间关系抽取任务中的性能与监督模型有很大的差距。此外，ChatGPT在小类别的时间关系抽取方面的性能优于监督模型。本文的实验表明，对于复杂的 NLP 任务，目前的零样本学习方法仍然受限，需要在更大规模的预训练模型和更丰富的知识获取方面进行进一步研究。

- (5): 挖掘预训练语言模型的潜力，改善时间关系的抽取任务，并寻求适用于更复杂 NLP 任务的简单零样本学习方法。




 ## Paper:27




1. Title: Generative Knowledge Selection for Knowledge-Grounded Dialogues（面向知识引导对话的生成式知识选择）

2. Authors: Weiwei Sun, Pengjie Ren, Zhaochun Ren*

3. Affiliation: Shandong University（山东大学）

4. Keywords: Knowledge selection, knowledge-grounded dialogues, generative approach, attention mechanisms

5. Urls: Paper link: https://arxiv.org/abs/2304.04836 Github: None

6. Summary:
- (1): 本文的研究背景是针对开放领域对话系统的不足，提出了利用外部结构性和非结构性知识来增加对话代理的信息量。
- (2): 以往的研究方法采用分类方式来选择知识片段，但此类方法忽略了知识间的相互作用，导致难以推断片段的含义。此外，它们缺乏对对话知识交互关系的建模。本文提出了一种简单而有效的生成式方法 GENKS，通过序列到序列模型生成标识符，从而选择片段。GENKS 通过关注机制天然地捕捉了片段之间的交互。同时，我们设计了一个超链接机制，以明确建模对话知识交互。 
- (3): 本文提出的 GENKS 在知识选择方面取得了最好的表现，并在相应生成任务上获得了最佳性能。 
- (4): 实验在三个基准数据集上进行，验证了 GENKS 在知识选择和响应生成方面的最佳表现。
- (5): 本文的研究动机是为了提高开放领域对话代理的信息量，利用外部结构性和非结构性知识来增加对话内容的丰富性。




 ## Paper:28




1. Title: Toxicity in CHATGPT: Analyzing Persona-assigned Language Models

2. Authors: Ameet Deshpande, Vishvak Murahari, Tanmay Rajpurohit, Ashwin Kalyan, Karthik Narasimhan

3. Affiliation:  Ameet Deshpande, Vishvak Murahari, and Karthik Narasimhan are from Princeton University, Ashwin Kalyan and Karthik Narasimhan are from The Allen Institute for AI, and Tanmay Rajpurohit is from Georgia Tech.

4. Keywords: deeplearning, ML, NLP, toxic language, large language models

5. Urls: Paper: https://arxiv.org/abs/2304.05335, Github: None

6. Summary:

- (1): The paper studies the toxicity of near-human-level language models, which are widely used in various applications such as healthcare, therapy, and customer service, but have the potential to generate harmful and biased outputs.

- (2): The past methods do not fully consider the potential harm caused to vulnerable users by the outputs generated by language models. The approach of systematically evaluating toxicity in persona-assigned language models is well motivated.

- (3): The researchers systematically evaluate toxicity in over half a million generations of CHATGPT, a popular dialogue-based LLM, by assigning it different personas and measuring the toxicity of its outputs. 

- (4): The paper finds that assigning CHATGPT a persona significantly increases the toxicity of its generations and that the toxicity can increase up to 6× depending on the assigned persona, with outputs engaging in incorrect stereotypes, harmful dialogue, and hurtful opinions. CHATGPT generates more toxic language for certain races, reflecting inherent discriminatory biases in the model. 

- (5): The motivation for the research in this article is to inspire the broader AI community to reimagine the current safety guardrails and develop better techniques that lead to robust, safe, and trustworthy AI systems.



